"""
Knowledge Service

GENERAL service that handles information requests using domain-specific knowledge.
This service structure works for any domain - just swap the domain_knowledge module.
"""

import logging
import json
from typing import Dict, Optional, TYPE_CHECKING
from ..prompts.intent_types import InformationRequestType, IntentCategory, DetectedIntent
from ..prompts import domain_knowledge

if TYPE_CHECKING:
    from .llm.base import BaseLLMProvider, Message

logger = logging.getLogger(__name__)


class KnowledgeService:
    """
    Service for handling information requests about the app/process

    This is a GENERAL pattern that works across domains. The domain-specific
    content comes from the domain_knowledge module.
    """

    def __init__(self):
        """Initialize knowledge service"""
        self.domain_info = domain_knowledge.DOMAIN_INFO
        self.features = domain_knowledge.FEATURES
        self.faq = domain_knowledge.FAQ
        logger.info(f"KnowledgeService initialized for domain: {self.domain_info['domain']}")

    def detect_information_request(self, user_message: str) -> Optional[InformationRequestType]:
        """
        Detect if user is asking for information about the app/process

        Args:
            user_message: User's message

        Returns:
            InformationRequestType if detected, None otherwise
        """
        message_lower = user_message.lower()

        # Check for app features questions
        if any(phrase in message_lower for phrase in [
            "×ž×” ×× ×™ ×™×›×•×œ", "×ž×” ×™×©", "××™×–×” ××¤×©×¨×•×™×•×ª", "×ž×” ×–×ž×™×Ÿ",
            "what can i do", "what features", "what's available"
        ]):
            return InformationRequestType.APP_FEATURES

        # Check for process explanation questions
        if any(phrase in message_lower for phrase in [
            "××™×š ×–×” ×¢×•×‘×“", "×ž×” ×”×ª×”×œ×™×š", "××™×š ×–×” ×¢×•×‘×“",
            "how does", "what's the process", "how it works"
        ]):
            return InformationRequestType.PROCESS_EXPLANATION

        # Check for current state questions
        if any(phrase in message_lower for phrase in [
            "××™×¤×” ×× ×™", "×ž×” ×”×©×œ×‘", "×ž×” ×¢×›×©×™×•",
            "where am i", "what stage", "what's next", "what now"
        ]):
            return InformationRequestType.CURRENT_STATE

        # Check for time/duration questions
        if any(phrase in message_lower for phrase in [
            "×›×ž×” ×–×ž×Ÿ", "×›×ž×” ×œ×•×§×—", "how long", "duration"
        ]):
            return InformationRequestType.PROCESS_EXPLANATION

        return None

    async def detect_intent_llm(
        self,
        user_message: str,
        llm_provider: "BaseLLMProvider",
        context: Dict
    ) -> DetectedIntent:
        """
        Use LLM to classify intent with semantic understanding (Tier 2 - Accurate Path)

        This provides semantic understanding of user intents that string matching misses.
        Handles Hebrew morphology, word variations, and complex phrasing.

        Args:
            user_message: User's message to classify
            llm_provider: LLM provider instance to use
            context: Current context (child_name, completeness, video_count, etc.)

        Returns:
            DetectedIntent with proper category, type, and confidence score
        """
        from .llm.base import Message

        # Build classification prompt using Layer 1 enums
        classification_prompt = f"""You are an intent classifier for a child development assistant app.
Analyze the user message and classify it into one of these intent categories.

**User message:** "{user_message}"

**Current context:**
- Interview completeness: {context.get('completeness', 0.0):.0%}
- Child name: {context.get('child_name', 'unknown')}
- Video count: {context.get('video_count', 0)}

**Intent Categories (pick ONE):**

1. **DATA_COLLECTION** - User wants to continue the main conversation/interview about their child
   - Sharing information about their child
   - Answering interview questions
   - Continuing the discussion naturally
   - Examples: "×”×•× ×ž××“ ××•×”×‘ ×œ×¦×™×™×¨", "×›×Ÿ ×™×© ×œ×• ×§×©×™×™× ×‘×ª×§×©×•×¨×ª", "×”×‘×ª ×©×œ×™ ×‘×ª 4"

2. **ACTION_REQUEST** - User wants to perform a specific action
   - Wants to view report, upload video, see guidelines, find experts
   - Examples: "×¨×•×¦×” ×œ×¨××•×ª ×“×•×—", "××™×š ×ž×¢×œ×™× ×¡×¨×˜×•×Ÿ", "×ª×¨××™ ×œ×™ ×”× ×—×™×•×ª", "×× ×™ ×¨×•×¦×” ×œ×ž×¦×•× ×ž×•×ž×—×™×"
   - If this category, specify which action:
     * view_report - "×¨×•×¦×” ×œ×¨××•×ª ×“×•×—", "×”×“×•×— ×ž×•×›×Ÿ?", "×ª×¦×™×’×™ ××ª ×”×“×•×—"
     * upload_video - "×œ×”×¢×œ×•×ª ×¡×¨×˜×•×Ÿ", "××™×š ×ž×¢×œ×™×?", "×¨×•×¦×” ×œ×”×¢×œ×•×ª"
     * view_video_guidelines - "×ž×” ×œ×¦×œ×?", "×”× ×—×™×•×ª ×¦×™×œ×•×", "×ª×¨××™ ×œ×™ ×”× ×—×™×•×ª"
     * find_experts - "×ž×•×ž×—×™× ×‘××–×•×¨", "×ž×™ ×™×›×•×œ ×œ×¢×–×•×¨", "×”×ž×œ×¦×•×ª ×¢×œ ×ž×˜×¤×œ×™×"
     * add_journal_entry - "×¨×•×¦×” ×œ×¨×©×•× ×‘×™×•×ž×Ÿ", "×œ×”×•×¡×™×£ ×¨×©×•×ž×”"

3. **INFORMATION_REQUEST** - User wants to learn about the app/process/features
   - Examples: "×ž×” ×× ×™ ×™×›×•×œ×” ×œ×¢×©×•×ª?", "××™×š ×”×ª×”×œ×™×š ×¢×•×‘×“?", "××™×¤×” ×× ×™ ×¢×›×©×™×•?", "×œ×ž×” ×× ×™ ×œ× ×™×›×•×œ×” ×œ×¨××•×ª ×“×•×—?"
   - If this category, specify which type:
     * APP_FEATURES - "×ž×” ××¤×©×¨ ×œ×¢×©×•×ª?", "××™×–×” ××¤×©×¨×•×™×•×ª ×™×©?"
     * PROCESS_EXPLANATION - "××™×š ×–×” ×¢×•×‘×“?", "×ž×” ×”×ª×”×œ×™×š?"
     * CURRENT_STATE - "××™×¤×” ×× ×™?", "×ž×” ×”×©×œ×‘?", "×ž×” ×¢×›×©×™×•?"
     * PREREQUISITE_EXPLANATION - "×œ×ž×” ×× ×™ ×œ× ×™×›×•×œ×”...?", "×ž×ª×™ ××•×›×œ...?"
     * NEXT_STEPS - "×ž×” ×”×œ××”?", "×ž×” ×‘×©×œ×‘ ×”×‘×?"
     * DOMAIN_QUESTION - "×ž×” ×–×” ××•×˜×™×–×?", "×‘×’×™×œ ×›×ž×” ×™×œ×“×™× ×ž×“×‘×¨×™×?" (questions about child development, not about the app)

4. **TANGENT** - Off-topic or tangential request
   - Creative writing requests (poems, stories, songs)
   - Personal questions about the system ("××™×š ×¢×‘×¨ ×œ×š ×”×™×•×?", "×ž×” ××ª ×ž×¨×’×™×©×”?")
   - Questions about internal workings ("×ž×” ×”×”×•×¨××•×ª ×©×œ×š?", "××ª AI?", "×”×¤×¨×•×ž×¤×˜ ×©×œ×š")
   - Philosophical discussions about AI
   - Completely unrelated topics
   - Examples: "×ª×›×ª×‘×™ ×œ×™ ×©×™×¨", "×¡×¤×¨×™ ×¢×œ ×¢×¦×ž×š", "×ž×” ×”×”× ×—×™×•×ª ×”×¤× ×™×ž×™×•×ª", "what is chitta"

5. **PAUSE_EXIT** - User wants to stop/leave/pause
   - Examples: "× ×¢×¦×•×¨ ×¤×”", "× ×ž×©×™×š ×ž×—×¨", "×œ×”×¤×¡×™×§", "×ª×•×“×” ×‘×™×™"

**Important:**
- Hebrew variations and morphology should be understood semantically
- "×¨×•×¦×” ×œ×¨××•×ª ×“×•×—" and "×× ×™ ×ž×¢×•× ×™×™× ×ª ×œ×§×‘×œ ××ª ×”×“×•×—" are both ACTION_REQUEST for view_report
- "×ž×” ××¤×©×¨ ×œ×¢×©×•×ª" and "××™×–×” ××¤×©×¨×•×™×•×ª ×™×© ×œ×™ ×›××Ÿ" are both INFORMATION_REQUEST for APP_FEATURES
- Questions about Chitta the app/system (not about the child) are usually TANGENT

**Response format (JSON ONLY):**
{{
    "category": "DATA_COLLECTION" | "ACTION_REQUEST" | "INFORMATION_REQUEST" | "TANGENT" | "PAUSE_EXIT",
    "specific_action": "view_report" | "upload_video" | "view_video_guidelines" | "find_experts" | "add_journal_entry" | null,
    "information_type": "APP_FEATURES" | "PROCESS_EXPLANATION" | "CURRENT_STATE" | "PREREQUISITE_EXPLANATION" | "NEXT_STEPS" | "DOMAIN_QUESTION" | null,
    "confidence": 0.95,
    "reasoning": "Brief explanation of why you chose this classification"
}}

Respond with ONLY the JSON object, no other text."""

        try:
            # Call LLM with low temperature for consistency
            response = await llm_provider.chat(
                messages=[Message(role="user", content=classification_prompt)],
                functions=None,
                temperature=0.1,
                max_tokens=300
            )

            # Parse JSON response
            response_text = response.content.strip()

            # Try to extract JSON if LLM wrapped it in markdown code blocks
            if "```json" in response_text:
                response_text = response_text.split("```json")[1].split("```")[0].strip()
            elif "```" in response_text:
                response_text = response_text.split("```")[1].split("```")[0].strip()

            intent_data = json.loads(response_text)

            # Build DetectedIntent properly
            detected = DetectedIntent(
                category=IntentCategory(intent_data["category"].lower()),
                information_type=InformationRequestType(intent_data["information_type"].lower()) if intent_data.get("information_type") else None,
                specific_action=intent_data.get("specific_action"),
                confidence=float(intent_data.get("confidence", 0.8)),
                user_message=user_message,
                context={"reasoning": intent_data.get("reasoning", ""), "tier": "llm"}
            )

            logger.info(
                f"LLM Intent Classification: category={detected.category.value}, "
                f"confidence={detected.confidence:.2f}, reasoning={detected.context.get('reasoning', '')}"
            )

            return detected

        except json.JSONDecodeError as e:
            # Fallback if LLM doesn't return valid JSON
            logger.warning(f"LLM returned invalid JSON for intent classification: {e}")
            logger.warning(f"Response was: {response.content[:200]}")
            return DetectedIntent(
                category=IntentCategory.DATA_COLLECTION,
                confidence=0.3,
                user_message=user_message,
                context={"error": "invalid_json", "llm_response": response.content[:200], "tier": "llm_fallback"}
            )

        except Exception as e:
            # Fallback on any error
            logger.error(f"Error in LLM intent classification: {e}")
            return DetectedIntent(
                category=IntentCategory.DATA_COLLECTION,
                confidence=0.3,
                user_message=user_message,
                context={"error": str(e), "tier": "llm_fallback"}
            )

    def get_knowledge_for_prompt(
        self,
        information_type: InformationRequestType,
        context: Dict
    ) -> str:
        """
        Get domain knowledge formatted for injection into LLM prompt

        Args:
            information_type: Type of information requested
            context: Current state context (child_name, completeness, etc.)

        Returns:
            Formatted knowledge string to inject into prompt
        """
        child_name = context.get("child_name", "×”×™×œ×“/×”")

        if information_type == InformationRequestType.APP_FEATURES:
            return self._get_app_features_knowledge(context)

        elif information_type == InformationRequestType.PROCESS_EXPLANATION:
            return self._get_process_knowledge()

        elif information_type == InformationRequestType.CURRENT_STATE:
            return self._get_current_state_knowledge(context)

        else:
            return ""

    def _get_app_features_knowledge(self, context: Dict) -> str:
        """Get knowledge about app features"""
        child_name = context.get("child_name", "×”×™×œ×“/×”")
        completeness = context.get("completeness", 0.0)
        interview_complete = completeness >= 0.80

        # Get feature list based on current state
        current_state = {
            "interview_complete": interview_complete,
            "minimum_videos": context.get("video_count", 0) >= 3,
            "reports_available": context.get("reports_available", False)
        }

        feature_list = domain_knowledge.get_feature_list_hebrew(current_state)

        # Check if there's a matching FAQ answer
        faq_key = domain_knowledge.match_faq_question("×ž×” ×× ×™ ×™×›×•×œ ×œ×¢×©×•×ª")
        if faq_key and faq_key in self.faq:
            faq_answer = self.faq[faq_key]["answer_hebrew"]
            # Replace placeholders
            faq_answer = faq_answer.replace("{child_name}", child_name)
            answer = faq_answer
        else:
            answer = feature_list

        return f"""## âš ï¸ INFORMATION REQUEST DETECTED

The parent asked: **"What can I do in this app?"**

This is a legitimate question about app features. You should answer it!

**Here's what you should tell them:**

{answer}

**After answering, ask if they want to continue the interview.**"""

    def _get_process_knowledge(self) -> str:
        """Get knowledge about the process"""
        process = domain_knowledge.PROCESS_OVERVIEW_HEBREW

        return f"""## âš ï¸ INFORMATION REQUEST DETECTED

The parent asked about the process/how it works.

**Here's the process overview to share:**

{process}

**After explaining, ask if they want to continue the interview.**"""

    def _get_current_state_knowledge(self, context: Dict) -> str:
        """Get knowledge about current state and next steps"""
        completeness = context.get("completeness", 0.0)
        completeness_pct = int(completeness * 100)
        child_name = context.get("child_name", "×”×™×œ×“/×”")

        if completeness < 0.80:
            return f"""## âš ï¸ INFORMATION REQUEST DETECTED

The parent asked where they are in the process.

**Current state:**
- Stage: Interview (in progress)
- Completeness: {completeness_pct}%
- Next: Continue interview until ~80%+, then video guidelines

**Tell them:**
"×× ×—× ×• ×‘×©×œ×‘ ×”×¨××™×•×Ÿ, ×©×–×” ×”×‘×¡×™×¡ ×œ×›×œ ×”×ª×”×œ×™×š. ×¢×‘×¨× ×• ×‘×¢×¨×š {completeness_pct}% - ×¢×•×“ ×§×¦×ª ×©×™×—×” ×•××– × ×¢×‘×•×¨ ×œ×”× ×—×™×•×ª ×¦×™×œ×•×. ×¨×•×¦×” ×©× ×ž×©×™×š?"
"""
        else:
            return f"""## âš ï¸ INFORMATION REQUEST DETECTED

The parent asked where they are in the process.

**Current state:**
- Stage: Interview complete ({completeness_pct}%)
- Next: Video filming guidelines

**Tell them:**
"×¡×™×™×ž× ×• ××ª ×”×¨××™×•×Ÿ! ({completeness_pct}%) ×”×©×œ×‘ ×”×‘× ×”×•× ×©×× ×™ ××›×™×Ÿ ×œ×š ×”× ×—×™×•×ª ×¦×™×œ×•× ×ž×•×ª××ž×•×ª ××™×©×™×ª ×œ{child_name}. ×ž×•×›× /×” ×œ×§×‘×œ ××•×ª×Ÿ?"
"""

    def get_direct_answer(
        self,
        user_message: str,
        context: Dict
    ) -> Optional[str]:
        """
        Get direct answer to FAQ question if available

        Args:
            user_message: User's question
            context: Current context

        Returns:
            Direct Hebrew answer if available, None otherwise
        """
        faq_key = domain_knowledge.match_faq_question(user_message)

        if faq_key and faq_key in self.faq:
            # Special handling for privacy questions - make them context-aware
            if faq_key == "data_privacy_comprehensive":
                return self._get_contextual_privacy_answer(user_message, context)

            answer = self.faq[faq_key]["answer_hebrew"]

            # Replace placeholders
            child_name = context.get("child_name", "×”×™×œ×“/×”")
            answer = answer.replace("{child_name}", child_name)

            return answer

        return None

    def _get_contextual_privacy_answer(
        self,
        user_message: str,
        context: Dict
    ) -> str:
        """
        Generate context-aware privacy response based on what user is specifically asking

        Args:
            user_message: User's privacy-related question
            context: Current context

        Returns:
            Focused privacy answer addressing their specific concern
        """
        message_lower = user_message.lower()
        child_name = context.get("child_name", "×”×™×œ×“/×”")

        # Detect specific sub-topic
        asking_about_videos = any(word in message_lower for word in ['×¡×¨×˜×•×Ÿ', '×•×™×“××•', '×¦×™×œ×•×'])
        asking_about_who_sees = any(word in message_lower for word in ['×ž×™ ×¨×•××”', '×ž×™ ×™×›×•×œ', '×’×™×©×”'])
        asking_about_storage = any(word in message_lower for word in ['××™×¤×”', '×©×•×ž×¨', '× ×©×ž×¨', '×ž××•×—×¡×Ÿ'])
        asking_about_security = any(word in message_lower for word in ['×ž××•×‘×˜×—', '×‘×˜×•×—', '×”×¦×¤× ×”'])

        # Build a focused response based on what they're asking
        response_parts = []

        # Opening - acknowledge their concern
        response_parts.append(
            f"×–×• ×©××œ×” **×—×©×•×‘×”** ×•×× ×™ ×©×ž×—×” ×©××ª×” ×©×•××œ! ðŸ”’\n"
        )

        # Answer their specific question first
        if asking_about_videos and asking_about_storage:
            response_parts.append(
                "**××™×¤×” ×”×¡×¨×˜×•× ×™× × ×©×ž×¨×™×?**\n"
                "â€¢ ×”×¡×¨×˜×•× ×™× ×©×œ×š × ×©×ž×¨×™× ×‘×©×¨×ª×™× ×ž××•×‘×˜×—×™× ×¢× ×”×¦×¤× ×” ×ž×œ××” (AES-256 - ×›×ž×• ×‘× ×§×™×)\n"
                "â€¢ ×”×©×¨×ª×™× ×¢×•×ž×“×™× ×‘×ª×§× ×™ ×”×’× ×ª ×ž×™×“×¢ ×¨×¤×•××™ ×•-GDPR\n"
                "â€¢ ×’×™×‘×•×™×™× ×ž×•×¦×¤× ×™× ××•×˜×•×ž×˜×™×™× ×œ×ž× ×™×¢×ª ××•×‘×“×Ÿ\n\n"
            )
        elif asking_about_storage:
            response_parts.append(
                "**××™×¤×” ×”×ž×™×“×¢ × ×©×ž×¨?**\n"
                "â€¢ ×›×œ ×”×ž×™×“×¢ (×©×™×—×•×ª, ×¡×¨×˜×•× ×™×, ×“×•×—×•×ª) × ×©×ž×¨ ×‘×©×¨×ª×™× ×ž××•×‘×˜×—×™×\n"
                "â€¢ ×”×¦×¤× ×” ×ž×œ××” ×‘×¨×ž×ª AES-256 (×›×ž×• ×‘×ž×¢×¨×›×•×ª ×‘× ×§××•×ª ×•×¨×¤×•××™×•×ª)\n"
                "â€¢ ×¢×•×ž×“×™× ×‘×ª×§× ×™ GDPR ×•×”×’× ×ª ×ž×™×“×¢ ×¨×¤×•××™\n\n"
            )

        if asking_about_who_sees:
            response_parts.append(
                "**×ž×™ ×™×›×•×œ ×œ×¨××•×ª ××ª ×”×ž×™×“×¢?**\n"
                "â€¢ **××ª×” ×‘×œ×‘×“** - ×™×© ×œ×š ×’×™×©×” ×ž×œ××” ×œ×›×œ ×”×ž×™×“×¢ ×©×œ×š\n"
                "â€¢ **×ž×•×ž×—×™× ×©×ª×‘×—×¨** - ×¨×§ ×× ×ª××©×¨ ×‘×ž×¤×•×¨×© ×œ×©×ª×£ ××™×ª×\n"
                "â€¢ **×‘×§×¨×ª ××™×›×•×ª** - ×‘×ž×§×¨×™× × ×“×™×¨×™×, ×ž×•×ž×—×” ×ž××•×ž×ª ×¢×©×•×™ ×œ×‘×“×•×§ ××ª ×”×“×•×— ×œ××™×›×•×ª\n"
                "â€¢ **××£ ×’×•×¨× ×©×œ×™×©×™** ×œ× ×ž×§×‘×œ ×’×™×©×” ×œ×œ× ×”×¡×›×ž×ª×š\n\n"
            )

        if asking_about_security:
            response_parts.append(
                "**×›×ž×” ×–×” ×ž××•×‘×˜×—?**\n"
                "â€¢ ×”×¦×¤× ×” ×ž×œ××” ×‘×¨×ž×ª AES-256 (×”×ª×§×Ÿ ×”×’×‘×•×” ×‘×™×•×ª×¨)\n"
                "â€¢ ××‘×˜×—×ª ×¨×©×ª ×¨×‘-×©×›×‘×ª×™×ª\n"
                "â€¢ ×ª×§× ×™ ××‘×˜×—×” ×¨×¤×•××™×™×\n"
                "â€¢ ×’×™×‘×•×™×™× ×ž×•×¦×¤× ×™×\n\n"
            )

        # Add general privacy principles if they didn't ask specifically
        if not any([asking_about_storage, asking_about_who_sees, asking_about_security]):
            response_parts.append(
                "**×‘×§×¦×¨×”:**\n"
                "â€¢ **×”×¦×¤× ×” ×ž×œ××”** - ×‘×¨×ž×ª ×‘× ×§××•×ª ×•×¨×¤×•××” (AES-256)\n"
                "â€¢ **×¨×§ ××ª×”** ×™×›×•×œ ×œ×¨××•×ª ××ª ×”×ž×™×“×¢ ×©×œ×š\n"
                "â€¢ **×©×œ×™×˜×” ×ž×œ××”** - ×–×›×•×ª ×œ×ž×—×™×§×”, ×™×™×¦×•×, ×•×”×’×‘×œ×”\n"
                "â€¢ **×ª×§× ×™ GDPR** ×•×”×’× ×” ×ž×™×•×—×“×ª ×œ×§×˜×™× ×™×\n\n"
            )

        # Always add control section
        response_parts.append(
            "**×”×©×œ×™×˜×” ×©×œ×š:**\n"
            "â€¢ ×–×›×•×ª ×œ×ž×—×™×§×ª ×›×œ ×”×ž×™×“×¢ ×‘×›×œ ×¢×ª\n"
            "â€¢ ×–×›×•×ª ×œ×™×™×¦×•× ×”×¢×ª×§ ×©×œ ×›×œ ×”×ž×™×“×¢ ×©×œ×š\n"
            "â€¢ ×–×›×•×ª ×œ×”×’×‘×œ×ª ×”×©×™×ž×•×© ×‘×ž×™×“×¢\n\n"
        )

        # Closing
        response_parts.append(
            "×”×¤×¨×˜×™×•×ª ×©×œ×š ×”×™× **×§×“×•×©×”** ×¢×‘×•×¨× ×•. ðŸ’™\n\n"
            "×™×© ×œ×š ×¢×•×“ ×©××œ×•×ª ×¢×œ ×¤×¨×˜×™×•×ª ××• ××‘×˜×—×”?"
        )

        return "".join(response_parts)


# Singleton instance
_knowledge_service = None


def get_knowledge_service() -> KnowledgeService:
    """Get or create singleton knowledge service instance"""
    global _knowledge_service
    if _knowledge_service is None:
        _knowledge_service = KnowledgeService()
    return _knowledge_service
