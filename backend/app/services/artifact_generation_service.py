"""
Artifact Generation Service - Wu Wei Architecture

Generates artifacts (guidelines, reports) when prerequisites are met.
Uses LLM to create personalized, context-aware content.

Key artifacts:
- video_guidelines: Personalized video recording instructions
- parent_report: Comprehensive assessment report (requires video analysis)
- professional_report: Clinical assessment for healthcare providers
"""

import logging
import os
from typing import Dict, Any, Optional
from datetime import datetime
import time

from app.models.artifact import Artifact
from app.config.artifact_manager import get_artifact_manager
from app.services.llm.factory import create_llm_provider

logger = logging.getLogger(__name__)


class ArtifactGenerationService:
    """
    Service for generating artifacts using LLM.

    Each artifact has:
    1. Input requirements (what data is needed)
    2. Generation logic (how to create it)
    3. Output format (markdown, JSON, etc.)
    """

    def __init__(self, llm_provider=None):
        """
        Initialize artifact generation service.

        Args:
            llm_provider: LLM provider for generation (optional, will create strong LLM if None)
        """
        if llm_provider is None:
            # ğŸŒŸ Create strong LLM specifically for artifact generation
            # This ensures high-quality output for guidelines, reports, etc.
            strong_model = os.getenv("STRONG_LLM_MODEL", "gemini-3-pro-preview")
            provider_type = os.getenv("LLM_PROVIDER", "gemini")

            logger.info(f"ğŸ§  Creating strong LLM for artifact generation: {strong_model}")
            self.llm_provider = create_llm_provider(
                provider_type=provider_type,
                model=strong_model,
                use_enhanced=False  # Strong models don't need enhanced mode
            )
        else:
            self.llm_provider = llm_provider

        self.artifact_manager = get_artifact_manager()
        logger.info(f"ArtifactGenerationService initialized with model: {getattr(self.llm_provider, 'model_name', 'unknown')}")

    async def generate_interview_summary(
        self,
        artifact_id: str,
        session_data: Dict[str, Any],
        **kwargs
    ) -> Artifact:
        """
        ğŸŒŸ Wu Wei: Generate comprehensive interview summary (formerly Stage 1).

        Extracts structured clinical data + parent persona from conversation transcript.
        This holistic summary captures:
        1. Clinical Data: difficulties, strengths, development
        2. Parent Persona: emotional vibe, vocabulary, communication style
        3. Contextual Assets: specific names, toys, places mentioned

        Used by: video_guidelines, video_analysis, professional_report

        Args:
            artifact_id: Artifact identifier (baseline_interview_summary, etc.)
            session_data: Session data with conversation_history, extracted_data
            **kwargs: Additional parameters from config

        Returns:
            Artifact with status 'ready' or 'error'
        """
        from app.services.llm.base import Message
        import json

        start_time = time.time()
        logger.info(f"ğŸ“ Generating interview summary: {artifact_id}")

        conversation_history = session_data.get("conversation_history", [])
        child_name = session_data.get("child_name", "×™×œ×“/×”")

        artifact = Artifact(
            artifact_id=artifact_id,
            artifact_type="analysis",
            status="generating",
            content_format="json",
            generation_inputs={
                "child_name": child_name,
                "conversation_turns": len(conversation_history)
            }
        )

        try:
            # Build transcript from conversation history
            transcript = self._build_transcript(conversation_history)

            # Build extraction prompt with holistic parent persona layer
            stage1_prompt_text = f"""# Stage 1: Extract Clinical Data & Parent Persona

## Role
You are a clinical psychologist specializing in child development interviews. You listen not just for symptoms, but for the "Voice of the Parent."

## Task
Extract and structure all information from the transcript. **Preserve parent quotes in Hebrew exactly as spoken.**

This has THREE layers:
1. **Clinical Data:** Specific difficulties, strengths, development (standard extraction)
2. **Parent Persona:** Emotional state, vocabulary, communication style
3. **Contextual Assets:** Specific names, toys, places mentioned

## Critical Instructions

### Clinical Data (Standard Extraction)
âœ… Copy exact parent quotes in Hebrew
âœ… Include at least 2-3 specific examples per difficulty
âœ… Extract strengths, development history, school info
âœ… Preserve Hebrew text exactly - spelling, grammar, colloquialisms

### Parent Persona (Holistic Layer)
âœ… **Emotional Vibe:** Diagnose parent's state (e.g., "×—×¨×“×” ×•××—×¤×©×ª ××™×©×•×¨", "××ª×•×¡×›×œ×ª ××š ××¢×©×™×ª", "×‘×”×›×—×©×”")
âœ… **Vocabulary Mirroring:** Identify specific HEBREW words parent uses for behaviors
   - If they say "×”×•× ××ª×¤×•×¦×¥" (He explodes), map "Tantrum" -> "××ª×¤×•×¦×¥"
   - If they say "×”×•× ××¨×—×£" (He hovers/zones out), map "Inattention" -> "××¨×—×£"
   - This map will be used to personalize guidelines
âœ… **Contextual Assets:** List specific items/people mentioned (e.g., "×¡×‘×ª× ×¨×—×œ", "×œ×’×• × ×™× ×’'×” ×’×•", "×”×©×˜×™×— ×”××“×•× ×‘×¡×œ×•×Ÿ")

### Rules
âŒ Don't invent information not in transcript
âŒ Don't interpret or analyze - just summarize
âŒ Don't translate Hebrew to English
âŒ Don't modify parent's words

## Interview Transcript

{transcript}
"""

            # Get structured output using Gemini's native JSON mode
            logger.info("ğŸ” Extracting clinical data + parent persona from transcript...")
            extracted_data = await self.llm_provider.chat_with_structured_output(
                messages=[Message(role="user", content=stage1_prompt_text)],
                response_schema=self._get_stage1_extraction_schema(),
                temperature=0.1
            )

            logger.info(f"âœ… Interview summary extracted: Parent Vibe = {extracted_data.get('parent_emotional_vibe', 'N/A')}")
            logger.info("=" * 80)
            logger.info("ğŸ“Š INTERVIEW SUMMARY OUTPUT (Clinical Data + Parent Persona):")
            logger.info(json.dumps(extracted_data, ensure_ascii=False, indent=2))
            logger.info("=" * 80)

            # Convert to JSON string
            content = json.dumps(extracted_data, ensure_ascii=False, indent=2)

            artifact.mark_ready(content)
            artifact.generation_duration_seconds = time.time() - start_time
            artifact.generation_model = getattr(self.llm_provider, "model_name", "unknown")

            logger.info(f"âœ… Interview summary generated in {artifact.generation_duration_seconds:.2f}s")

        except Exception as e:
            logger.error(f"âŒ Error generating interview summary: {e}", exc_info=True)
            artifact.mark_error(str(e))

        return artifact

    async def generate_video_guidelines(
        self,
        artifact_id: str,
        session_data: Dict[str, Any],
        **kwargs
    ) -> Artifact:
        """
        ğŸŒŸ Wu Wei: Generate personalized video recording guidelines from interview_summary artifact.

        Requires: baseline_interview_summary artifact (contains clinical data + parent persona)
        Generates: Video filming instructions with analyst_context for video analysis

        This method now ONLY does Stage 2 (guideline generation).
        Stage 1 (interview summary extraction) is a separate artifact.

        Args:
            artifact_id: Artifact identifier (baseline_video_guidelines, re_assessment_video_guidelines, etc.)
            session_data: Session data including artifacts dictionary
            **kwargs: Additional parameters from config (interview_summary_source)

        Returns:
            Artifact with status 'ready' or 'error'
        """
        start_time = time.time()

        logger.info(f"ğŸ¬ Generating video guidelines: {artifact_id} for child: {session_data.get('child_name', 'Unknown')}")

        # Create artifact in 'generating' state
        artifact = Artifact(
            artifact_id=artifact_id,
            artifact_type="guidelines",
            status="generating",
            content_format="markdown",
            generation_inputs={
                "child_name": session_data.get("child_name"),
                "age": session_data.get("age"),
                "primary_concerns": session_data.get("primary_concerns", []),
                "concern_details": session_data.get("concern_details"),
                "strengths": session_data.get("strengths"),
            }
        )

        try:
            # ğŸŒŸ Wu Wei: Load interview_summary artifact (required dependency)
            interview_summary_source = kwargs.get("interview_summary_source", "baseline_interview_summary")
            interview_summary_artifact = session_data.get("artifacts", {}).get(interview_summary_source)

            if not interview_summary_artifact or not interview_summary_artifact.get("exists"):
                error_msg = f"Cannot generate video guidelines: {interview_summary_source} not available"
                logger.error(f"âŒ {error_msg}")
                artifact.mark_error(error_msg)
                return artifact

            # Parse interview summary content
            import json
            if isinstance(interview_summary_artifact.get("content"), str):
                interview_summary = json.loads(interview_summary_artifact.get("content"))
            else:
                interview_summary = interview_summary_artifact.get("content")

            logger.info(f"âœ… Loaded interview summary from {interview_summary_source}")

            # Generate using LLM with interview summary
            if self.llm_provider:
                logger.info("ğŸ“ Generating video guidelines from interview summary")
                content = await self._generate_guidelines_with_llm(interview_summary)
            else:
                logger.info("ğŸ“ Using template generation (no LLM provider)")
                # Fallback to template only if no LLM provider
                child_name = session_data.get("child_name", "×™×œ×“/×”")
                age = session_data.get("age", "")
                age_str = f"{age} ×©× ×™×" if age else "×’×™×œ ×œ× ×¦×•×™×Ÿ"
                concerns = session_data.get("primary_concerns", [])
                concern_details = session_data.get("concern_details", "")

                template_content = self._generate_guidelines_template(
                    child_name=child_name,
                    age_str=age_str,
                    concerns=concerns,
                    concern_details=concern_details
                )

                # Convert to JSON format
                content = self._convert_template_to_json_format(
                    template_content,
                    child_name,
                    age_str
                )

            # Mark artifact as ready
            artifact.mark_ready(content)
            artifact.generation_duration_seconds = time.time() - start_time
            artifact.generation_model = getattr(self.llm_provider, "model_name", "template") if self.llm_provider else "template"

            logger.info(
                f"âœ… Video guidelines generated successfully in {artifact.generation_duration_seconds:.2f}s "
                f"({len(content)} chars)"
            )

        except Exception as e:
            logger.error(f"âŒ Error generating video guidelines: {e}", exc_info=True)
            artifact.mark_error(str(e))

        return artifact

    def _build_guidelines_prompt(
        self,
        child_name: str,
        age_str: str,
        concerns: list,
        concern_details: str,
        strengths: str
    ) -> str:
        """Build LLM prompt for generating video guidelines."""

        concerns_text = "\n".join(f"- {c}" for c in concerns) if concerns else "×œ× ×¦×•×™× ×• ×“××’×•×ª ×¡×¤×¦×™×¤×™×•×ª"

        return f"""
××ª×” ××•××—×” ×‘×”×¢×¨×›×” ×”×ª×¤×ª×—×•×ª×™×ª ×©×œ ×™×œ×“×™×. ×ª×¤×§×™×“×š ×œ×™×¦×•×¨ ×”× ×—×™×•×ª ×¦×™×œ×•× ××•×ª×××•×ª ××™×©×™×ª ×œ×”×•×¨×”.

**××™×“×¢ ×¢×œ ×”×™×œ×“/×”:**
- ×©×: {child_name}
- ×’×™×œ: {age_str}

**×“××’×•×ª ×¢×™×§×¨×™×•×ª:**
{concerns_text}

**×¤×¨×˜×™× × ×•×¡×¤×™× ×¢×œ ×”×“××’×•×ª:**
{concern_details if concern_details else "×œ× ×¦×•×™× ×•"}

**×—×•×–×§×•×ª:**
{strengths if strengths else "×œ× ×¦×•×™× ×•"}

**×”××©×™××”:**
×¦×•×¨ ×”× ×—×™×•×ª ×¦×™×œ×•× ××•×ª×××•×ª ××™×©×™×ª ×‘×¢×‘×¨×™×ª ×©×™×¢×–×¨×• ×œ×”×•×¨×” ×œ×¦×œ× ×¡×¨×˜×•× ×™× ×©×™×¡×™×™×¢×• ×‘×”×¢×¨×›×” ×”×ª×¤×ª×—×•×ª×™×ª.

**××‘× ×” ×”×”× ×—×™×•×ª:**

# ×”× ×—×™×•×ª ×¦×™×œ×•× ××•×ª×××•×ª ××™×©×™×ª ×¢×‘×•×¨ {child_name}

## ×œ××” ×—×©×•×‘ ×œ×¦×œ×?
[×”×¡×‘×¨ ×§×¦×¨ ×•××™×©×™ ×œ××” ×”×¡×¨×˜×•× ×™× ×™×¢×–×¨×• - ×‘×”×§×©×¨ ×œ×“××’×•×ª ×©×”×•×¢×œ×•]

## ××” ×œ×¦×œ×? 3 ××¦×‘×™× ××•××œ×¦×™×

### ××¦×‘ 1: [×©× ×”××¦×‘ - ×¨×œ×•×•× ×˜×™ ×œ×“××’×” ×”×¢×™×§×¨×™×ª]
- **××” ×œ×¦×œ×:** [×ª×™××•×¨ ×¡×¤×¦×™×¤×™]
- **×œ××” ×—×©×•×‘:** [×§×©×¨ ×œ×”×¢×¨×›×”]
- **×“×•×’××”:** [×“×•×’××” ×§×•× ×§×¨×˜×™×ª]

### ××¦×‘ 2: [××¦×‘ × ×•×¡×£ - ×¨×œ×•×•× ×˜×™ ×œ×“××’×” ××©× ×™×ª ××• ×ª×—×•× ××—×¨]
- **××” ×œ×¦×œ×:** [×ª×™××•×¨ ×¡×¤×¦×™×¤×™]
- **×œ××” ×—×©×•×‘:** [×§×©×¨ ×œ×”×¢×¨×›×”]
- **×“×•×’××”:** [×“×•×’××” ×§×•× ×§×¨×˜×™×ª]

### ××¦×‘ 3: [××¦×‘ ×”××¨××” ×—×•×–×§×•×ª ××• ×”×§×©×¨ ×›×œ×œ×™]
- **××” ×œ×¦×œ×:** [×ª×™××•×¨ ×¡×¤×¦×™×¤×™]
- **×œ××” ×—×©×•×‘:** [×§×©×¨ ×œ×”×¢×¨×›×”]
- **×“×•×’××”:** [×“×•×’××” ×§×•× ×§×¨×˜×™×ª]

## ×˜×™×¤×™× ×˜×›× ×™×™× ×œ×¦×™×œ×•×
- [3-4 ×˜×™×¤×™× ××¢×©×™×™×: ×ª××•×¨×”, ×–×•×•×™×ª, ××•×¨×š, ×¨×¢×© ×¨×§×¢]

## ××” ×œ× ×¦×¨×™×š ×œ×¦×œ×
- [2-3 ×“×‘×¨×™× ×©×œ× ×¨×œ×•×•× ×˜×™×™× ××• ×¢×œ×•×œ×™× ×œ×”×¤×¨×™×¢]

## ×”×¢×¨×•×ª ×—×©×•×‘×•×ª
- ×¡×”"×› 3 ×¡×¨×˜×•× ×™×, ×›×œ ××—×“ 2-5 ×“×§×•×ª
- ×¦×™×œ×•× ×‘×¡×‘×™×‘×” ×˜×‘×¢×™×ª ×œ×™×œ×“/×”
- ××™×Ÿ ×¦×•×¨×š ×‘×”×›× ×” ××™×•×—×“×ª ××• "×”×¤×§×”"

**×¡×’× ×•×Ÿ ×›×ª×™×‘×”:**
- ×—×, ××¢×•×“×“, ××•×¤×˜×™××™
- ×‘×¨×•×¨ ×•××¢×©×™
- ××•×ª×× ××™×©×™×ª ×œ×“××’×•×ª ×©×”×•×¢×œ×•
- ×××•×§×“ ×‘×—×•×–×§×•×ª, ×œ× ×¨×§ ×‘×“××’×•×ª
- ×‘×¢×‘×¨×™×ª ×¤×©×•×˜×” ×•×–×•×¨××ª

×¦×•×¨ ××ª ×”×”× ×—×™×•×ª ×¢×›×©×™×•:
"""

    def _generate_guidelines_template(
        self,
        child_name: str,
        age_str: str,
        concerns: list,
        concern_details: str
    ) -> str:
        """
        Generate guidelines using template (fallback when no LLM available).

        This is a reasonable default that gets personalized with child info.
        """

        # Determine primary concern area for customization
        primary_area = "×”×ª×¤×ª×—×•×ª ×›×œ×œ×™×ª"
        situation_1 = "××©×—×§ ×—×•×¤×©×™"
        situation_2 = "××™× ×˜×¨××§×¦×™×” ×—×‘×¨×ª×™×ª"
        situation_3 = "×¤×¢×™×œ×•×ª ×™×•××™×•××™×ª"

        if concerns:
            concern_lower = concerns[0].lower() if concerns else ""
            if "×©×¤×”" in concern_lower or "×ª×§×©×•×¨×ª" in concern_lower:
                primary_area = "×©×¤×” ×•×ª×§×©×•×¨×ª"
                situation_1 = "×©×™×—×” ××• ×ª×§×©×•×¨×ª"
                situation_2 = "××©×—×§ ×¢× ×¦×¢×¦×•×¢×™×"
            elif "×—×‘×¨×ª×™" in concern_lower or "×—×‘×¨×”" in concern_lower:
                primary_area = "××™× ×˜×¨××§×¦×™×” ×—×‘×¨×ª×™×ª"
                situation_1 = "××©×—×§ ×¢× ×™×œ×“×™× ××—×¨×™×"
                situation_2 = "××™× ×˜×¨××§×¦×™×” ×¢× ××‘×•×’×¨×™×"
            elif "××•×˜×•×¨×™" in concern_lower or "×ª× ×•×¢×”" in concern_lower:
                primary_area = "××™×•×× ×•×™×•×ª ××•×˜×•×¨×™×•×ª"
                situation_1 = "×¤×¢×™×œ×•×ª ×’×•×¤× ×™×ª"
                situation_2 = "××©×—×§ ×”×“×•×¨×© ×ª× ×•×¢×”"

        return f"""# ×”× ×—×™×•×ª ×¦×™×œ×•× ××•×ª×××•×ª ××™×©×™×ª ×¢×‘×•×¨ {child_name}

## ×œ××” ×—×©×•×‘ ×œ×¦×œ×?

×”×¡×¨×˜×•× ×™× ×©×ª×¦×œ×/×™ ×™×¢×–×¨×• ×œ× ×• ×œ×§×‘×œ ×ª××•× ×” ×¢×©×™×¨×” ×•××œ××” ×¢×œ {child_name}. ×‘×’×™×œ {age_str}, ×”×ª×‘×•× × ×•×ª ×‘×”×ª× ×”×’×•×™×•×ª ×˜×‘×¢×™×•×ª ×‘××¦×‘×™× ×©×•× ×™× ×™×›×•×œ×” ×œ×¡×¤×§ ×ª×•×‘× ×•×ª ×—×©×•×‘×•×ª, ×‘××™×•×—×“ ×‘×”×§×©×¨ ×œ{primary_area}.

××™×Ÿ ×¦×•×¨×š ×‘"×”×¤×§×”" - ×× ×—× ×• ×¨×•×¦×™× ×œ×¨××•×ª ××ª {child_name} ×‘×¡×‘×™×‘×” ×”×˜×‘×¢×™×ª, ×œ×”×‘×™×Ÿ ××ª ×”×—×•×–×§×•×ª ×•××ª ×”×ª×—×•××™× ×©××•×œ×™ ×¦×¨×™×›×™× ×ª××™×›×”.

## ××” ×œ×¦×œ×? 3 ××¦×‘×™× ××•××œ×¦×™×

### ××¦×‘ 1: {situation_1}

**××” ×œ×¦×œ×:**
×¦×œ×/×™ ××ª {child_name} ×‘{situation_1} - ×–×” ×™×›×•×œ ×œ×”×™×•×ª ×‘×‘×™×ª, ×‘×’×Ÿ, ××• ×‘×›×œ ××§×•× ×©× ×•×—. ×”××˜×¨×” ×”×™× ×œ×¨××•×ª ××™×š {child_name} ××ª× ×”×œ/×ª ×‘××¦×‘ ×”×–×”.

**×œ××” ×—×©×•×‘:**
××¦×‘×™× ×›××œ×” ×××¤×©×¨×™× ×œ× ×• ×œ×”×‘×™×Ÿ ××ª ×”×“×¨×š ×©×‘×” {child_name} {f"××ª×§×©×¨/×ª ×•××‘×˜×/×” ×¦×¨×›×™×" if "×©×¤×”" in primary_area else "××ª×§×©×¨/×ª ×¢× ×”×¡×‘×™×‘×”"}.

**×“×•×’××”:**
{f"×©×™×—×” ×¨×’×™×œ×” ×‘×–××Ÿ ××¨×•×—×”, ××©×—×§ ×¢× ×¦×¢×¦×•×¢×™× ×ª×•×š ×›×“×™ ×ª×§×©×•×¨×ª, ××• ×›×œ ××¦×‘ ×©×‘×• {child_name} ×¦×¨×™×š/×” ×œ×”×‘×™×¢ ××©×”×•." if "×©×¤×”" in primary_area else f"××©×—×§ ×¢× ×§×•×‘×™×•×ª, ×¤××–×œ, ××• ××©×—×§ ×—×•×¤×©×™ ×©×‘×• {child_name} ×‘×•×—×¨/×ª ××ª ×”×¤×¢×™×œ×•×ª."}

### ××¦×‘ 2: {situation_2}

**××” ×œ×¦×œ×:**
{f"××™× ×˜×¨××§×¦×™×” ×©×œ {child_name} ×¢× ××—×¨ - ×–×” ×™×›×•×œ ×œ×”×™×•×ª ××—/×•×ª, ×”×•×¨×”, ×—×‘×¨/×”, ××• ×›×œ ××“× ××—×¨." if "×—×‘×¨×ª×™" in primary_area else f"×¦×œ×/×™ ××ª {child_name} ×‘××¦×‘ ×©×•× ×” ××”×¨××©×•×Ÿ - ×œ××©×œ, ×¤×¢×™×œ×•×ª ××•×‘× ×™×ª ×™×•×ª×¨ ××• ××©×—×§ ××¡×•×’ ××—×¨."}

**×œ××” ×—×©×•×‘:**
×–×” ×¢×•×–×¨ ×œ× ×• ×œ×”×‘×™×Ÿ ××ª {f"×”××™×•×× ×•×™×•×ª ×”×—×‘×¨×ª×™×•×ª ×•×”××™× ×˜×¨××§×˜×™×‘×™×•×ª" if "×—×‘×¨×ª×™" in primary_area else "×”×’××™×©×•×ª ×•×”×”×¡×ª×’×œ×•×ª ×©×œ " + child_name} ×‘××¦×‘×™× ×©×•× ×™×.

**×“×•×’××”:**
{f"××©×—×§ ××©×•×ª×£ ×¢× ×™×œ×“ ××—×¨, ×©×™×—×” ×¢× ××‘×•×’×¨, ××• ×›×œ ××¦×‘ ×©×‘×• {child_name} ×¦×¨×™×š/×” ×œ×”×’×™×‘ ×œ××—×¨." if "×—×‘×¨×ª×™" in primary_area else f"×¤×¢×™×œ×•×ª ×™×¦×™×¨×ª×™×ª, ××©×—×§ ×¢× ×›×œ×™ ××©×—×§ ××¡×•×™×, ××• ×¤×¢×™×œ×•×ª ×©××¢× ×™×™× ×ª ××ª {child_name}."}

### ××¦×‘ 3: ×¤×¢×™×œ×•×ª ×™×•××™×•××™×ª ×˜×‘×¢×™×ª

**××” ×œ×¦×œ×:**
×›×œ ×¤×¢×™×œ×•×ª ×™×•××™×•××™×ª ×©×‘×” {child_name} ×¢×•×¡×§/×ª ×‘××•×¤×Ÿ ×˜×‘×¢×™ - ××•×›×œ, ××©×—×§ ×—×•×¤×©×™, ×”×›× ×” ×œ×©×™× ×”, ×•×›×“'.

**×œ××” ×—×©×•×‘:**
××¦×‘×™× ×˜×‘×¢×™×™× ××¨××™× ××ª {child_name} ×›×¤×™ ×©×”×•×/×”×™× ×‘×××ª, ×œ×œ× "×”×•×¤×¢×”" ××• ××¦×‘ ××œ××›×•×ª×™.

**×“×•×’××”:**
××¨×•×—×” ××©×¤×—×ª×™×ª, ××©×—×§ ×‘×—×¦×¨, ×–××Ÿ ×§×¨×™××”, ××• ×›×œ ×¨×’×¢ ×™×•××™×•××™ ×©× ×¨××” ××•×¤×™×™× ×™.

## ×˜×™×¤×™× ×˜×›× ×™×™× ×œ×¦×™×œ×•×

ğŸ“± **×–×•×•×™×ª ×¦×™×œ×•×:** ×¦×œ×/×™ ××’×•×‘×” ×¢×™× ×™×™× ×©×œ {child_name} ×›×©××¤×©×¨ - ×–×” × ×•×ª×Ÿ ×ª××•× ×” ×˜×•×‘×” ×™×•×ª×¨ ×©×œ ×”×”×ª× ×”×’×•×ª.

ğŸ’¡ **×ª××•×¨×”:** ×ª××•×¨×” ×˜×‘×¢×™×ª ×”×™× ×”×›×™ ×˜×•×‘×”. × ×¡×”/×™ ×œ×¦×œ× ×‘××•×¨ ×™×•× ××• ×‘×—×“×¨ ××•××¨.

â±ï¸ **××•×¨×š:** ×›×œ ×¡×¨×˜×•×Ÿ 2-5 ×“×§×•×ª. ××™×Ÿ ×¦×•×¨×š ×™×•×ª×¨ - ×× ×—× ×• ×¦×¨×™×›×™× "×—×œ×•×Ÿ" ×œ×¢×•×œ× ×©×œ {child_name}, ×œ× ×¡×¨×˜ ×ª×™×¢×•×“×™ ×©×œ×.

ğŸ”‡ **×¨×¢×© ×¨×§×¢:** ×›××” ×©×¤×—×•×ª - ×–×” ×¢×•×–×¨ ×œ× ×• ×œ×©××•×¢ ×•×œ×”×‘×™×Ÿ ××ª {child_name} ×˜×•×‘ ×™×•×ª×¨.

## ××” ×œ× ×¦×¨×™×š ×œ×¦×œ×

âŒ ××™×Ÿ ×¦×•×¨×š ×‘××¦×‘×™× "××‘×•×™××™×" - ×× ×—× ×• ×¨×•×¦×™× ×œ×¨××•×ª ××ª {child_name} ×‘×˜×‘×¢×™×•×ª.

âŒ ××™×Ÿ ×¦×•×¨×š ×œ×‘×§×© ×{child_name} "×œ×‘×¦×¢" ××©×™××•×ª ××¡×•×™××•×ª - ×–×” ×œ× ××‘×—×Ÿ.

âŒ ××™×Ÿ ×¦×•×¨×š ×‘×¡×¨×˜×•× ×™× ××¨×•×›×™× - 2-5 ×“×§×•×ª ××¡×¤×™×§.

## ×”×¢×¨×•×ª ×—×©×•×‘×•×ª

âœ… **×¡×”"×› 3 ×¡×¨×˜×•× ×™×** - ×›×œ ××—×“ ××¦×‘ ×©×•× ×”

âœ… **×¡×‘×™×‘×” ×˜×‘×¢×™×ª** - ×‘×™×ª, ×’×Ÿ, ×¤××¨×§ - ×›×œ ××§×•× ×©×‘×• {child_name} ××¨×’×™×©/×” ×‘× ×•×—

âœ… **××™×Ÿ ×”×›× ×” ××™×•×—×“×ª** - {child_name} ×œ× ×¦×¨×™×š/×” ×œ×”×ª×›×•× ×Ÿ ××• ×œ×”×ª×××Ÿ

âœ… **×¤×¨×˜×™×•×ª ××•×‘×˜×—×ª** - ×”×¡×¨×˜×•× ×™× × ×©××¨×™× ×‘×¦×•×¨×” ×××•×‘×˜×—×ª ×•×œ× ××©×•×ª×¤×™× ×œ×œ× ×”×¡×›××” ××¤×•×¨×©×ª

---

×× ×—× ×• ×›××Ÿ ×›×“×™ ×œ×¢×–×•×¨! ×”×¡×¨×˜×•× ×™× ×”××œ×” ×™×ª× ×• ×œ× ×• ×›×œ×™× ×œ×”×‘×™×Ÿ ××ª {child_name} ×˜×•×‘ ×™×•×ª×¨ ×•×œ×”×¦×™×¢ ×”××œ×¦×•×ª ××•×ª×××•×ª ××™×©×™×ª.
"""

    async def _generate_guidelines_with_llm(
        self,
        interview_summary: Dict[str, Any]
    ) -> str:
        """
        ğŸŒŸ Wu Wei: Generate video guidelines from interview_summary artifact (Stage 2 only).

        Previously this method did Stage 1 (extraction) + Stage 2 (generation).
        Now Stage 1 is a separate artifact (baseline_interview_summary), and this method
        only does Stage 2 using the summary.

        This holistic approach uses parent persona data to create anxiety-reducing,
        personalized guidelines that mirror the parent's language.

        Args:
            interview_summary: Interview summary artifact content (clinical data + parent persona)

        Returns:
            JSON structured video guidelines in Hebrew with embedded analyst_context for video analysis
        """
        from app.services.llm.base import Message
        import json

        logger.info("ğŸ“ Generating empathetic video guidelines from interview summary")
        logger.info(f"âœ… Using existing interview summary: Parent Vibe = {interview_summary.get('parent_emotional_vibe', 'N/A')}")

        # Extract persona data for personalization from interview_summary
        parent_vibe = interview_summary.get('parent_emotional_vibe', '×œ× ×–×•×”×”')

        # Convert vocab_map from array format to dict for easier use
        vocab_map_array = interview_summary.get('specific_vocabulary_map', [])
        vocab_map = {item['clinical_term']: item['parent_word'] for item in vocab_map_array} if vocab_map_array else {}

        context_assets = interview_summary.get('family_context_assets', [])
        child_name = interview_summary.get('child', {}).get('name', '×”×™×œ×“/×”')

        json_input = json.dumps(interview_summary, ensure_ascii=False, indent=2)
        stage2_prompt_text = f"""# Stage 2: Generate Empathetic Video Guidelines (Hebrew)

## Role
You are "Chitta," a supportive child development expert writing directly to the Israeli parent in Hebrew.
**Your Goal:** Lower their anxiety while getting high-quality video data for analysis.

## Parent Context (Use This!)
**Parent Vibe:** {parent_vibe}
**Child Name:** {child_name}
**Parent's Vocabulary:** {json.dumps(vocab_map, ensure_ascii=False)}
**Context Assets:** {json.dumps(context_assets, ensure_ascii=False)}

## Critical Instructions for Writing Guidelines

### 1. CONCRETE & SIMPLE (Lower Cognitive Load)
âŒ BAD: "×©×—×§×• ××©×—×§ ×¢× ×—×•×§×™× ×•×ª×•×¨×•×ª"
âœ… GOOD: "×©×‘×• ×œ×™×“ ×”×©×•×œ×—×Ÿ ×‘××˜×‘×—, ×‘×—×¨×• ××©×—×§ ×¡×•×œ××•×ª ×•×—×‘×œ×™× ××• ×–×™×›×¨×•×Ÿ (×§×œ×¤×™×). ×©×—×§×• ×™×—×“ 5 ×“×§×•×ª."

âŒ BAD: "×¦×œ××• ×¤×¢×™×œ×•×ª ×™×¦×™×¨×ª×™×ª"
âœ… GOOD: "×”× ×™×—×• ×“×£ A4 ×•×¢×¤×¨×•× ×•×ª ×¦×‘×¢×•× ×™×™× ×¢×œ ×”×©×•×œ×—×Ÿ. ×‘×§×©×• ××× ×” ×œ×¦×™×™×¨ ××©×¤×—×” ××• ×‘×™×ª. ×¦×œ××• ××•×ª×” ×‘×–××Ÿ ×”×¦×™×•×¨."

### 2. The "Sandwich" Rationale (Emotional Regulation for Parents)
The `rationale_for_parent` must follow this structure in Hebrew:
1. **Validate:** "×©××¢×ª×™ ×›××” ×”×‘×§×¨×™× ×©×œ×›× ×¢××•×¡×™×..." (I heard how exhausting mornings are...)
2. **Explain:** "×¦×™×œ×•× ×©×œ ×¨×’×¢ ×›×–×” ×™×¢×–×•×¨ ×œ× ×• ×œ×”×‘×™×Ÿ ×‘×“×™×•×§ ××” ×”×˜×¨×™×’×¨..." (Filming this helps us see the trigger...)
3. **Reassure:** "××œ ×ª×“××’×• ×'×œ×¡×“×¨' ××ª ×”××¦×‘ ×œ××¦×œ××”. ×× ×—× ×• ×¨×•×¦×™× ×œ×¨××•×ª ××ª ×”×—×™×™× ×”×××™×ª×™×™×." (Don't worry about fixing it...)

For strength_baseline scenarios, emphasize validation and completeness:
- "×¨××™×ª×™ ×©×”×•× ××¦×˜×™×™×Ÿ ×‘... (I saw he excels at...)
- "×¡×¨×˜×•×Ÿ ×©×œ ×”×¨×’×¢×™× ×”×˜×•×‘×™× ×™×¢×–×•×¨ ×œ× ×• ×œ×¨××•×ª ××” ×¢×•×‘×“ ×•×œ×‘× ×•×ª ×¢×œ ×–×”..."
- "×–×” ×—×œ×§ ×—×©×•×‘ ××”×ª××•× ×” ×”×©×œ××”"

### 3. Vocabulary Mirroring (CRITICAL)
Use the **Vocabulary Map** above.
- If parent uses "×”×ª×§×£" (Attack), YOU use "×”×ª×§×£" in instructions
- If parent uses "××¨×—×£" (Zones out), YOU use "××¨×—×£"
- Don't use clinical jargon unless parent used it

### 4. Use Contextual Assets
- Do NOT say: "×©×—×§×• ×¢× ×¦×¢×¦×•×¢" (Play with a toy)
- DO say: "×©×‘×• ×¢×œ {context_assets[0] if context_assets else '×”×©×˜×™×—'} ×¢× ×”{context_assets[1] if len(context_assets) > 1 else '×¦×¢×¦×•×¢ ×”××”×•×‘'}..."
- Make `example_situations` specific to their mentioned environment

### 5. Focus Points (focus_points) are INTERNAL ONLY
These are for YOU to analyze the video later. NOT for parents to worry about while filming.
Write them as clinical observation notes: "×”×× × ×¨××™×ª ×ª× ×•×¢×ª ×™×ª×¨?", "×›××” ×–××Ÿ ××—×–×™×§×” ×§×©×‘?"

### 6. Example Situations Must Be Concrete
âŒ "×–××Ÿ ××©×—×§ ×—×•×¤×©×™"
âœ… "×‘×¡×œ×•×Ÿ ××—×¨×™ ×”×¦×”×¨×™×™×, ×¢× ×”×¦×¢×¦×•×¢×™× ×©×™×© ×œ×” ×‘××¨×•×Ÿ"

## Task
1. Identify 1-2 main reported difficulties from the parent's descriptions
2. Infer 1-2 additional areas to check (comorbidities) based on clinical framework below
3. **INCLUDE 1 strength/baseline scenario** - Show the child when regulated and thriving
4. Create **EXACTLY 3-4 video filming guidelines** in Hebrew (minimum 3, maximum 5)

**CRITICAL REQUIREMENT:** You MUST generate at least 3 complete video_guidelines entries:
- At least 1 must be category: "reported_difficulty"
- At least 1 must be category: "strength_baseline" (REQUIRED - strengths-based approach)
- Optionally 1-2 can be category: "comorbidity_check"

## Field Usage by Category

### For "reported_difficulty" and "comorbidity_check":
- difficulty_area: Problem area in Hebrew (e.g., "×§×©×‘ ×‘××©×—×§×™×", "×•×™×¡×•×ª ×¨×’×©×™")

### For "strength_baseline":
- difficulty_area: Strength domain in Hebrew (e.g., "××©×—×§ ×¢×¦×××™", "×™×¦×™×¨×ª×™×•×ª", "××™× ×˜×¨××§×¦×™×” ×—×‘×¨×ª×™×ª")

Each guideline must have:
- Unique id (1, 2, 3, etc.)
- Category (reported_difficulty, comorbidity_check, or strength_baseline)
- difficulty_area: Context-sensitive (problem area OR strength domain)
- title: Short title in Hebrew (3-5 words)
- instruction: CONCRETE, SIMPLE filming instruction using parent's vocabulary
- example_situations: 2-3 CONCRETE situations using their mentioned context
- duration_suggestion: Clear time estimate ("5-7 ×“×§×•×ª", "×¢×“ ×©×”×™× ×××‘×“×ª ×¢× ×™×™×Ÿ")
- focus_points: 2-4 INTERNAL analysis points (clinical observation notes)
- rationale_for_parent: "Sandwich" structure (Validate-Explain-Reassure) in Hebrew

## Clinical Comorbidity Framework

**ADHD/Attention** â†’ Check: Sensory regulation, fine motor, emotional regulation
**Learning difficulties** â†’ Check: Visual perception, auditory processing, working memory
**Social/communication** â†’ Check: Symbolic play, restricted interests, repetitive behaviors
**Emotional outbursts** â†’ Check: Sensory triggers, language comprehension, frustration tolerance
**Language delays** â†’ Check: Social interactions, imaginative play, non-verbal communication

## Structured Data from Interview

{json_input}

## Example of GOOD Difficulty Guideline

{{
  "id": 1,
  "category": "reported_difficulty",
  "difficulty_area": "×§×©×‘ ×‘××©×—×§×™×",
  "title": "××©×—×§ ×§×•×¤×¡×” ×‘××˜×‘×—",
  "instruction": "×©×‘×• ×™×—×“ ×œ×™×“ ×©×•×œ×—×Ÿ ×”××˜×‘×—. ×‘×—×¨×• ××©×—×§ ×§×•×¤×¡×” ×¤×©×•×˜ ×©×”×™×œ×“×” ××›×™×¨×” - ×¡×•×œ××•×ª ×•×—×‘×œ×™×, ×“××§×”, ××• ×–×™×›×¨×•×Ÿ. ×©×—×§×• ×™×—×“ 5-7 ×“×§×•×ª, ××• ×¢×“ ×©×”×™× ×××‘×“×ª ×¢× ×™×™×Ÿ. ×× ×”×™× ×§××” ××• ××¤×¡×™×§×” - ×–×” ×‘×¡×“×¨, ×”××©×™×›×• ×œ×¦×œ× ×¢×•×“ ×“×§×” ×›×“×™ ×œ×¨××•×ª ×œ××Ÿ ×”×™× ×”×•×œ×›×ª.",
  "example_situations": [
    "××—×¨×™ ××¨×•×—×ª ×¦×”×¨×™×™×, ×œ×™×“ ×©×•×œ×—×Ÿ ×”××˜×‘×—",
    "×‘×¢×¨×‘ ×œ×¤× ×™ ×”×××‘×˜×™×”, ×‘×¡×œ×•×Ÿ ×¢×œ ×”×©×˜×™×—"
  ],
  "duration_suggestion": "5-7 ×“×§×•×ª",
  "focus_points": [
    "×›××” ×–××Ÿ ×”×™× ××—×–×™×§×” ×§×©×‘ ×œ×¤× ×™ ×”×ª× ×•×¢×” ×”×¨××©×•× ×” ××”×›×™×¡×?",
    "××” ×”×™× ×¢×•×©×” ×‘×–××Ÿ ×”×”××ª× ×” ×œ×ª×•×¨ - ××¡×ª×›×œ×ª, ×–×–×”, ××“×‘×¨×ª?",
    "××™×š ×”×™× ××’×™×‘×” ×›×©××–×›×™×¨×™× ×œ×” ×œ×—×–×•×¨ ×œ××©×—×§?"
  ],
  "rationale_for_parent": "×©××¢×ª×™ ×©×”×™× ××ª×§×©×” ×œ×—×›×•×ª ×œ×ª×•×¨×” ×‘××©×—×§×™× ×•×©'×”××—×©×‘×•×ª ×©×œ×” ×‘×•×¨×—×•×ª' - ×–×” ×‘×˜×— ×××ª×’×¨ ×‘×©×‘×™×œ×›×. ×¡×¨×˜×•×Ÿ ×–×” ×™×¢×–×•×¨ ×œ× ×• ×œ×¨××•×ª ×‘×“×™×•×§ ××™×š ×–×” × ×¨××” - ×”×× ×–×” ×§×•×©×™ ×‘×‘×œ×™××”, ×§×•×©×™ ×‘×”××ª× ×”, ××• ××©×”×• ××—×¨. ××œ ×ª×“××’×• ×œ×’×¨×•× ×œ××©×—×§ ×œ×”×™×¨××•×ª '××•×©×œ×' - ×× ×—× ×• ×¨×•×¦×™× ×œ×¨××•×ª ××ª ×”××¦×™××•×ª. ×–×” ×™×›×•×•×Ÿ ××•×ª× ×• ××™×š ×œ×¢×–×•×¨ ×œ×” ×‘×›×™×ª×” ×'."
}}

## Example of GOOD Strength Guideline

{{
  "id": 3,
  "category": "strength_baseline",
  "difficulty_area": "××©×—×§ ×™×¦×™×¨×ª×™",
  "title": "×–××Ÿ ×™×¦×™×¨×” ×—×•×¤×©×™×ª",
  "instruction": "×ª× ×• ×œ×” ×“×£ ×¨×™×§ ×•×¦×‘×¢×™×, ×•×ª× ×• ×œ×” ×œ×¦×™×™×¨ ××• ×œ×™×¦×•×¨ ××” ×©×”×™× ×¨×•×¦×”. ×¦×œ××• 5 ×“×§×•×ª ×©×œ ×™×¦×™×¨×” ×—×•×¤×©×™×ª.",
  "example_situations": [
    "××—×¨ ×”×¦×”×¨×™×™× ×‘×¤×™× ×ª ×”×™×¦×™×¨×”",
    "×‘×©×•×œ×—×Ÿ ×”××˜×‘×— ×¢× ×¢×¤×¨×•× ×•×ª ×¦×‘×¢×•× ×™×™×"
  ],
  "duration_suggestion": "5 ×“×§×•×ª",
  "focus_points": [
    "×›××” ×–××Ÿ ×”×™× × ×©××¨×ª ×××•×§×“×ª ×‘×¤×¢×™×œ×•×ª?",
    "××™×š ×”×™× ××ª××•×“×“×ª ×¢× ×”×—×•××¨×™×?",
    "×”×× ×™×© ×™×¦×™×¨×ª×™×•×ª ×•×“××™×•×Ÿ?"
  ],
  "rationale_for_parent": "×©××¢×ª×™ ×©×”×™× ××•×”×‘×ª ×œ×¦×™×™×¨ ×•×œ×™×¦×•×¨ - ×–×” ×—×•×–×§×” ×××™×ª×™×ª! ×¡×¨×˜×•×Ÿ ×©×œ ×”×¨×’×¢×™× ×©×‘×”× ×”×™× ×©×§×•×¢×” ×‘×™×¦×™×¨×” ×™×¢×–×•×¨ ×œ× ×• ×œ×”×‘×™×Ÿ ××” ×¢×•×‘×“ ×˜×•×‘ ×•×œ×‘× ×•×ª ×¢×œ ×–×”. ×”×ª××•× ×” ×”×©×œ××” ×›×•×œ×œ×ª ×’× ××ª ××” ×©×”×™× ×¢×•×©×” × ×”×“×¨."
}}
"""

        # Get structured output using Gemini's native JSON mode
        try:
            guidelines_data = await self.llm_provider.chat_with_structured_output(
                messages=[Message(role="user", content=stage2_prompt_text)],
                response_schema=self._get_stage2_guidelines_schema(),
                temperature=0.7
            )
            logger.info(f"âœ… Stage 2 complete: Generated guidelines using native JSON mode")
            logger.info("=" * 80)
            logger.info("ğŸ“Š STAGE 2 OUTPUT (Generated Guidelines):")
            logger.info(json.dumps(guidelines_data, ensure_ascii=False, indent=2))
            logger.info("=" * 80)

            # CRITICAL VALIDATION: Gemini schema constraints are HINTS, not enforced!
            # We must validate the output ourselves to ensure it meets requirements
            video_guidelines = guidelines_data.get("video_guidelines", [])
            if len(video_guidelines) < 3:
                error_msg = f"Validation failed: Generated only {len(video_guidelines)} guidelines, minimum 3 required"
                logger.error(f"âŒ {error_msg}")
                logger.error(f"Guidelines data: {json.dumps(guidelines_data, ensure_ascii=False)[:500]}")
                raise ValueError(error_msg)

            logger.info(f"âœ… Validation passed: {len(video_guidelines)} guidelines generated")

        except Exception as e:
            logger.error(f"âŒ Stage 2 failed: {e}")
            raise ValueError(f"Failed to generate guidelines: {e}")

        # Convert JSON to markdown format for parent
        markdown_content = self._convert_guidelines_json_to_markdown(guidelines_data)

        # Also transform to component-compatible format for frontend
        component_format = self._transform_to_component_format(guidelines_data)

        # Enrich with analyst context for video analysis (Bridge to Observation Agent)
        guidelines_list = guidelines_data.get("video_guidelines", [])
        for idx, scenario in enumerate(component_format.get("scenarios", [])):
            if idx < len(guidelines_list):
                guideline = guidelines_list[idx]
                scenario["analyst_context"] = {
                    "instruction_given_to_parent": scenario.get("what_to_film", ""),
                    "internal_focus_points": guideline.get("focus_points", []),
                    "parent_persona_data": {
                        "emotional_vibe": extracted_data.get("parent_emotional_vibe", ""),
                        "vocabulary_map": extracted_data.get("specific_vocabulary_map", []),  # Array format
                        "context_assets": extracted_data.get("family_context_assets", [])
                    },
                    "clinical_goal": guideline.get("category", "")
                }

        logger.info(f"âœ… Holistic generation complete: {len(markdown_content)} chars markdown")
        logger.info(f"ğŸ“Š Component format: {len(component_format.get('scenarios', []))} scenarios generated")
        logger.info(f"ğŸ¯ Analyst context embedded in all scenarios for video analysis")
        logger.debug(f"Guidelines data keys: {guidelines_data.keys()}")
        logger.debug(f"Video guidelines count: {len(guidelines_data.get('video_guidelines', []))}")

        # Return structured format (not markdown) for the component
        return json.dumps(component_format, ensure_ascii=False)

    def _build_transcript(self, conversation_history: list) -> str:
        """Build interview transcript from conversation history."""
        transcript_lines = []

        for turn in conversation_history:
            role = turn.get("role", "unknown")
            content = turn.get("content", "")

            if role == "user":
                transcript_lines.append(f"×”×•×¨×”: {content}")
            elif role == "assistant":
                transcript_lines.append(f"Chitta: {content}")

        return "\n\n".join(transcript_lines)

    def _build_stage1_extraction_prompt(self, transcript: str) -> str:
        """Build Stage 1 prompt for extracting structured data from transcript."""
        return f"""# Chitta Stage 1: JSON Extraction (English Prompt)

## Role
You are a clinical data analyst specializing in child development interviews. Your task is to extract and structure information from parent interviews into JSON format.

## Task
Read the interview transcript and produce a structured JSON with all relevant information. **Preserve all parent quotes in Hebrew exactly as spoken.**

## JSON Schema

```json
{{
  "child": {{
    "name": "",
    "age_years": 0,
    "age_months": 0,
    "gender": ""
  }},

  "main_concern": "Main presenting problem in parent's own words (Hebrew)",

  "difficulties": [
    {{
      "area": "attention|behavior|communication|sensory|emotional|social|learning|motor|sleep|eating|visual|auditory",
      "description": "Detailed description in parent's words (Hebrew)",
      "specific_examples": [
        {{
          "when_where": "When and where it occurs (Hebrew)",
          "behavior": "Exact behavior observed - what child does/says (Hebrew)",
          "trigger": "What triggers it, if known (Hebrew)",
          "frequency": "How often and intensity (Hebrew)",
          "duration": "How long each episode lasts (Hebrew)"
        }}
      ],
      "duration_since_onset": "How long the difficulty has existed (Hebrew)",
      "impact_child": "Impact on child's functioning (Hebrew)",
      "impact_family": "Impact on parent/family (Hebrew)"
    }}
  ],

  "strengths": {{
    "likes": ["What child likes doing (Hebrew)"],
    "good_at": ["What child is good at (Hebrew)"],
    "positives": "Positive observations (Hebrew)"
  }},

  "development": {{
    "pregnancy_birth": "Pregnancy/birth complications if any (Hebrew)",
    "milestones": "Developmental delays if any (Hebrew)",
    "medical": "Chronic conditions/medications/medical events (Hebrew)"
  }},

  "school": {{
    "type": "Preschool/school/special ed (Hebrew)",
    "adjustment": "How child is doing (Hebrew)",
    "support": "Support services received (Hebrew)"
  }},

  "history": {{
    "previous_diagnosis": "Previous diagnoses (Hebrew)",
    "previous_treatment": "Previous treatments and their effectiveness (Hebrew)",
    "family_history": "Similar difficulties in family (Hebrew)"
  }},

  "parent_perspective": {{
    "childs_experience": "What parent thinks child is experiencing (Hebrew)",
    "what_tried": "What parent tried and what worked/didn't (Hebrew)",
    "hopes": "Parent's hopes and expectations (Hebrew)"
  }}
}}
```

## Working Rules

### DO:
âœ… Copy exact parent quotes in Hebrew (use quotation marks for direct quotes)
âœ… Include **at least 2-3 specific examples** per difficulty
âœ… If information is missing â†’ leave `null` or empty string
âœ… Maintain valid JSON syntax (critical!)
âœ… Be concise but comprehensive
âœ… Preserve Hebrew text exactly - including spelling, grammar, colloquialisms

### DON'T:
âŒ Don't invent information not in transcript
âŒ Don't interpret or analyze - just summarize
âŒ Don't add clinical comments
âŒ Don't translate Hebrew to English
âŒ Don't modify parent's words
âŒ Don't add fields not in schema

## Output Format
Return **ONLY** the JSON, no additional text.

Make sure:
- JSON is valid (check syntax carefully)
- All strings are properly escaped
- Hebrew text is preserved
- No trailing commas

---

## Input

The interview transcript will appear after `[TRANSCRIPT]`:

[TRANSCRIPT]
{transcript}
"""

    def _build_stage2_guidelines_prompt(self, extracted_data: dict) -> str:
        """Build Stage 2 prompt for generating guidelines from structured data."""
        import json
        json_input = json.dumps(extracted_data, ensure_ascii=False, indent=2)

        return f"""# Chitta Stage 2: Video Guidelines Generation (English Prompt)

## Role
You are a clinical expert in child development. You receive structured JSON from a parent interview and generate smart video filming guidelines.

## Task
1. Identify 1-2 main reported difficulties
2. Infer 1-2 additional areas to check (comorbidities)
3. Create 3-4 clear, sensitive filming guidelines
4. Output as JSON with Hebrew text for parents

---

## Clinical Framework

### Common Comorbidities:

**ADHD (attention/hyperactivity)** â†’ Check:
- Sensory regulation (noise, touch, light sensitivity)
- Fine motor coordination (writing, cutting)
- Emotional regulation (frustration, transitions)

**Learning difficulties (reading/writing/math)** â†’ Check:
- Eye tracking and visual perception
- Auditory processing and comprehension
- Working memory

**Social/communication difficulties** â†’ Check:
- Symbolic play and imagination
- Restricted interests
- Repetitive behaviors/movements
- Unusual sensory responses

**Emotional outbursts/regulation** â†’ Check:
- Sensory triggers
- Language comprehension (complex instructions)
- Parent-child dynamics

**Language delays** â†’ Check:
- Social interactions
- Imaginative play
- Non-verbal communication

---

## Output JSON Schema

```json
{{
  "parent_greeting": {{
    "parent_name": "×©× ×”×”×•×¨×” (if available from extracted data, else '×”×•×¨×” ×™×§×¨')",
    "child_name": "USE CHILD_NAME FROM EXTRACTED DATA ABOVE - ×©× ×”×™×œ×“/×” ××”× ×ª×•× ×™× ×©××¢×œ",
    "opening_message": "×¤×¡×§×ª ×¤×ª×™×—×” ××œ××” ×‘×¢×‘×¨×™×ª - ×ª×•×“×” ×¢×œ ×”×©×™×—×”, ×”×¡×‘×¨ ×§×¦×¨ ×¢×œ ××˜×¨×ª ×”×¡×¨×˜×•× ×™×"
  }},

  "general_filming_tips": [
    "×¦×™×œ×•× ×˜×‘×¢×™ - ××œ ×ª×‘×§×©×• ××”×™×œ×“ ×œ×¢×©×•×ª ××©×”×• ××™×•×—×“",
    "1-2 ×“×§×•×ª ×œ×›×œ ×¡×¨×˜×•×Ÿ",
    "××™×§×•×“ ×¢×œ ×¤× ×™ ×•×’×•×£ ×”×™×œ×“",
    "×¡×•×“×™×•×ª ××œ××” - ×”×›×œ × ×©××¨ ×‘××¤×œ×™×§×¦×™×” ×‘×œ×‘×“"
  ],

  "video_guidelines": [
    {{
      "id": 1,
      "category": "reported_difficulty",
      "difficulty_area": "attention|behavior|communication|sensory|emotional|social|learning|motor",
      "title": "×›×•×ª×¨×ª ×§×¦×¨×” ×•×ª×™××•×¨×™×ª ×‘×¢×‘×¨×™×ª",
      "instruction": "×”× ×—×™×™×ª ×¦×™×œ×•× ××¤×•×¨×˜×ª ×•×¡×¤×¦×™×¤×™×ª ×‘×¢×‘×¨×™×ª - ××” ×œ×¦×œ×, ××™×š, ×‘××™×–×” ××¦×‘",
      "example_situations": [
        "×“×•×’××” ×§×•× ×§×¨×˜×™×ª 1 ×œ××¦×‘ ×˜×‘×¢×™ ×œ×¦×œ×",
        "×“×•×’××” ×§×•× ×§×¨×˜×™×ª 2"
      ],
      "duration_suggestion": "1-2 ×“×§×•×ª",
      "focus_points": [
        "×¢×œ ××” ×œ×”×ª××§×“ ×‘×¦×™×œ×•× - × ×§×•×“×” 1",
        "× ×§×•×“×” 2"
      ]
    }},
    {{
      "id": 2,
      "category": "reported_difficulty",
      "difficulty_area": "...",
      "title": "...",
      "instruction": "...",
      "example_situations": ["..."],
      "duration_suggestion": "1-2 ×“×§×•×ª",
      "focus_points": ["..."]
    }},
    {{
      "id": 3,
      "category": "comorbidity_check",
      "related_to": "attention|behavior|...",
      "suspected_area": "sensory|motor|social|...",
      "title": "×›×•×ª×¨×ª ×¨×’×™×©×” ×‘×¢×‘×¨×™×ª",
      "instruction": "×”× ×—×™×™×ª ×¦×™×œ×•× ×¢× × ×™×¡×•×— ×¨×š ×•××–××™×Ÿ ×‘×¢×‘×¨×™×ª. ×”×©×ª××© ×‘×‘×™×˜×•×™×™× ×›××•: '×›×“×™ ×œ×”×©×œ×™× ××ª ×”×ª××•× ×”', '×œ×¤×¢××™× X ×§×©×•×¨ ×’× ×œ-Y', '×× ×ª×©×™××• ×œ×‘ ×œ...'",
      "rationale_for_parent": "×”×¡×‘×¨ ×§×¦×¨ ×•×œ×-×˜×›× ×™ ×œ××” ×–×” ×¨×œ×•×•× ×˜×™ (××•×¤×¦×™×•× ×œ×™)",
      "example_situations": ["×“×•×’××” ×§×•× ×§×¨×˜×™×ª"],
      "duration_suggestion": "1-2 ×“×§×•×ª",
      "focus_points": ["..."]
    }},
    {{
      "id": 4,
      "category": "comorbidity_check",
      "related_to": "...",
      "suspected_area": "...",
      "title": "...",
      "instruction": "...",
      "rationale_for_parent": "...",
      "example_situations": ["..."],
      "duration_suggestion": "1-2 ×“×§×•×ª",
      "focus_points": ["..."]
    }}
  ],

  "closing_message": "×ª×•×“×” ×¨×‘×” ×¢×œ ×©×™×ª×•×£ ×”×¤×¢×•×œ×”, ×–×” ×™×¢×–×•×¨ ×œ× ×• ×œ×”×‘×™×Ÿ ××ª [child_name] ×œ×¢×•××§!"
}}
```

---

## Guidelines Creation Process

### Step 1: Analyze the JSON
```
What are the 2 most prominent, clearly described difficulties?
â†’ These become guidelines #1-2 (category: "reported_difficulty")

What comorbidities are likely based on the reported difficulties?
â†’ Select 1-2 additional areas that are clinically suspicious
â†’ These become guidelines #3-4 (category: "comorbidity_check")
```

### Step 2: Build Each Guideline

**For each guideline:**
1. **Clear title** - what to film (Hebrew)
2. **Specific instruction** - how to film, in what context (Hebrew)
3. **Concrete examples** - natural situations to capture (Hebrew)
4. **Focus points** - what behaviors/aspects to capture (Hebrew)

**Phrasing rules:**
- ğŸ¯ Action-oriented, specific instructions, not general descriptions
- ğŸ¤ Containing, non-judgmental tone
- ğŸ” For comorbidity checks: gentle, inviting language
- ğŸ“ Maximum 4 guidelines total (3 is often ideal)

---

## Critical Rules

### âœ… DO:
- Use child's name throughout the Hebrew text
- Provide specific instructions ("film during homework" not "film learning")
- Give concrete examples ("when doing puzzles, building blocks")
- Keep tone warm and collaborative
- Limit to 3-4 guidelines (don't overwhelm parent)
- Return valid JSON (check syntax!)

### âŒ DON'T:
- Never suggest diagnoses ("check for autism")
- Don't use professional jargon
- Don't overwhelm parent (max 4 guidelines)
- Don't be judgmental or alarming
- Don't create vague instructions
- Don't output anything except the JSON

---

## Sensitive Phrasing Examples (for comorbidity checks)

**Good examples (use these patterns):**
- "×›×“×™ ×œ×”×©×œ×™× ××ª ×”×ª××•× ×” ×”×¨×—×‘×” ×‘×™×•×ª×¨, × ×©××— ×œ×¨××•×ª..."
- "×œ×¤×¢××™× ×§×©×™×™× ×‘-X ×§×©×•×¨×™× ×’× ×œ-Y. ×× ×ª×©×™××• ×œ×‘ ×œ-Z, ×™×”×™×” ××•×¢×™×œ ×œ×¨××•×ª..."
- "××¤×™×œ×• ×× ×–×” ×œ× × ×¨××” ×›×‘×¢×™×” ××¨×›×–×™×ª, ×–×” ×™×¢×–×•×¨ ×œ× ×• ×œ×”×‘×™×Ÿ..."
- "×›×“×™ ×©× ×•×›×œ ×œ×ª×ª ××ª ×”××¢× ×” ×”××“×•×™×§ ×‘×™×•×ª×¨, × ×©××— ×’× ×œ×¨××•×ª..."

**Bad examples (avoid these):**
- "×‘×“×§×• ×× ×”×™×œ×“ ××¨××” ×¡×™×× ×™ ××•×˜×™×–×"
- "×× ×—× ×• ×—×•×©×‘×™× ×©×™×© ×‘×¢×™×” ×’× ×‘-X"
- "×–×” ×™×›×•×œ ×œ×”×™×•×ª ×—××•×¨"

---

## Output Format
Return **ONLY** the JSON, no additional text.

Ensure:
- Valid JSON syntax
- All Hebrew strings properly escaped
- Exactly 3-4 video_guidelines (not more, not less)
- At least 1 reported_difficulty category
- At least 1 comorbidity_check category (unless only 1 difficulty was reported)
- Professional yet warm Hebrew text

---

## Input

The extracted JSON will appear here:

```json
{json_input}
```
"""

    def _convert_guidelines_json_to_markdown(self, guidelines_data: dict) -> str:
        """Convert guidelines JSON to markdown format for parents."""
        md = []

        # Parent greeting
        greeting = guidelines_data.get("parent_greeting", {})
        child_name = greeting.get("child_name", "")
        opening = greeting.get("opening_message", "")

        md.append(f"# ×”× ×—×™×•×ª ×¦×™×œ×•× ××•×ª×××•×ª ××™×©×™×ª ×¢×‘×•×¨ {child_name}\n")
        md.append(f"{opening}\n")

        # General tips
        md.append("## ×˜×™×¤×™× ×›×œ×œ×™×™× ×œ×¦×™×œ×•×\n")
        for tip in guidelines_data.get("general_filming_tips", []):
            md.append(f"- {tip}")
        md.append("")

        # Video guidelines
        md.append("## ××” ×œ×¦×œ×?\n")
        for guideline in guidelines_data.get("video_guidelines", []):
            gid = guideline.get("id", "")
            title = guideline.get("title", "")
            instruction = guideline.get("instruction", "")
            examples = guideline.get("example_situations", [])
            focus = guideline.get("focus_points", [])
            duration = guideline.get("duration_suggestion", "1-2 ×“×§×•×ª")

            md.append(f"### ×¡×¨×˜×•×Ÿ {gid}: {title}\n")
            md.append(f"**×”× ×—×™×”:** {instruction}\n")

            if examples:
                md.append("**×“×•×’×××•×ª ×œ××¦×‘×™×:**")
                for ex in examples:
                    md.append(f"- {ex}")
                md.append("")

            if focus:
                md.append("**×¢×œ ××” ×œ×”×ª××§×“:**")
                for f in focus:
                    md.append(f"- {f}")
                md.append("")

            md.append(f"**××©×š:** {duration}\n")

        # Closing
        closing = guidelines_data.get("closing_message", "")
        md.append(f"---\n\n{closing}")

        return "\n".join(md)

    def _transform_to_component_format(self, guidelines_data: dict) -> dict:
        """
        Transform LLM-generated JSON to VideoGuidelinesView component format.

        LLM Format:
        - video_guidelines: [{ id, title, instruction, example_situations, focus_points, rationale_for_parent }]
        - general_filming_tips: [...]
        - parent_greeting.opening_message

        Component Format:
        - scenarios: [{ title, context, what_to_film, what_to_look_for, duration, why_matters }]
        - general_tips: [...]
        - introduction: string

        IMPORTANT: Field usage for frontend display:
        - why_matters (rationale_for_parent): MUST be displayed to parents in ALL scenarios as "×œ××” ×–×” ×—×©×•×‘:"
        - what_to_look_for (focus_points): INTERNAL USE ONLY - for team analysis, NOT for parent display
        """
        video_guidelines = guidelines_data.get("video_guidelines", [])
        parent_greeting = guidelines_data.get("parent_greeting", {})

        # Transform video_guidelines to scenarios
        scenarios = []
        for guideline in video_guidelines:
            # Build context from difficulty area (short label, not the full rationale)
            # The full rationale goes in why_matters to avoid duplication
            context = guideline.get("difficulty_area", f"×ª×¨×—×™×© {guideline.get('id')}")

            # Build scenario object
            scenario = {
                "title": guideline.get("title", ""),
                "context": context,
                "what_to_film": guideline.get("instruction", ""),
                "what_to_look_for": guideline.get("focus_points", []),  # Internal use - not for display
                "duration": guideline.get("duration_suggestion", "1-2 ×“×§×•×ª"),
                "why_matters": guideline.get("rationale_for_parent", "")  # Always include for ALL scenarios
            }

            # Add example situations as additional context
            examples = guideline.get("example_situations", [])
            if examples:
                scenario["examples"] = examples

            scenarios.append(scenario)

        return {
            "introduction": parent_greeting.get("opening_message", ""),
            "scenarios": scenarios,
            "general_tips": guidelines_data.get("general_filming_tips", []),
            "estimated_duration": "1-2 ×“×§×•×ª ×œ×¡×¨×˜×•×Ÿ",
            "child_name": parent_greeting.get("child_name", "")
        }

    def _strip_markdown_code_blocks(self, text: str) -> str:
        """
        Strip markdown code blocks from LLM output.
        LLMs often wrap JSON in ```json ... ``` or ``` ... ``` blocks.

        Args:
            text: Raw text from LLM that may contain markdown code blocks

        Returns:
            Cleaned text with markdown wrappers removed
        """
        import re

        if not text:
            return text

        text = text.strip()

        # Try multiple patterns to handle different markdown formats
        patterns = [
            # Pattern 1: ```json\n...\n```
            r'^```json\s*\n(.*?)\n```$',
            # Pattern 2: ```\n...\n```
            r'^```\s*\n(.*?)\n```$',
            # Pattern 3: ``` json\n...\n``` (space after backticks)
            r'^```\s+json\s*\n(.*?)\n```$',
            # Pattern 4: More permissive - any backticks with optional json
            r'```(?:json)?\s*(.*?)\s*```',
        ]

        for pattern in patterns:
            match = re.search(pattern, text, re.DOTALL)
            if match:
                extracted = match.group(1).strip()
                if extracted:  # Only return if we got non-empty content
                    return extracted

        # No markdown blocks found, return original text
        return text

    def _convert_template_to_json_format(
        self,
        markdown_content: str,
        child_name: str,
        age_str: str
    ) -> str:
        """
        Convert template markdown to JSON format expected by frontend.

        This ensures template fallback provides the same structure as LLM generation.
        Frontend expects: { introduction, scenarios, general_tips, child_name }
        """
        import json

        # Create 3 standard scenarios for template-based guidelines
        scenarios = [
            {
                "title": "××©×—×§ ×—×•×¤×©×™",
                "context": "×ª×¨×—×™×© 1",
                "what_to_film": f"×¦×œ××• ××ª {child_name} ×‘××©×—×§ ×—×•×¤×©×™ - ×‘×‘×™×ª, ×‘×’×Ÿ, ××• ×‘×›×œ ××§×•× ×©× ×•×—. ×”××˜×¨×” ×”×™× ×œ×¨××•×ª ××™×š {child_name} ××ª× ×”×œ/×ª ×‘××¦×‘ ×–×”.",
                "what_to_look_for": [
                    "××™×š ×”×™×œ×“/×” ×‘×•×—×¨/×ª ×¤×¢×™×œ×•×ª",
                    "××©×š ×–××Ÿ ×”×§×©×‘ ×œ×¤×¢×™×œ×•×ª",
                    "×ª×’×•×‘×•×ª ×œ×¡×‘×™×‘×”"
                ],
                "duration": "2-5 ×“×§×•×ª",
                "examples": [
                    "××©×—×§ ×¢× ×¦×¢×¦×•×¢×™× ×‘×¡×œ×•×Ÿ",
                    "×¤×¢×™×œ×•×ª ×™×¦×™×¨×ª×™×ª ×‘×©×•×œ×—×Ÿ"
                ]
            },
            {
                "title": "××™× ×˜×¨××§×¦×™×” ×—×‘×¨×ª×™×ª",
                "context": "×ª×¨×—×™×© 2",
                "what_to_film": f"×¦×œ××• ××™× ×˜×¨××§×¦×™×” ×©×œ {child_name} ×¢× ××“× ××—×¨ - ×–×” ×™×›×•×œ ×œ×”×™×•×ª ××—/×•×ª, ×”×•×¨×”, ××• ×—×‘×¨/×”.",
                "what_to_look_for": [
                    "××™×›×•×ª ×”×ª×§×©×•×¨×ª",
                    "×™×•×–××” ×—×‘×¨×ª×™×ª",
                    "×ª×’×•×‘×ª×™×•×ª ×œ××—×¨"
                ],
                "duration": "2-5 ×“×§×•×ª",
                "examples": [
                    "××©×—×§ ××©×•×ª×£ ×¢× ×™×œ×“ ××—×¨",
                    "×©×™×—×” ×¢× ××‘×•×’×¨"
                ]
            },
            {
                "title": "×¤×¢×™×œ×•×ª ×™×•××™×•××™×ª",
                "context": "×ª×¨×—×™×© 3",
                "what_to_film": f"×›×œ ×¤×¢×™×œ×•×ª ×™×•××™×•××™×ª ×©×‘×” {child_name} ×¢×•×¡×§/×ª ×‘××•×¤×Ÿ ×˜×‘×¢×™ - ××•×›×œ, ××©×—×§, ×”×›× ×” ×œ×©×™× ×” ×•×›×“'.",
                "what_to_look_for": [
                    "×¢×¦×××•×ª ×‘×‘×™×¦×•×¢",
                    "×”×ª××¨×’× ×•×ª",
                    "×•×™×¡×•×ª ×¢×¦××™"
                ],
                "duration": "2-5 ×“×§×•×ª",
                "examples": [
                    "××¨×•×—×” ××©×¤×—×ª×™×ª",
                    "××©×—×§ ×‘×—×¦×¨",
                    "×–××Ÿ ×§×¨×™××”"
                ]
            }
        ]

        return json.dumps({
            "introduction": f"×”× ×—×™×•×ª ×¦×™×œ×•× ××•×ª×××•×ª ×¢×‘×•×¨ {child_name}",
            "scenarios": scenarios,
            "general_tips": [
                "×¦×™×œ×•× ×˜×‘×¢×™ - ××œ ×ª×‘×§×©×• ××”×™×œ×“/×” ×œ×¢×©×•×ª ××©×”×• ××™×•×—×“",
                "2-5 ×“×§×•×ª ×œ×›×œ ×¡×¨×˜×•×Ÿ",
                "××™×§×•×“ ×¢×œ ×¤× ×™ ×•×’×•×£ ×”×™×œ×“/×”",
                "×ª××•×¨×” ×˜×‘×¢×™×ª ×”×™× ×”×›×™ ×˜×•×‘×”"
            ],
            "estimated_duration": "2-5 ×“×§×•×ª ×œ×¡×¨×˜×•×Ÿ",
            "child_name": child_name
        }, ensure_ascii=False)

    def _get_stage1_extraction_schema(self) -> dict:
        """
        Get JSON schema for Stage 1 extraction.
        Defines the structure for extracting interview data + parent persona (holistic diagnosis).
        """
        return {
            "type": "object",
            "properties": {
                "child": {
                    "type": "object",
                    "properties": {
                        "name": {"type": "string"},
                        "age_years": {"type": "number"},
                        "age_months": {"type": "number"},
                        "gender": {"type": "string"}
                    }
                },
                "main_concern": {"type": "string"},
                "difficulties": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "area": {"type": "string"},
                            "description": {"type": "string"},
                            "specific_examples": {
                                "type": "array",
                                "items": {
                                    "type": "object",
                                    "properties": {
                                        "when_where": {"type": "string"},
                                        "behavior": {"type": "string"},
                                        "trigger": {"type": "string"},
                                        "frequency": {"type": "string"},
                                        "duration": {"type": "string"}
                                    }
                                }
                            },
                            "duration_since_onset": {"type": "string"},
                            "impact_child": {"type": "string"},
                            "impact_family": {"type": "string"}
                        }
                    }
                },
                "strengths": {
                    "type": "object",
                    "properties": {
                        "likes": {"type": "array", "items": {"type": "string"}},
                        "good_at": {"type": "array", "items": {"type": "string"}},
                        "positives": {"type": "string"}
                    }
                },
                "development": {
                    "type": "object",
                    "properties": {
                        "pregnancy_birth": {"type": "string"},
                        "milestones": {"type": "string"},
                        "medical": {"type": "string"}
                    }
                },
                "school": {
                    "type": "object",
                    "properties": {
                        "type": {"type": "string"},
                        "adjustment": {"type": "string"},
                        "support": {"type": "string"}
                    }
                },
                "history": {
                    "type": "object",
                    "properties": {
                        "previous_diagnosis": {"type": "string"},
                        "previous_treatment": {"type": "string"},
                        "family_history": {"type": "string"}
                    }
                },
                "parent_perspective": {
                    "type": "object",
                    "properties": {
                        "childs_experience": {"type": "string"},
                        "what_tried": {"type": "string"},
                        "hopes": {"type": "string"}
                    }
                },

                # Holistic Diagnosis Fields (Parent Persona)
                "parent_emotional_vibe": {
                    "type": "string",
                    "description": "Parent's emotional state in Hebrew (e.g., '×—×¨×“×” ×•××—×¤×©×ª ××™×©×•×¨', '××ª×•×¡×›×œ×ª ××š ××¢×©×™×ª')"
                },
                "specific_vocabulary_map": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "clinical_term": {"type": "string", "description": "Clinical term (e.g., 'Tantrum', 'Inattention')"},
                            "parent_word": {"type": "string", "description": "Parent's specific Hebrew word (e.g., '××ª×¤×•×¦×¥', '××¨×—×£')"}
                        },
                        "required": ["clinical_term", "parent_word"]
                    },
                    "description": "Array of vocabulary mappings from clinical terms to parent's specific Hebrew words"
                },
                "family_context_assets": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "Specific toys, people, places mentioned in transcript (e.g., '×¡×‘×ª× ×¨×—×œ', '×œ×’×• × ×™× ×’'×” ×’×•', '×”×©×˜×™×— ×”××“×•× ×‘×¡×œ×•×Ÿ')"
                }
            }
        }

    def _get_stage2_guidelines_schema(self) -> dict:
        """
        Get JSON schema for Stage 2 guidelines generation.
        Defines the structure for video filming guidelines.
        """
        return {
            "type": "object",
            "required": ["parent_greeting", "general_filming_tips", "video_guidelines"],
            "properties": {
                "parent_greeting": {
                    "type": "object",
                    "required": ["child_name", "opening_message"],
                    "properties": {
                        "parent_name": {"type": "string"},
                        "child_name": {"type": "string"},
                        "opening_message": {"type": "string"}
                    }
                },
                "general_filming_tips": {
                    "type": "array",
                    "minItems": 3,
                    "items": {"type": "string"}
                },
                "video_guidelines": {
                    "type": "array",
                    "minItems": 3,
                    "maxItems": 5,
                    "items": {
                        "type": "object",
                        "required": ["id", "category", "title", "instruction", "example_situations", "focus_points", "rationale_for_parent"],
                        "properties": {
                            "id": {"type": "integer"},
                            "category": {"type": "string", "enum": ["reported_difficulty", "comorbidity_check", "strength_baseline"]},
                            "difficulty_area": {"type": "string", "description": "For difficulties: problem area. For strength_baseline: strength domain (e.g., '×™×¦×™×¨×ª×™×•×ª', '××©×—×§ ×—×‘×¨×ª×™')"},
                            "title": {"type": "string"},
                            "instruction": {"type": "string"},
                            "example_situations": {
                                "type": "array",
                                "minItems": 2,
                                "items": {"type": "string"}
                            },
                            "duration_suggestion": {"type": "string"},
                            "focus_points": {
                                "type": "array",
                                "minItems": 2,
                                "items": {"type": "string"}
                            },
                            "rationale_for_parent": {"type": "string"}
                        }
                    }
                }
            }
        }

    async def _call_llm(self, prompt: str, temperature: float = 0.7, max_tokens: int = 2000) -> str:
        """
        Call LLM provider with prompt.

        Args:
            prompt: The prompt to send
            temperature: Temperature for generation
            max_tokens: Maximum tokens to generate

        Returns:
            Generated text from LLM
        """
        if not self.llm_provider:
            raise ValueError("No LLM provider configured")

        # Use provider's chat method
        from app.services.llm.base import Message

        response = await self.llm_provider.chat(
            messages=[Message(role="user", content=prompt)],
            temperature=temperature,
            max_tokens=max_tokens
        )

        return response.content

    async def generate_artifact(
        self,
        artifact_id: str,
        session_data: Dict[str, Any],
        **kwargs
    ) -> Artifact:
        """
        ğŸŒŸ Wu Wei: Generic artifact generator - config-driven dispatch.

        This method reads artifacts.yaml to determine how to generate each artifact.
        No hardcoded artifact IDs in the dispatcher!

        Args:
            artifact_id: Artifact identifier (e.g., "baseline_video_guidelines")
            session_data: Session context
            **kwargs: Additional parameters (e.g., required artifacts)

        Returns:
            Generated Artifact with status 'ready' or 'error'
        """
        logger.info(f"ğŸ¬ Generic generator dispatching for: {artifact_id}")

        # Get generator config from artifact_manager
        generator_config = self.artifact_manager.get_generator_config(artifact_id)

        if not generator_config:
            logger.error(f"âŒ No generator config found for artifact: {artifact_id}")
            error_artifact = Artifact(
                artifact_id=artifact_id,
                artifact_type="unknown",
                status="error"
            )
            error_artifact.mark_error(f"No generator configuration for {artifact_id}")
            return error_artifact

        # Get the generator method name from config
        method_name = generator_config.get("method")

        if not method_name:
            logger.error(f"âŒ No method specified in generator config for: {artifact_id}")
            error_artifact = Artifact(
                artifact_id=artifact_id,
                artifact_type="unknown",
                status="error"
            )
            error_artifact.mark_error(f"No method specified for {artifact_id}")
            return error_artifact

        # Get the method from this service
        generator_method = getattr(self, method_name, None)

        if not generator_method:
            logger.error(f"âŒ Generator method '{method_name}' not found for: {artifact_id}")
            error_artifact = Artifact(
                artifact_id=artifact_id,
                artifact_type="unknown",
                status="error"
            )
            error_artifact.mark_error(f"Generator method '{method_name}' not implemented")
            return error_artifact

        # Merge config params with kwargs
        params = generator_config.get("params", {})
        call_kwargs = {**params, **kwargs}

        # Call the generator method
        logger.info(f"âœ… Calling {method_name} for {artifact_id}")
        return await generator_method(artifact_id, session_data, **call_kwargs)

    async def generate_professional_report(
        self,
        artifact_id: str,
        session_data: Dict[str, Any],
        video_analysis_source: str = "baseline_video_analysis",
        **kwargs
    ) -> Artifact:
        """
        Generate professional clinical report from video analysis.

        Wu Wei: This is triggered when video analysis is complete.

        Args:
            artifact_id: Artifact identifier (baseline_professional_report, etc.)
            session_data: Session data including extracted_data and artifacts
            video_analysis_source: Artifact ID of video analysis to use

        Returns:
            Artifact with status 'ready' or 'error'
        """
        start_time = time.time()

        logger.info(f"ğŸ“‹ Generating professional report: {artifact_id}")

        # Get video analysis from session artifacts
        video_analysis_artifact = session_data.get("artifacts", {}).get(video_analysis_source)

        if not video_analysis_artifact or not video_analysis_artifact.get("exists"):
            logger.error(f"âŒ Cannot generate professional report: {video_analysis_source} not found")
            error_artifact = Artifact(
                artifact_id=artifact_id,
                artifact_type="report",
                status="error"
            )
            error_artifact.mark_error(f"Required artifact {video_analysis_source} not available")
            return error_artifact

        # Parse video analysis content
        import json
        video_analysis = json.loads(video_analysis_artifact.get("content", "{}"))

        artifact = Artifact(
            artifact_id=artifact_id,
            artifact_type="report",
            status="generating",
            content_format="markdown",
            generation_inputs={
                "child_name": session_data.get("child_name"),
                "video_analysis_source": video_analysis_source,
                "extracted_data": session_data.get("extracted_data", {})
            }
        )

        try:
            # TODO: Implement professional report generation with LLM
            # For now, create placeholder
            content = self._generate_professional_report_placeholder(
                child_name=session_data.get("child_name", "×™×œ×“/×”"),
                session_data=session_data,
                video_analysis=video_analysis
            )

            artifact.mark_ready(content)
            artifact.generation_duration_seconds = time.time() - start_time

            logger.info(f"âœ… Professional report generated in {artifact.generation_duration_seconds:.2f}s")

        except Exception as e:
            logger.error(f"âŒ Error generating professional report: {e}", exc_info=True)
            artifact.mark_error(str(e))

        return artifact

    async def generate_parent_report(
        self,
        artifact_id: str,
        session_data: Dict[str, Any],
        professional_report_source: str = "baseline_professional_report",
        **kwargs
    ) -> Artifact:
        """
        Generate parent-friendly report derived from professional report.

        Wu Wei: Parent report is a simplified, accessible version of the professional report.

        Args:
            artifact_id: Artifact identifier (baseline_parent_report, etc.)
            session_data: Session data including extracted_data and artifacts
            professional_report_source: Artifact ID of professional report to derive from

        Returns:
            Artifact with status 'ready' or 'error'
        """
        start_time = time.time()

        logger.info(f"ğŸ“‹ Generating parent report from: {professional_report_source}")

        # Get professional report from session artifacts
        professional_report_artifact = session_data.get("artifacts", {}).get(professional_report_source)

        if not professional_report_artifact or not professional_report_artifact.get("exists"):
            logger.error(f"âŒ Cannot generate parent report: {professional_report_source} not found")
            error_artifact = Artifact(
                artifact_id=artifact_id,
                artifact_type="report",
                status="error"
            )
            error_artifact.mark_error(f"Required artifact {professional_report_source} not available")
            return error_artifact

        professional_report_content = professional_report_artifact.get("content", "")

        artifact = Artifact(
            artifact_id=artifact_id,
            artifact_type="report",
            status="generating",
            content_format="markdown",
            generation_inputs={
                "child_name": session_data.get("child_name"),
                "professional_report_source": professional_report_source,
                "extracted_data": session_data.get("extracted_data", {})
            }
        )

        try:
            # TODO: Implement parent report derivation from professional report using LLM
            # For now, create placeholder
            content = self._generate_parent_report_placeholder(
                child_name=session_data.get("child_name", "×™×œ×“/×”"),
                session_data=session_data
            )

            artifact.mark_ready(content)
            artifact.generation_duration_seconds = time.time() - start_time

            logger.info(f"âœ… Parent report generated in {artifact.generation_duration_seconds:.2f}s")

        except Exception as e:
            logger.error(f"âŒ Error generating parent report: {e}", exc_info=True)
            artifact.mark_error(str(e))

        return artifact

    def _generate_professional_report_placeholder(
        self,
        child_name: str,
        session_data: Dict[str, Any],
        video_analysis: Dict[str, Any]
    ) -> str:
        """Generate placeholder professional report."""
        return f"""# ×“×•×— ××§×¦×•×¢×™ - ×”×¢×¨×›×” ×”×ª×¤×ª×—×•×ª×™×ª

## ×¤×¨×˜×™ ×”××§×¨×”

**×©× ×”×™×œ×“/×”:** {child_name}
**×’×™×œ:** {session_data.get('age', '×œ× ×¦×•×™×Ÿ')}
**×ª××¨×™×š ×”×¢×¨×›×”:** {datetime.now().strftime('%d/%m/%Y')}

## ××™×“×¢ ×¨×§×¢

[××™×“×¢ ××”×¨××™×•×Ÿ ×¢× ×”×”×•×¨×”]

## ×ª×¦×¤×™×•×ª ×”×ª× ×”×’×•×ª×™×•×ª

### × ×™×ª×•×— ×•×™×“××•

[×××¦××™× ×× ×™×ª×•×— ×”×¡×¨×˜×•× ×™× - ××‘×•×¡×¡ ×¢×œ video_analysis]

### ×“×¤×•×¡×™× ×–×•×”×•

[×“×¤×•×¡×™× ×§×œ×™× ×™×™× ×©×–×•×”×•]

## ×¨×•×©× ×§×œ×™× ×™

### ×©×™×§×•×œ×™× ××‘×—× ×ª×™×™×

[×©×™×§×•×œ×™× ××‘×•×¡×¡×™ DSM-5/ICD-11]

### ×¨××•×ª ×‘×™×˜×—×•×Ÿ

[×¨××•×ª ×‘×™×˜×—×•×Ÿ ×‘×××¦××™×]

## ×”×©×œ×›×•×ª ×ª×¤×§×•×“×™×•×ª

[×”×©×¤×¢×” ×¢×œ ×ª×¤×§×•×“ ×™×•××™×•××™]

## ×”××œ×¦×•×ª

### ×”×¢×¨×›×•×ª × ×•×¡×¤×•×ª × ×“×¨×©×•×ª

[×”××œ×¦×•×ª ×œ×”×¢×¨×›×•×ª × ×•×¡×¤×•×ª]

### ×”×ª×¢×¨×‘×•×™×•×ª ×˜×™×¤×•×œ×™×•×ª

[×”××œ×¦×•×ª ×˜×™×¤×•×œ×™×•×ª]

### ×”×¤× ×™×•×ª ×œ××•××—×™×

[×”××œ×¦×•×ª ×œ×”×¤× ×™×”]

## ××’×‘×œ×•×ª ×”×”×¢×¨×›×”

[×”×’×‘×œ×•×ª ×•×”×¢×¨×•×ª ×—×©×•×‘×•×ª ×œ×’×‘×™ ×ª×—×•× ×”×”×¢×¨×›×”]

---

*×“×•×— ××§×¦×•×¢×™ ×–×” × ×•×¦×¨ ×‘×ª××¨×™×š: {datetime.now().strftime('%d/%m/%Y')}*
*×œ××˜×¨×•×ª ××‘×—×•×Ÿ ×•×˜×™×¤×•×œ ×‘×œ×‘×“*
"""

    def _generate_parent_report_placeholder(
        self,
        child_name: str,
        session_data: Dict[str, Any]
    ) -> str:
        """Generate placeholder parent report (derived from professional report)."""
        return f"""# ×“×•×— ×”×¢×¨×›×” ×”×ª×¤×ª×—×•×ª×™×ª - {child_name}

## ×¡×™×›×•× ×× ×”×œ×™×

[×“×•×— ×–×” × ×’×–×¨ ××”×“×•×— ×”××§×¦×•×¢×™ ×•××•×ª×× ×œ×”×•×¨×™×]

## ×¤×¨×•×¤×™×œ ×”×™×œ×“/×”

**×©×:** {child_name}
**×’×™×œ:** {session_data.get('age', '×œ× ×¦×•×™×Ÿ')}

## ×ª×¦×¤×™×•×ª ×”×ª×¤×ª×—×•×ª×™×•×ª

[×ª×¦×¤×™×•×ª ×‘×©×¤×” × ×’×™×©×” ×•××›×™×œ×”]

## ×ª×—×•××™ ×—×•×–×§×”

[××” {child_name} ×¢×•×©×” × ×”×“×¨]

## ×ª×—×•××™× ×œ×ª××™×›×”

[××™×¤×” {child_name} ×™×›×•×œ/×” ×œ×”×©×ª×¤×¨ ×¢× ×ª××™×›×”]

## ×”××œ×¦×•×ª ××¢×©×™×•×ª

### ×¦×¢×“×™× ××™×™×“×™×™×
[×¤×¢×•×œ×•×ª ×§×•× ×§×¨×˜×™×•×ª]

### ×™×¢×“×™× ×œ×˜×•×•×— ××¨×•×š
[××” ×œ×©××•×£ ××œ×™×•]

### ××©××‘×™×
[×§×™×©×•×¨×™× ×•××©××‘×™× ××•×¢×™×œ×™×]

## ×”×©×œ×‘×™× ×”×‘××™×

[×ª×•×›× ×™×ª ×¤×¢×•×œ×” ×‘×¨×•×¨×”]

---

*×“×•×— ×–×” × ×•×¦×¨ ×‘×ª××¨×™×š: {datetime.now().strftime('%d/%m/%Y')}*
*× ×›×ª×‘ ×‘×©×¤×” ×¤×©×•×˜×” ×•××›×™×œ×” ×œ×”×•×¨×™×*
"""
