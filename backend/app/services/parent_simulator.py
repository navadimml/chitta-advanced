"""
Parent Simulator - Simulates realistic parent personas
Uses real backend processing to test entire system
"""
from typing import Dict, List, Optional
from pydantic import BaseModel
from datetime import datetime
import logging

logger = logging.getLogger(__name__)


class ParentPersona(BaseModel):
    """A realistic parent persona for testing"""
    persona_id: str
    parent_name: str
    child_name: str
    child_age: float
    child_gender: str

    main_concern: str
    strengths: List[str]

    background: dict
    response_style: str

    # For generating responses
    context_info: dict


# Define test personas
PARENT_PERSONAS = {
    "sarah_language_delay": ParentPersona(
        persona_id="sarah_language_delay",
        parent_name="×©×¨×”",
        child_name="×“× ×™××œ",
        child_age=3.5,
        child_gender="boy",

        main_concern="××™×—×•×¨ ×‘×“×™×‘×•×¨ - ×”×•× ×‘×§×•×©×™ ××•×ž×¨ ×ž×™×œ×™× ×‘×•×“×“×•×ª",
        strengths=[
            "×™×œ×“ ×ž××•×“ ×—×™×‘×•×§×™ ×•×ž×—×‘×§",
            "××•×”×‘ ×ž×•×–×™×§×” ×•×¨×•×§×“ ×›×©×”×•× ×©×•×ž×¢ ×©×™×¨×™×",
            "×ž××•×“ ×™×¦×™×¨×ª×™ ×¢× ×§×•×‘×™×•×ª ×œ×’×•"
        ],

        background={
            "milestones": {
                "walking": "12 ×—×•×“×©×™× - ×ª×§×™×Ÿ",
                "first_words": "24 ×—×•×“×©×™× - ×ž××•×—×¨",
                "sentences": "×˜×¨× - ×–×• ×”×“××’×” ×”×¢×™×§×¨×™×ª"
            },
            "family_context": "×‘×Ÿ ×™×—×™×“, ×“×•×‘×¨ ×¢×‘×¨×™×ª ×‘×‘×™×ª, ××‘× ×¢×•×‘×“ ×”×¨×‘×”",
            "previous_assessments": "×‘×“×™×§×ª ×©×ž×™×¢×” - ×ª×§×™× ×”",
            "gan_feedback": "×”×’× × ×ª ××ž×¨×” ×©×”×•× ×ž×©×—×§ ×œ×‘×“ ×”×¨×‘×”, ×œ× ×ž×ž×© ×ž×“×‘×¨ ×¢× ×”×™×œ×“×™×"
        },

        response_style="worried but hopeful, detailed answers, asks follow-up questions",

        context_info={
            "typical_day": "×‘×•×§×¨ ×‘×’×Ÿ ×¢×“ 14:00, ××—×¨ ×›×¦×”×¨×™×™× ×‘×‘×™×ª, ×ž×©×—×§ ×”×¨×‘×” ×œ×‘×“",
            "favorite_activities": "×œ×’×•, ×ž×•×–×™×§×”, ×¡×¨×˜×•× ×™× ×©×œ ×¨×›×‘×•×ª ×‘×™×•×˜×™×•×‘",
            "concerns_intensity": "×ž×•×“××’×ª ×ž××•×“, ×œ× ×™×©× ×” ×˜×•×‘ ×‘×œ×™×œ×•×ª",
            "support_system": "×¡×‘×ª× ×¢×•×–×¨×ª ×¤×¢×ž×™×™× ×‘×©×‘×•×¢"
        }
    ),

    "michael_social": ParentPersona(
        persona_id="michael_social",
        parent_name="×ž×™×›××œ",
        child_name="× ×•×¢×”",
        child_age=4.0,
        child_gender="girl",

        main_concern="×§×©×™×™× ×—×‘×¨×ª×™×™× - ×ž×ª×§×©×” ×œ×”×ª×—×‘×¨ ×œ×™×œ×“×™× ×‘×’×Ÿ",
        strengths=[
            "×ž××•×“ ×—×›×ž×” - ×–×•×›×¨×ª ×”×›×œ",
            "××•×”×‘×ª ×¤××–×œ×™× ×•×ž×¦×œ×™×—×” ×œ×¤×ª×•×¨ ×ž×”×¨",
            "×ž×“×‘×¨×ª ×˜×•×‘, ××•×¦×¨ ×ž×™×œ×™× ×¢×©×™×¨"
        ],

        background={
            "milestones": {
                "walking": "13 ×—×•×“×©×™×",
                "speech": "×ž×•×§×“× - ×ž×©×¤×˜×™× ×ž×’×™×œ ×©× ×ª×™×™×",
                "social": "×ª×ž×™×“ ×”×¢×“×™×¤×” ×ž×‘×•×’×¨×™× ×¢×œ ×™×œ×“×™×"
            },
            "family_context": "×™×© ××— ×§×˜×Ÿ ×‘×Ÿ ×©× ×ª×™×™×, × ×•×¢×” ×§×¦×ª ×§× ××™×ª",
            "interests": "×ž×¡×¤×¨×™×, ×“×™× ×•×–××•×¨×™×, ×ž×“×¢",
            "gan_feedback": "×”×’× × ×ª ×ž×•×“××’×ª ×©× ×•×¢×” ×ž×©×—×§×ª ×œ×‘×“, ×™×© ×œ×” ×§×•×©×™ ×‘×¢×™×Ÿ-×§×©×¨"
        },

        response_style="analytical, seeks understanding, less emotional",

        context_info={
            "typical_day": "×’×Ÿ ×¢×“ 16:00, ××—×¨ ×›×¦×”×¨×™×™× ×—×•×’×™× (××•×ž× ×•×ª, ×©×—×™×™×”)",
            "favorite_activities": "×¤××–×œ×™×, ×¡×¤×¨×™ ×¢×•×‘×“×•×ª, ×ž×©×—×§×™ ×–×™×›×¨×•×Ÿ",
            "concerns_intensity": "×ž× ×¡×” ×œ×”×‘×™×Ÿ ×× ×–×” × ×•×¨×ž×œ×™ ××• ×¦×¨×™×š ×¢×–×¨×”",
            "support_system": "××ž× × ×©××¨×ª ×‘×‘×™×ª, ×ž×©×¤×—×” ×ž×¢×•×¨×‘×ª"
        }
    ),

    "rita_behavior": ParentPersona(
        persona_id="rita_behavior",
        parent_name="×¨×•×ª×™",
        child_name="××•×¤×§",
        child_age=5.0,
        child_gender="boy",

        main_concern="×”×ª×¤×¨×¦×•×™×•×ª ×–×¢× - ×ž××‘×“ ×©×œ×™×˜×” ×‘×§×œ×•×ª",
        strengths=[
            "×ž××•×“ ××›×¤×ª×™ - ×©×•××œ ×× ××—×¨×™× ×‘×¡×“×¨",
            "××•×”×‘ ×œ×¢×–×•×¨ ×‘×ž×˜×œ×•×ª ×‘×‘×™×ª",
            "×§×©×•×‘ ×‘×ž×™×•×—×“ ×œ×¡×™×¤×•×¨×™×"
        ],

        background={
            "milestones": {
                "all_developmental": "×ª×§×™× ×™× - ×”×ª×¤×ª×—×•×ª ×ž×•×˜×•×¨×™×ª ×•×©×¤×ª×™×ª ×˜×•×‘×”"
            },
            "family_context": "×™×© ××—×•×ª ×ª××•×ž×”, ×™×—×¡×™× ×˜×•×‘×™× ××‘×œ ×™×© ×ª×—×¨×•×ª",
            "triggers": "×ž×¢×‘×¨×™×, ×©×™× ×•×™ ×ª×•×›× ×™×•×ª, ×ª×¡×›×•×œ ×›×©×ž×©×”×• ×œ× ×ž×¦×œ×™×—",
            "gan_feedback": "×ž×ª× ×”×’ ×™×¤×” ×¢× ×”×ž×•×¨×”, ××‘×œ ×‘×›×™×ª×” ×™×© ×ž×¨×™×‘×•×ª"
        },

        response_style="exhausted, looking for practical solutions",

        context_info={
            "typical_day": "×‘×•×§×¨ ×‘×’×Ÿ, ××—×¨ ×›×¦×”×¨×™×™× ×¤×¢×™×œ×•×™×•×ª ×ž×©×¤×—×ª×™×•×ª",
            "favorite_activities": "×¨×›×™×‘×” ×¢×œ ××•×¤× ×™×™×, ×ž×©×—×§×™ ×§×œ×¤×™×, ×‘×™×©×•×œ ×‘×™×—×“",
            "concerns_intensity": "×ž×•×ª×©×ª, ×¦×¨×™×›×” ×›×œ×™× ×ž×¢×©×™×™×",
            "support_system": "×‘×¢×œ ×ž×¢×•×¨×‘, ××‘×œ ×©× ×™×”× ×¢×•×‘×“×™×"
        }
    ),

    # === CHALLENGING PERSONAS - Test Edge Cases ===

    "yael_vague": ParentPersona(
        persona_id="yael_vague",
        parent_name="×™×¢×œ",
        child_name="×ª×•×",
        child_age=3.0,
        child_gender="boy",

        main_concern="×œ× ×‘×˜×•×—×” ×‘×“×™×•×§... ×ž×©×”×• ×œ× ×ž×¡×ª×“×¨",
        strengths=[
            "×—×ž×•×“",
            "×™×•×“×¢ ×œ×©×—×§",
            "×˜×•×‘"
        ],

        background={
            "milestones": {
                "general": "×œ× ×ž×ž×© ×–×•×›×¨×ª ×‘×“×™×•×§, ××•×œ×™ ×‘×¡×“×¨?"
            },
            "family_context": "×ž×©×¤×—×” ×’×¨×¢×™× ×™×ª ×¨×’×™×œ×”",
            "current_situation": "×ž×©×”×• ×ž×˜×¨×™×“ ××•×ª×™ ××‘×œ ×§×©×” ×œ×™ ×œ×”×¡×‘×™×¨"
        },

        response_style="vague, incomplete answers, uses general terms like 'kind of', 'I don't know', 'maybe'",

        context_info={
            "answer_patterns": [
                "CLEAR ANSWERS on: child's name, age, what they like to do",
                "VAGUE on: developmental milestones, when things started, comparisons",
                "Uses vague terms only when uncertain: '×ž×©×”×• ×›×–×”', '×œ× ×‘×“×™×•×§'",
                "Struggles with timelines and specific examples",
                "Mix of clear and unclear - NOT vague on everything"
            ],
            "testing_purpose": "Tests Chitta's ability to extract information through probing questions",
            "typical_responses": [
                "Clear: '×©×ž×• ×ª×•× ×•×”×•× ×‘×Ÿ 3'",
                "Vague: '××ž×ž... ×œ× ×™×•×“×¢×ª ×‘×“×™×•×§ ×ž×ª×™ ×–×” ×”×ª×—×™×œ'",
                "Mixed: '×”×•× ××•×”×‘ ×œ×©×—×§, ××‘×œ... ×§×©×” ×œ×™ ×œ×”×¡×‘×™×¨ ×‘×“×™×•×§ ×ž×”'"
            ]
        }
    ),

    "dani_anxious_questioner": ParentPersona(
        persona_id="dani_anxious_questioner",
        parent_name="×“× ×™",
        child_name="×ž×™×›×œ",
        child_age=4.5,
        child_gender="girl",

        main_concern="×§×©×™×™ ×§×©×‘ - ××‘×œ ×ž×” ×–×” ××•×ž×¨ ×¢×œ ×”×¢×ª×™×“ ×©×œ×”?",
        strengths=[
            "×× ×¨×’×˜×™×ª ×•×©×ž×—×”",
            "××•×”×‘×ª ×œ×¨×§×•×“",
            "×—×‘×¨×•×ª×™×ª ×ž××•×“"
        ],

        background={
            "milestones": {
                "speech_motor": "×”×›×œ ×ª×§×™×Ÿ"
            },
            "family_context": "×”×•×¨×™× ×ž×•×“××’×™×, ×§×•×¨××™× ×”×¨×‘×” ×‘××™× ×˜×¨× ×˜",
            "main_fear": "×—×•×©×© ×©×–×” ××•×ž×¨ ×©×™×© ×œ×” ADHD, ×ž×” ×™×”×™×” ×‘×‘×™×ª ×¡×¤×¨?"
        },

        response_style="asks many questions, seeks reassurance, worries about next steps",

        context_info={
            "answer_patterns": [
                "ANSWERS first, THEN asks one follow-up question (not constant questioning)",
                "Asks questions on maybe 60% of responses, not ALL",
                "Seeks reassurance mainly on concerning topics, not basic facts",
                "Worries about implications: '×ž×” ×–×” ××•×ž×¨ ×¢×œ...?'",
                "Can answer factual questions without anxiety"
            ],
            "testing_purpose": "Tests Chitta's ability to handle anxious parents and maintain interview flow",
            "typical_responses": [
                "Clear answer: '×©×ž×” ×ž×™×›×œ, ×‘×ª 4.5, ×× ×¨×’×˜×™×ª ×ž××•×“'",
                "Anxious: '×”×™× ×œ× ×ž×ž×© ×ž×ª×¨×›×–×ª. ×–×” ××•×ž×¨ ×ž×©×”×• ×¨×¦×™× ×™?'",
                "Mixed: '×›×Ÿ, ×”×™× ××•×”×‘×ª ×œ×¨×§×•×“. ××‘×œ ×ž×” ×”×¦×¢×“ ×”×‘×?'"
            ]
        }
    ),

    "orna_offtopic": ParentPersona(
        persona_id="orna_offtopic",
        parent_name="××•×¨× ×”",
        child_name="×¨×•× ×™",
        child_age=3.5,
        child_gender="boy",

        main_concern="×œ× ××•×›×œ ×™×¨×§×•×ª - ××‘×œ ×’× ×× ×™ ×‘×™×œ×“×•×ª ×œ× ××”×‘×ª×™",
        strengths=[
            "×ž×¦×—×™×§ ×ž××•×“",
            "××•×”×‘ ×—×™×•×ª",
            "×“×ž×™×•×Ÿ ×¢×©×™×¨"
        ],

        background={
            "milestones": {
                "development": "×ª×§×™×Ÿ ×‘×¢×™×§×¨×•×Ÿ"
            },
            "family_context": "×¡×‘×ª× ×’×¨×” ×§×¨×•×‘, ×”×ž×•×Ÿ ×“×¢×•×ª",
            "tangents": "× ×•×˜×” ×œ×¡×¤×¨ ×¢×œ ×“×‘×¨×™× ×œ× ×§×©×•×¨×™×"
        },

        response_style="goes off-topic, shares unrelated stories, overshares about family dynamics",

        context_info={
            "answer_patterns": [
                "Answers directly about 40% of the time without tangent",
                "Goes on tangent maybe 60% - not EVERY time",
                "When on tangent: briefly shares then catches herself",
                "Can stay focused when Chitta redirects gently",
                "Basic facts answered clearly, complex topics trigger tangents"
            ],
            "testing_purpose": "Tests Chitta's ability to redirect conversation and stay focused",
            "typical_responses": [
                "Direct: '×¨×•× ×™, 3.5, ××•×”×‘ ×—×™×•×ª'",
                "Tangent: '×”×•× ×œ× ××•×›×œ ×™×¨×§×•×ª... ××” ×–×” ×ž×–×›×™×¨ ×œ×™ ×©×’× ×× ×™...'",
                "Caught: '×¨×’×¢, ×¡×˜×™×ª×™ ×ž×”× ×•×©×. ×ž×” ×©××œ×ª?'"
            ]
        }
    ),

    "moshe_contradictory": ParentPersona(
        persona_id="moshe_contradictory",
        parent_name="×ž×©×”",
        child_name="×™×•× ×ª×Ÿ",
        child_age=4.0,
        child_gender="boy",

        main_concern="×”×•× ×ž×“×‘×¨ ×˜×•×‘ - ××” ×œ× ×¨×’×¢, ×‘×¢×¦× ×”×•× ×›×Ÿ ×ž×ª×§×©×” ×§×¦×ª",
        strengths=[
            "×™×œ×“ ×—×›×",
            "×œ×¤×¢×ž×™× ×ž×ª× ×”×’ ×™×¤×”",
            "×ª×œ×•×™ ×‘×ž×¦×‘ ×¨×•×—"
        ],

        background={
            "milestones": {
                "confusion": "×× ×™ ×•××™×©×ª×™ ×œ× ×ž×¡×›×™×ž×™× ×¢×œ ×ž×” ×”×ª×¤×ª×—×•×ª ×ª×§×™× ×”"
            },
            "family_context": "×“×¢×•×ª ×©×•× ×•×ª ×‘×™×Ÿ ×”×”×•×¨×™×, ×‘×œ×‘×•×œ",
            "uncertainty": "×œ× ×‘×˜×•×— ×ž×” × ×•×¨×ž×œ×™ ×•×ž×” ×œ×"
        },

        response_style="contradicts himself, changes answers, seems confused about facts",

        context_info={
            "answer_patterns": [
                "CLEAR on basic facts: name, age, favorite activities",
                "CONTRADICTORY on: timelines, severity assessments, comparisons",
                "Contradicts maybe 50% of the time, not constantly",
                "Can provide consistent info when asked to clarify",
                "Uncertainty shows on complex developmental questions"
            ],
            "testing_purpose": "Tests Chitta's ability to clarify contradictions and establish facts",
            "typical_responses": [
                "Clear: '×©×ž×• ×™×•× ×ª×Ÿ, ×‘×Ÿ 4'",
                "Contradictory: '×”×•× ×ž×“×‘×¨ ×˜×•×‘... ××” ×¨×’×¢, ×œ× ×‘×“×™×•×§'",
                "Clarified: '××” ×›×Ÿ, ××©×ª×™ ×¦×•×“×§×ª - ×–×” ×”×™×” ×‘×’×™×œ 3'"
            ]
        }
    ),

    "tamar_defensive": ParentPersona(
        persona_id="tamar_defensive",
        parent_name="×ª×ž×¨",
        child_name="××•×¨×™",
        child_age=5.0,
        child_gender="boy",

        main_concern="×”×’× × ×ª ××ž×¨×” ×©×™×© ×‘×¢×™×” ××‘×œ ×× ×™ ×œ× ×—×•×©×‘×ª ×©×™×©",
        strengths=[
            "×™×œ×“ × ×”×“×¨",
            "×ž××•×“ ×—×›×",
            "×¤×©×•×˜ ××—×¨"
        ],

        background={
            "milestones": {
                "development": "×”×›×œ ×ž×¦×•×™×Ÿ"
            },
            "family_context": "×”×•×¤× ×ª×” ×¢×´×™ ×’×Ÿ ×‘×œ×™ ×©×”×™× ×ž×¡×›×™×ž×”",
            "attitude": "×—×•×©×‘×ª ×©×ž×’×–×™×ž×™×, ×ž×™×™×—×¡×ª ×œ×’×™×œ"
        },

        response_style="defensive, minimizes concerns, questions if there's really a problem",

        context_info={
            "answer_patterns": [
                "Answers facts clearly: name, age, strengths",
                "Defensive about CONCERNS, not basic questions",
                "Downplays issues maybe 50-60% of the time",
                "Can acknowledge small concerns when asked gently",
                "Opens up gradually as conversation progresses"
            ],
            "testing_purpose": "Tests Chitta's ability to handle resistant parents with empathy",
            "typical_responses": [
                "Clear: '××•×¨×™, 5 ×©× ×™×, ×™×œ×“ ×—×›×'",
                "Defensive: '×”×’× × ×ª ×ž×’×–×™×ž×”, ×–×” × ×•×¨×ž×œ×™ ×œ×’×™×œ'",
                "Opening: '× ×•, ××•×œ×™ ×™×© ×§×¦×ª ×§×•×©×™... ××‘×œ ×œ× ×ž×©×”×• ×¨×¦×™× ×™'"
            ]
        }
    ),

    "liora_overwhelmed": ParentPersona(
        persona_id="liora_overwhelmed",
        parent_name="×œ×™××•×¨×”",
        child_name="×©×™×¨×”",
        child_age=3.0,
        child_gender="girl",

        main_concern="×™×© ×›×œ ×›×š ×”×¨×‘×” ×“×‘×¨×™×... ××™×¤×” ×× ×™ ×ž×ª×—×™×œ×”?",
        strengths=[
            "×ž×ª×•×§×”",
            "××•×”×‘×ª ×œ×¦×™×™×¨",
            "×œ×¤×¢×ž×™×..."
        ],

        background={
            "milestones": {
                "multiple_concerns": "×“×™×‘×•×¨, ×©×™× ×”, ××›×™×œ×”, ×”×ª× ×”×’×•×ª - ×”×›×œ ×‘×™×—×“"
            },
            "family_context": "××ž× ×—×“ ×”×•×¨×™×ª, ×¢×•×‘×“×ª ×‘×ž×©×¨×” ×ž×œ××”, ×ž×•×ª×©×ª",
            "state": "×ž×•×¦×¤×ª, ×§×©×” ×œ×ž×§×“"
        },

        response_style="overwhelmed, scattered, mentions multiple concerns, partial answers",

        context_info={
            "answer_patterns": [
                "Can answer simple direct questions: name, age",
                "Gets overwhelmed on open-ended questions: 'what concerns you?'",
                "Mentions multiple things maybe 60% of time, not always",
                "Can focus when Chitta asks about ONE specific thing",
                "Improves when feeling supported and guided"
            ],
            "testing_purpose": "Tests Chitta's ability to help parent focus and prioritize",
            "typical_responses": [
                "Clear: '×©×™×¨×”, 3 ×©× ×™×'",
                "Overwhelmed: '×™×© ×›×œ ×›×š ×”×¨×‘×”... ×“×™×‘×•×¨, ×©×™× ×”...'",
                "Focused: '×¢×œ ×”×“×™×‘×•×¨? ×›×Ÿ, ×”×™× ××•×ž×¨×ª ×ž×™×œ×™× ×‘×•×“×“×•×ª'"
            ]
        }
    )
}


class ParentSimulator:
    """
    Simulates realistic parent responses.
    Uses LLM to generate contextual responses based on persona.
    """

    def __init__(self):
        self.personas = PARENT_PERSONAS
        self.active_simulations: Dict[str, dict] = {}

    def get_persona(self, persona_id: str) -> Optional[ParentPersona]:
        """Get persona by ID"""
        return self.personas.get(persona_id)

    def list_personas(self) -> List[dict]:
        """List all available personas"""
        return [
            {
                "id": p.persona_id,
                "parent": p.parent_name,
                "child": f"{p.child_name} ({p.child_age} ×©× ×™×)",
                "concern": p.main_concern
            }
            for p in self.personas.values()
        ]

    def start_simulation(self, persona_id: str, family_id: str) -> dict:
        """Start a test simulation with this persona"""
        persona = self.get_persona(persona_id)
        if not persona:
            raise ValueError(f"Persona {persona_id} not found")

        self.active_simulations[family_id] = {
            "persona": persona,
            "started_at": datetime.now(),
            "message_count": 0
        }

        return {
            "family_id": family_id,
            "persona": persona.dict(),
            "status": "active"
        }

    async def generate_response(
        self,
        family_id: str,
        chitta_question: str,
        llm_provider,
        graphiti=None
    ) -> Optional[str]:
        """
        Generate realistic parent response using LLM.
        The LLM acts as the parent persona.

        Args:
            family_id: Family ID for this simulation
            chitta_question: Current question from Chitta
            llm_provider: LLM provider for generating responses
            graphiti: Optional graphiti instance to retrieve conversation history

        Returns:
            str: Parent's response
            None: If conversation should end (interview complete)
        """
        simulation = self.active_simulations.get(family_id)
        if not simulation:
            raise ValueError(f"No active simulation for {family_id}")

        persona = simulation["persona"]
        message_count = simulation["message_count"]
        simulation["message_count"] += 1

        # Check if interview artifacts have been generated (indicates completion)
        from app.services.interview_service import get_interview_service
        interview_service = get_interview_service()
        session = interview_service.get_or_create_session(family_id)

        guidelines_ready = session.has_artifact("baseline_video_guidelines")
        acknowledgment_count = simulation.get("completion_acknowledgments", 0)

        # Simple, deterministic completion logic based on artifact state
        # If guidelines ready AND parent has acknowledged 2+ times â†’ stop
        if guidelines_ready and acknowledgment_count >= 2:
            logger.info(
                f"ðŸ›‘ Interview complete for {family_id}: "
                f"guidelines ready, acknowledged {acknowledgment_count} times"
            )
            return None  # Stop - conversation is done

        # Build context for LLM
        answer_patterns = persona.context_info.get("answer_patterns", [])
        patterns_text = "\n".join([f"- {p}" for p in answer_patterns]) if answer_patterns else ""

        # Determine conversation phase based on message count only
        if message_count < 3:
            phase = "beginning - settling in"
            detail_level = "basic facts"
        elif message_count < 8:
            phase = "middle - opening up"
            detail_level = "adding context"
        else:
            phase = "established conversation"
            detail_level = "comprehensive"

        # Build natural character description
        background_text = self._format_background_naturally(persona.background)

        system_prompt = f"""CONTEXT: This is a development/testing simulation for a child development guidance platform used by parents at home. You are role-playing as a parent character to help test the system.

---

××ª×” {persona.parent_name}, ×”×•×¨×” ×œ×™×œ×“/×” ×‘×©× {persona.child_name} ×‘×Ÿ/×‘×ª {persona.child_age}.

××ª×” ×ž×“×‘×¨/×ª ×¢× ×¦'×™×˜×”, ×ž×“×¨×™×›×” ×œ×”×ª×¤×ª×—×•×ª ×™×œ×“×™×.

×”×“××’×” ×”×¢×™×§×¨×™×ª ×©×œ×š: {persona.main_concern.lower()}

{background_text}

×ª×’×•×‘×” ×˜×‘×¢×™×ª:
- ×ª×Ÿ ×ª×©×•×‘×” ×§×¦×¨×” ×•×¤×©×•×˜×” ×›×ž×• ×©×”×•×¨×” ××ž×™×ª×™ ×”×™×” ××•×ž×¨
- ×ž×©×¤×˜ ××—×“ ××• ×©× ×™×™×, ×œ× ×™×•×ª×¨
- ××œ ×ª×¨×©×•× ×¨×©×™×ž×•×ª ××• × ×§×•×“×•×ª
- ×× ××ª×” ×œ× ×‘×˜×•×— ×‘×ž×©×”×•, ×¤×©×•×˜ ×ª×’×™×“ "×× ×™ ×œ× ×‘×˜×•×—×”" ××• "×× ×™ ×¦×¨×™×›×” ×œ×—×©×•×‘"
- ×ª×“×‘×¨ ×‘×¢×‘×¨×™×ª ×¤×©×•×˜×” ×•×˜×‘×¢×™×ª

×¦'×™×˜×” ×©×•××œ×ª: "{chitta_question}"

×ª×©×•×‘×”:"""

        # Use LLM to generate response
        from app.services.llm.base import Message

        # Build messages list with conversation history
        messages = [Message(role="system", content=system_prompt)]

        # Add recent conversation history if available (last 8 messages)
        # This gives the LLM context about what it said before
        if graphiti:
            state = graphiti.get_or_create_state(family_id)
            recent_messages = state.conversation[-8:] if len(state.conversation) > 8 else state.conversation

            for msg in recent_messages:
                # Convert graphiti messages to LLM messages
                messages.append(Message(
                    role="assistant" if msg.role == "user" else "user",  # Flip roles: user is Chitta, assistant is parent
                    content=msg.content
                ))

        # Add current question
        messages.append(Message(role="user", content=chitta_question))

        response = await llm_provider.chat(messages=messages, temperature=0.75)  # Higher temp for natural, varied responses

        response_text = response.content.strip()

        # Track acknowledgments when guidelines are ready
        if guidelines_ready and "###COMPLETE###" not in response_text:
            simulation["completion_acknowledgments"] = acknowledgment_count + 1
            logger.info(
                f"ðŸ“ Parent acknowledged completion #{acknowledgment_count + 1} for {family_id}"
            )

        # Let the LLM signal completion naturally
        if "###COMPLETE###" in response_text:
            logger.info(f"ðŸ›‘ Test mode: Interview complete for {family_id} (guidelines ready: {guidelines_ready})")
            return None

        return response_text

    def _format_background(self, background: dict) -> str:
        """Format background dict into readable text (DEPRECATED - use _format_background_naturally)"""
        lines = []
        for key, value in background.items():
            if isinstance(value, dict):
                lines.append(f"{key}:")
                for k, v in value.items():
                    lines.append(f"  - {k}: {v}")
            else:
                lines.append(f"{key}: {value}")
        return "\n".join(lines)

    def _format_background_naturally(self, background: dict) -> str:
        """Format background as natural conversational text, not bullet points"""
        parts = []

        # Handle milestones
        if "milestones" in background:
            milestones = background["milestones"]
            if isinstance(milestones, dict):
                milestone_texts = []
                for key, value in milestones.items():
                    if value and str(value).lower() not in ["n/a", "unknown", "×œ× ×¨×œ×•×•× ×˜×™"]:
                        milestone_texts.append(str(value))
                if milestone_texts:
                    parts.append(f"×”×ª×¤×ª×—×•×ª×™×ª: {', '.join(milestone_texts[:2])}")

        # Handle family context
        if "family_context" in background:
            ctx = background["family_context"]
            if ctx:
                parts.append(f"×‘×ž×©×¤×—×”: {ctx}")

        # Handle other background info
        for key, value in background.items():
            if key not in ["milestones", "family_context"] and value:
                if isinstance(value, str):
                    parts.append(f"{value}")

        return ". ".join(parts) + "." if parts else ""

    def _format_context(self, context: dict) -> str:
        """Format context dict into readable text"""
        return "\n".join([f"{k}: {v}" for k, v in context.items()])

    def stop_simulation(self, family_id: str):
        """Stop active simulation"""
        if family_id in self.active_simulations:
            del self.active_simulations[family_id]


# Global instance
_parent_simulator_instance = None


def get_parent_simulator() -> ParentSimulator:
    """Get singleton instance"""
    global _parent_simulator_instance
    if _parent_simulator_instance is None:
        _parent_simulator_instance = ParentSimulator()
    return _parent_simulator_instance
