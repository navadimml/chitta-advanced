"""
Development-only routes for testing and debugging
"""

from fastapi import APIRouter, HTTPException
from typing import Literal
import logging
from datetime import datetime

from app.services.session_service import get_session_service
from app.services.lifecycle_manager import get_lifecycle_manager
from app.services.prerequisite_service import get_prerequisite_service

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/dev", tags=["Development"])


# Test scenarios with different stages of completion
TEST_SCENARIOS = {
    "early_conversation": {
        "description": "Early conversation - basic info only",
        "data": {
            "child_name": "×“× ×™",
            "age": 3,
            "gender": "male",
            "primary_concerns": ["speech"],
        },
        "completeness": 0.3,
        "message_count": 3,
    },
    "guidelines_ready": {
        "description": "Rich knowledge - guidelines should generate",
        "data": {
            "child_name": "×“× ×™",
            "age": 3,
            "gender": "male",
            "primary_concerns": ["speech", "social"],
            "concern_details": "×“× ×™ ×œ× ××“×‘×¨ ×”×¨×‘×” ×•××ª×§×©×” ×œ×©×—×§ ×¢× ×™×œ×“×™× ××—×¨×™×. ×›×©×”×•× ××©×—×§ ×‘×’×Ÿ, ×”×•× × ×•×˜×” ×œ×©×—×§ ×œ×‘×“ ×•×œ× ××’×™×‘ ×›×©×™×œ×“×™× ×× ×¡×™× ×œ×”×¦×˜×¨×£ ××œ×™×•. ×”×•× ×œ× ××©×ª××© ×‘××™×œ×™× ×”×¨×‘×”, ×‘×¢×™×§×¨ ××¦×‘×™×¢ ××• ××•×©×š ××•×ª×™ ×œ××” ×©×”×•× ×¨×•×¦×”.",
            "strengths": "×“× ×™ ××•×”×‘ ×œ×‘× ×•×ª ×¢× ×§×•×‘×™×•×ª ×•×™×© ×œ×• ×“××™×•×Ÿ ××“×”×™×. ×”×•× ×™×›×•×œ ×œ×‘× ×•×ª ××’×“×œ×™× ×’×‘×•×”×™× ×•××•×¨×›×‘×™×. ×”×•× ×’× ××•×”×‘ ×¡×¤×¨×™× ×•×™×›×•×œ ×œ×”×ª×¨×›×– ×‘×”× ×œ×–××Ÿ ××¨×•×š.",
            "developmental_history": "×“× ×™ × ×•×œ×“ ×‘×–××Ÿ, ×”×ª×¤×ª×—×•×ª ×ª×§×™× ×” ×¢×“ ×’×™×œ ×©× ×” ×•×—×¦×™, ××– ×”×—×œ×• ×”×§×©×™×™× ×‘×©×¤×”. ×”×•× ×”×ª×—×™×œ ×œ×œ×›×ª ×‘×–××Ÿ (13 ×—×•×“×©×™×) ××‘×œ ×”××™×œ×™× ×”×¨××©×•× ×•×ª ×”×’×™×¢×• ×××•×—×¨ (24 ×—×•×“×©×™×).",
            "family_context": "×“× ×™ ×”×•× ×”×™×œ×“ ×”×¨××©×•×Ÿ ×‘××©×¤×—×”, ×™×© ×œ×• ××— ×§×˜×Ÿ ×‘×Ÿ ×©× ×”. ××‘× ×¢×•×‘×“ ×”×¨×‘×”, ××× ×‘×—×•×¤×©×ª ×œ×™×“×”. ×™×© ×§×©×¨ ×˜×•×‘ ×¢× ×¡×‘× ×•×¡×‘×ª× ×©×¢×•×–×¨×™× ×”×¨×‘×”.",
            "daily_routines": "×“× ×™ ×”×•×œ×š ×œ×’×Ÿ ×‘×‘×•×§×¨ (8:00-13:00), ××•×›×œ ×˜×•×‘, ×™×©×Ÿ ×”×™×˜×‘ ×‘×œ×™×œ×” (20:00-7:00). ××—×¨ ×”×¦×”×¨×™×™× ××©×—×§ ×‘×‘×™×ª ××• ×‘×¤××¨×§. ××•×”×‘ ×××•×“ ××ª ×–××Ÿ ×”×××‘×˜×™×”.",
        },
        "completeness": 0.8,
        "message_count": 12,
    },
    "videos_uploaded": {
        "description": "Videos uploaded - ready for analysis",
        "data": {
            "child_name": "×“× ×™",
            "age": 3,
            "gender": "male",
            "primary_concerns": ["speech", "social"],
            "concern_details": "×“× ×™ ×œ× ××“×‘×¨ ×”×¨×‘×” ×•××ª×§×©×” ×œ×©×—×§ ×¢× ×™×œ×“×™× ××—×¨×™×. ×›×©×”×•× ××©×—×§ ×‘×’×Ÿ, ×”×•× × ×•×˜×” ×œ×©×—×§ ×œ×‘×“ ×•×œ× ××’×™×‘ ×›×©×™×œ×“×™× ×× ×¡×™× ×œ×”×¦×˜×¨×£ ××œ×™×•.",
            "strengths": "×“× ×™ ××•×”×‘ ×œ×‘× ×•×ª ×¢× ×§×•×‘×™×•×ª ×•×™×© ×œ×• ×“××™×•×Ÿ ××“×”×™×. ×”×•× ×™×›×•×œ ×œ×‘× ×•×ª ××’×“×œ×™× ×’×‘×•×”×™× ×•××•×¨×›×‘×™×.",
            "developmental_history": "×“× ×™ × ×•×œ×“ ×‘×–××Ÿ, ×”×ª×¤×ª×—×•×ª ×ª×§×™× ×” ×¢×“ ×’×™×œ ×©× ×” ×•×—×¦×™, ××– ×”×—×œ×• ×”×§×©×™×™× ×‘×©×¤×”.",
            "family_context": "×“× ×™ ×”×•× ×”×™×œ×“ ×”×¨××©×•×Ÿ ×‘××©×¤×—×”, ×™×© ×œ×• ××— ×§×˜×Ÿ ×‘×Ÿ ×©× ×”.",
            "daily_routines": "×“× ×™ ×”×•×œ×š ×œ×’×Ÿ ×‘×‘×•×§×¨, ××•×›×œ ×˜×•×‘, ×™×©×Ÿ ×”×™×˜×‘ ×‘×œ×™×œ×”.",
        },
        "completeness": 0.85,
        "message_count": 15,
        "uploaded_videos": 3,  # Simulate videos uploaded
    },
    "living_dashboard": {
        "description": "ğŸŒŸ Living Dashboard demo - all artifacts ready",
        "data": {
            "child_name": "×“× ×™",
            "age": 3,
            "gender": "male",
            "primary_concerns": ["speech", "social"],
            "concern_details": "×“× ×™ ×œ× ××“×‘×¨ ×”×¨×‘×” ×•××ª×§×©×” ×œ×©×—×§ ×¢× ×™×œ×“×™× ××—×¨×™×.",
            "strengths": "×“× ×™ ××•×”×‘ ×œ×‘× ×•×ª ×¢× ×§×•×‘×™×•×ª ×•×™×© ×œ×• ×“××™×•×Ÿ ××“×”×™×.",
            "developmental_history": "×“× ×™ × ×•×œ×“ ×‘×–××Ÿ, ×”×ª×¤×ª×—×•×ª ×ª×§×™× ×” ×¢×“ ×’×™×œ ×©× ×” ×•×—×¦×™.",
            "family_context": "×“× ×™ ×”×•× ×”×™×œ×“ ×”×¨××©×•×Ÿ ×‘××©×¤×—×”.",
            "daily_routines": "×“× ×™ ×”×•×œ×š ×œ×’×Ÿ ×‘×‘×•×§×¨, ××•×›×œ ×˜×•×‘, ×™×©×Ÿ ×”×™×˜×‘.",
        },
        "completeness": 0.95,
        "message_count": 15,
        "uploaded_videos": 3,
        "seed_artifacts": True,  # Special flag to seed mock artifacts
    },
}


@router.post("/seed/{scenario}")
async def seed_test_scenario(
    scenario: Literal["early_conversation", "guidelines_ready", "videos_uploaded", "living_dashboard"],
    family_id: str = "dev_test_family",
    generate_artifacts: bool = False
):
    """
    ğŸ”§ DEV ONLY: Seed a test scenario with pre-populated data

    This allows you to quickly test features at different stages without
    going through the full conversation flow.

    Available scenarios:
    - early_conversation: Basic info only, no guidelines yet
    - guidelines_ready: Rich knowledge, triggers guideline generation
    - videos_uploaded: Simulates videos uploaded, ready for analysis

    Args:
        scenario: Which test scenario to seed
        family_id: Family ID to use (default: dev_test_family)
        generate_artifacts: If True, triggers artifact generation (SLOW - 2+ min)
                          If False (default), only seeds data (FAST - instant)

    Returns the seeded session state
    """

    scenario_config = TEST_SCENARIOS[scenario]

    logger.info(f"ğŸŒ± Seeding test scenario '{scenario}' for family '{family_id}'")

    # Get services
    session_service = get_session_service()
    lifecycle_manager = get_lifecycle_manager()
    prereq_service = get_prerequisite_service()

    # Create/update session
    session = session_service.get_or_create_session(family_id)
    session_service.update_extracted_data(family_id, scenario_config["data"])
    session.completeness = scenario_config["completeness"]

    # Add realistic conversation history based on extracted data
    # This allows artifact generation to extract meaningful content
    child_name = scenario_config["data"].get("child_name", "×”×™×œ×“/×”")
    age = scenario_config["data"].get("age", 3)
    concerns = scenario_config["data"].get("concern_details", "")
    strengths = scenario_config["data"].get("strengths", "")
    dev_history = scenario_config["data"].get("developmental_history", "")
    family_ctx = scenario_config["data"].get("family_context", "")
    routines = scenario_config["data"].get("daily_routines", "")

    # Build realistic conversation turns
    conversation_turns = [
        ("user", f"×©×œ×•×, ×× ×™ ×¨×•×¦×” ×œ×“×‘×¨ ×¢×œ {child_name}"),
        ("assistant", f"×©×œ×•×! ×©××—×” ×œ×”×›×™×¨. {child_name} - ×©× ×™×¤×”. ×‘×Ÿ ×›××” ×”×•×/×”×™×?"),
        ("user", f"{child_name} ×‘×Ÿ/×‘×ª {age}"),
        ("assistant", "×ª×•×“×”. ××” ×”×“××’×” ×”×¢×™×§×¨×™×ª ×©×œ×š ×œ×’×‘×™ ×”×”×ª×¤×ª×—×•×ª ×©×œ×•/×”?"),
        ("user", concerns if concerns else "×™×© ×œ×™ ×›××” ×“××’×•×ª"),
        ("assistant", "×× ×™ ××‘×™× ×”. ×¡×¤×¨×™ ×œ×™ ×™×•×ª×¨ ×¢×œ ×”×—×•×–×§×•×ª ×©×œ×•/×” - ×‘××” ×”×•×/×”×™× ××¦×˜×™×™×Ÿ/×ª?"),
        ("user", strengths if strengths else "×™×© ×œ×•/×” ×”×¨×‘×” ×—×•×–×§×•×ª"),
        ("assistant", "× ×”×“×¨. ××™×š ×”×™×ª×” ×”×”×ª×¤×ª×—×•×ª ×©×œ×•/×” ×¢×“ ×›×”?"),
        ("user", dev_history if dev_history else "×”×ª×¤×ª×—×•×ª ×ª×§×™× ×” ×‘×¢×™×§×¨×•×Ÿ"),
        ("assistant", "×ª×•×“×”. ×¡×¤×¨×™ ×œ×™ ×¢×œ ×”××©×¤×—×” ×•×”×¡×‘×™×‘×” ×©×œ×›×"),
        ("user", family_ctx if family_ctx else "××©×¤×—×” ×¨×’×™×œ×”"),
        ("assistant", "××” × ×¨××” ×™×•× ×˜×™×¤×•×¡×™ ××¦×œ×›×?"),
        ("user", routines if routines else "×™×•× ×¨×’×™×œ, ×’×Ÿ ×‘×‘×•×§×¨"),
    ]

    # Add only the number of turns specified in scenario
    for i, (role, content) in enumerate(conversation_turns[:scenario_config["message_count"]]):
        session.conversation_history.append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        })

    # Handle video upload simulation
    if scenario_config.get("uploaded_videos"):
        from app.models.family_state import Video
        from app.services.mock_graphiti import get_mock_graphiti

        graphiti = get_mock_graphiti()
        state = graphiti.get_or_create_state(family_id)

        for i in range(scenario_config["uploaded_videos"]):
            video = Video(
                id=f"vid_{i+1}",
                scenario=["××¨×•×—×ª ×‘×•×§×¨", "××©×—×§ ×—×•×¤×©×™", "×–××Ÿ ×××‘×˜×™×”"][i % 3],
                uploaded_at=datetime.now(),
                duration_seconds=60 + i * 30,
            )
            state.videos_uploaded.append(video)

        logger.info(f"ğŸ“¹ Simulated {len(state.videos_uploaded)} videos uploaded")

    # ğŸŒŸ Living Dashboard: Seed mock artifacts for demo
    if scenario_config.get("seed_artifacts"):
        from app.models.artifact import Artifact

        logger.info("ğŸŒŸ Seeding Living Dashboard demo artifacts...")

        # Mock Parent Report (markdown with sections for Living Documents)
        parent_report_content = """# ×“×•×— ×”×ª×¤×ª×—×•×ª - ×“× ×™

## ×¡×™×›×•× ×›×œ×œ×™

×“× ×™ ×”×•× ×™×œ×“ ×‘×Ÿ 3 ×¢× ×™×›×•×œ×•×ª ×§×•×’× ×™×˜×™×‘×™×•×ª ×˜×•×‘×•×ª. ×”×•× ××¨××” ×¢× ×™×™×Ÿ ×¨×‘ ×‘×¤×¢×™×œ×•×™×•×ª ×‘× ×™×™×” ×•××©×—×§×™ ×“××™×•×Ÿ.
×™×©× × ×ª×—×•××™× ×”×“×•×¨×©×™× ×ª××™×›×”, ×‘××™×•×—×“ ×‘×ª×—×•× ×”×ª×§×©×•×¨×ª ×•×”××™× ×˜×¨××§×¦×™×” ×”×—×‘×¨×ª×™×ª.

## ×”×ª×¤×ª×—×•×ª ××•×˜×•×¨×™×ª

×“× ×™ ××¨××” ×”×ª×¤×ª×—×•×ª ××•×˜×•×¨×™×ª ×ª×§×™× ×” ×œ×’×™×œ×•. ×”×•× ×™×›×•×œ ×œ×¨×•×¥, ×œ×§×¤×•×¥ ×•×œ×˜×¤×¡.
×”××•×˜×•×¨×™×§×” ×”×¢×“×™× ×” ×©×œ×• ×˜×•×‘×” - ×”×•× ×‘×•× ×” ××’×“×œ×™× ×’×‘×•×”×™× ×•××•×¨×›×‘×™× ×¢× ×§×•×‘×™×•×ª.

## ×ª×§×©×•×¨×ª ×•×©×¤×”

×–×”×• ×ª×—×•× ×©×“×•×¨×© ×ª×©×•××ª ×œ×‘. ×“× ×™ ××©×ª××© ×‘××™×œ×™× ×‘×•×“×“×•×ª ×•×‘×¢×™×§×¨ ××ª×§×©×¨ ×‘×××¦×¢×•×ª ×”×¦×‘×¢×” ×•××©×™×›×”.
×”×•× ××‘×™×Ÿ ×”×•×¨××•×ª ×¤×©×•×˜×•×ª ××š ××ª×§×©×” ×œ×‘×˜× ××ª ×¢×¦××• ××™×œ×•×œ×™×ª.

### ×”××œ×¦×•×ª ×œ×ª×§×©×•×¨×ª
- ×œ×¢×•×“×“ ×ª×§×©×•×¨×ª ××™×œ×•×œ×™×ª ×‘×›×œ ×”×–×“×× ×•×ª
- ×œ×”×©×ª××© ×‘×ª××•× ×•×ª ×•××™×œ×™× ×™×—×“
- ×œ×©×™×¨ ×©×™×¨×™× ×¤×©×•×˜×™× ×¢× ×—×–×¨×•×ª

## ×”×ª×¤×ª×—×•×ª ×—×‘×¨×ª×™×ª-×¨×’×©×™×ª

×“× ×™ × ×•×˜×” ×œ×©×—×§ ×œ×‘×“ ×•××ª×§×©×” ×œ×”×¦×˜×¨×£ ×œ××©×—×§ ×¢× ×™×œ×“×™× ××—×¨×™×.
×”×•× ×œ× ×ª××™×“ ××’×™×‘ ×›×©×™×œ×“×™× ×× ×¡×™× ×œ×©×ª×£ ××•×ª×• ×‘××©×—×§.

## ×—×•×–×§×•×ª

- ×“××™×•×Ÿ ×¢×©×™×¨ ×•×™×›×•×œ×ª ×‘× ×™×™×” ××¨×©×™××”
- ×™×›×•×œ×ª ×¨×™×›×•×– ×’×‘×•×”×” ×‘×¤×¢×™×œ×•×™×•×ª ×©××¢× ×™×™× ×•×ª ××•×ª×•
- ×¡×§×¨× ×•×ª ×•×”×ª×¢× ×™×™× ×•×ª ×‘×¡×¤×¨×™×

## ×”××œ×¦×•×ª

1. ×”×ª×™×™×¢×¦×•×ª ×¢× ×§×œ×™× ××™×ª ×ª×§×©×•×¨×ª
2. ×”×¦×˜×¨×¤×•×ª ×œ×§×‘×•×¦×ª ××©×—×§ ×§×˜× ×”
3. ×”××©×š ×¢×™×“×•×“ ×¤×¢×™×œ×•×™×•×ª ×‘× ×™×™×” ×•×™×¦×™×¨×”
"""

        parent_report = Artifact(
            artifact_id="baseline_parent_report",
            artifact_type="report",
            status="ready",
            content=parent_report_content,
            content_format="markdown",
            created_at=datetime.now(),
            ready_at=datetime.now()
        )
        session.add_artifact(parent_report)

        # Mock Video Guidelines (JSON) - Structure matches VideoGuidelinesView component
        guidelines_content = {
            "child_name": "×“× ×™",
            "introduction": "×”×¡×¨×˜×•× ×™× ×©×ª×¦×œ××• ×™×¢×–×¨×• ×œ× ×• ×œ×”×‘×™×Ÿ ×˜×•×‘ ×™×•×ª×¨ ××ª ×“× ×™ ×‘×¡×‘×™×‘×” ×”×˜×‘×¢×™×ª ×©×œ×•. ×× ×—× ×• ×œ× ××—×¤×©×™× '×‘×™×¦×•×¢×™×' - ××œ× ×¨×’×¢×™× ×××™×ª×™×™× ××”×—×™×™×. ×”×¡×¨×˜×•× ×™× ×”××œ×” ×™××¤×©×¨×• ×œ× ×• ×œ×¨××•×ª ××ª ×”×—×•×–×§×•×ª ×©×œ ×“× ×™, ×œ×”×‘×™×Ÿ ××ª ×¡×’× ×•×Ÿ ×”×ª×§×©×•×¨×ª ×©×œ×•, ×•×œ×–×”×•×ª ×”×–×“×× ×•×™×•×ª ×œ×ª××™×›×” ×‘×”×ª×¤×ª×—×•×ª ×©×œ×•.",
            "estimated_duration": "15-20 ×“×§×•×ª ×¡×”×´×›",
            "focus_areas": ["×ª×§×©×•×¨×ª", "××™× ×˜×¨××§×¦×™×” ×—×‘×¨×ª×™×ª", "××©×—×§"],
            "scenarios": [
                {
                    "title": "××¨×•×—×ª ×‘×•×§×¨",
                    "context": "×¨×’×¢ ×™×•××™×•××™ ×©×××¤×©×¨ ×œ×¨××•×ª ×ª×§×©×•×¨×ª ×˜×‘×¢×™×ª",
                    "duration": "3-5 ×“×§×•×ª",
                    "what_to_film": "×¦×œ××• ××ª ×“× ×™ ×‘××”×œ×š ××¨×•×—×ª ×”×‘×•×§×¨ ×”×¨×’×™×œ×”. ×©×™××• ××ª ×”×˜×œ×¤×•×Ÿ ×‘××§×•× ×™×¦×™×‘ (××¤×©×¨ ×œ×”×™×©×¢×Ÿ ×¢×œ ×§×•×¤×¡×” ××• ×¡×¤×¨) ×›×š ×©×¨×•××™× ××ª ×“× ×™ ×•××ª ××™ ×©××•×›×œ ××™×ª×•. ×¤×©×•×˜ ×ª× ×”×’×• ×›×¨×’×™×œ - ×“×‘×¨×•, ××›×œ×•, ×”×™×• ×˜×‘×¢×™×™×.",
                    "why_matters": "××¨×•×—×•×ª ×”×Ÿ ×”×–×“×× ×•×ª ××¦×•×™× ×ª ×œ×¨××•×ª ××™×š ×“× ×™ ××ª×§×©×¨ ×›×©×”×•× ×¨×•×¦×” ××©×”×•, ××™×š ×”×•× ××’×™×‘ ×œ×©×™×—×”, ×•××™×š ×”×•× ××ª××•×“×“ ×¢× ×©×’×¨×” ×™×•××™×•××™×ª.",
                    "analyst_context": {
                        "guideline_title": "××¨×•×—×ª ×‘×•×§×¨",
                        "look_for": ["×™×•×–××ª ×ª×§×©×•×¨×ª", "×‘×§×©×•×ª", "×§×©×¨ ×¢×™×Ÿ", "×ª×’×•×‘×” ×œ×¤× ×™×•×ª"]
                    }
                },
                {
                    "title": "××©×—×§ ×—×•×¤×©×™",
                    "context": "×”×–×“×× ×•×ª ×œ×¨××•×ª ×™×¦×™×¨×ª×™×•×ª ×•×“××™×•×Ÿ",
                    "duration": "5-7 ×“×§×•×ª",
                    "what_to_film": "×ª× ×• ×œ×“× ×™ ×œ×‘×—×•×¨ ×‘××” ×œ×©×—×§ - ×§×•×‘×™×•×ª, ×‘×•×‘×•×ª, ××›×•× ×™×•×ª, ×›×œ ××” ×©×”×•× ××•×”×‘. ×©×‘×• ×œ×™×“×• ×¢×œ ×”×¨×¦×¤×” ×¢× ×”×˜×œ×¤×•×Ÿ. ××ª× ×™×›×•×œ×™× ×œ×©×—×§ ××™×ª×• ××• ×¤×©×•×˜ ×œ×©×‘×ª ×œ×™×“ ×•×œ×¦×¤×•×ª. ××œ ×ª×›×•×•× ×• ××ª ×”××©×—×§ - ×ª× ×• ×œ×• ×œ×”×•×‘×™×œ.",
                    "why_matters": "××©×—×§ ×—×•×¤×©×™ ××¨××” ×œ× ×• ××ª ×¢×•×œ× ×”×“××™×•×Ÿ ×©×œ ×“× ×™, ××™×š ×”×•× ×¤×•×ª×¨ ×‘×¢×™×•×ª, ×•××™×š ×”×•× ××ª×™×™×—×¡ ×œ×¦×¢×¦×•×¢×™× ×•×œ×× ×©×™× ×¡×‘×™×‘×•.",
                    "analyst_context": {
                        "guideline_title": "××©×—×§ ×—×•×¤×©×™",
                        "look_for": ["××©×—×§ ×¡×™××‘×•×œ×™", "×¨×™×›×•×–", "×™×¦×™×¨×ª×™×•×ª", "×©×™×ª×•×£"]
                    }
                },
                {
                    "title": "×–××Ÿ ×××‘×˜×™×”",
                    "context": "×¨×’×¢ ×©×œ ×§×¨×‘×” ×•×•×™×¡×•×ª ×—×•×©×™",
                    "duration": "3-5 ×“×§×•×ª",
                    "what_to_film": "×¦×œ××• ××ª ×“× ×™ ×‘×–××Ÿ ×”×××‘×˜×™×” ××• ××©×—×§ ×¢× ××™×. ×©×™××• ×œ×‘ ×œ×‘×˜×™×—×•×ª - ×”×˜×œ×¤×•×Ÿ ×¦×¨×™×š ×œ×”×™×•×ª ×‘××§×•× ×™×‘×© ×•×™×¦×™×‘. ×¦×œ××• ××™×š ×”×•× ××’×™×‘ ×œ××™×, ×œ×‘×•×¢×•×ª ×¡×‘×•×Ÿ, ×œ×¦×¢×¦×•×¢×™ ×××‘×˜×™×”.",
                    "why_matters": "×–××Ÿ ×××‘×˜×™×” ××¨××” ×œ× ×• ××™×š ×“× ×™ ××ª××•×“×“ ×¢× ×—×•×•×™×•×ª ×—×•×©×™×•×ª (××™×, ×˜××¤×¨×˜×•×¨×”, ××’×¢) ×•××™×š ×”×•× ××©×ª×£ ×¤×¢×•×œ×” ×‘×©×’×¨×” ×™×•××™×•××™×ª.",
                    "analyst_context": {
                        "guideline_title": "×–××Ÿ ×××‘×˜×™×”",
                        "look_for": ["×•×™×¡×•×ª ×—×•×©×™", "×©×™×ª×•×£ ×¤×¢×•×œ×”", "×”× ××”", "×ª×§×©×•×¨×ª"]
                    }
                }
            ],
            "general_tips": [
                "×¦×œ××• ×‘×¡×‘×™×‘×” ×˜×‘×¢×™×ª ×•×¨×’×•×¢×” - ×œ× ×¦×¨×™×š ×œ×¡×“×¨ ××• ×œ×”×›×™×Ÿ ××©×”×• ××™×•×—×“",
                "××œ ×ª× ×¡×• ×œ×›×•×•×Ÿ ××ª ×“× ×™ ××• ×œ×‘×§×© ××× ×• ×œ×¢×©×•×ª ×“×‘×¨×™× - ×ª× ×• ×œ×• ×œ×”×™×•×ª ×˜×‘×¢×™",
                "×ª××•×¨×” ×˜×•×‘×” ×—×©×•×‘×” - ×¢×“×™×£ ××•×¨ ×˜×‘×¢×™ ××”×—×œ×•×Ÿ",
                "×× ×“× ×™ ×©× ×œ×‘ ×œ××¦×œ××” ×•××•×¤×¨×¢ - ×¢×¦×¨×• ×•×—×›×• ×©×™×ª×¨×’×œ, ××• × ×¡×• ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨",
                "××™×Ÿ '×¡×¨×˜×•×Ÿ ××•×©×œ×' - ×’× ×¨×’×¢×™× ×©×œ ×ª×¡×›×•×œ ××• ×§×•×©×™ ×”× ×‘×¢×œ×™ ×¢×¨×š"
            ]
        }

        import json
        guidelines = Artifact(
            artifact_id="baseline_video_guidelines",
            artifact_type="guidelines",
            status="ready",
            content=json.dumps(guidelines_content, ensure_ascii=False),
            content_format="json",
            created_at=datetime.now(),
            ready_at=datetime.now()
        )
        session.add_artifact(guidelines)

        # Add journal entries to state
        from app.models.family_state import JournalEntry, Artifact as FamilyArtifact
        graphiti = get_mock_graphiti()
        state = graphiti.get_or_create_state(family_id)

        state.journal_entries = [
            JournalEntry(
                id="entry_1",
                content="×”×™×•× ×“× ×™ ×××¨ '××™×' ×‘×¤×¢× ×”×¨××©×•× ×”! ×”×ª×¨×’×©×ª×™ ×××•×“.",
                timestamp=datetime.now()
            ),
            JournalEntry(
                id="entry_2",
                content="×©×™×—×§× ×• ×™×—×“ ×‘×§×•×‘×™×•×ª ×•×”×•× ×‘× ×” ××’×“×œ ×¢× ×§.",
                timestamp=datetime.now()
            ),
        ]

        # Set child info
        state.child = {"name": "×“× ×™", "age": 3}

        # ğŸ”§ CRITICAL: Also add artifacts to FamilyState.artifacts (for /state endpoint)
        # The frontend reads from state.artifacts, not session.artifacts
        state.artifacts["baseline_parent_report"] = FamilyArtifact(
            type="baseline_parent_report",
            content={"raw": parent_report_content, "format": "markdown"},
            created_at=datetime.now()
        )
        state.artifacts["baseline_video_guidelines"] = FamilyArtifact(
            type="baseline_video_guidelines",
            content=guidelines_content,  # Already a dict
            created_at=datetime.now()
        )

        # ğŸ“œ Add historical versions of artifacts for demo
        # This demonstrates the "version history" feature in ChildSpace
        from datetime import timedelta

        # Historical parent report (version 1 - older, shorter)
        old_report_content = """# ×“×•×— ×”×ª×¤×ª×—×•×ª ×¨××©×•× ×™ - ×“× ×™

## ×¡×™×›×•× ×›×œ×œ×™

×“× ×™ ×”×•× ×™×œ×“ ×‘×Ÿ 3. × ×¦×¤×• ×§×©×™×™× ×‘×ª×—×•× ×”×ª×§×©×•×¨×ª ×•×”××™× ×˜×¨××§×¦×™×” ×”×—×‘×¨×ª×™×ª.

## ×ª×—×•××™× ×œ×‘×“×™×§×”

- ×ª×§×©×•×¨×ª ×•×©×¤×”
- ×”×ª×¤×ª×—×•×ª ×—×‘×¨×ª×™×ª

## ×”××œ×¦×•×ª ×¨××©×•× ×™×•×ª

1. ×œ×”××©×™×š ×‘××¢×§×‘
2. ×œ×©×§×•×œ ×”×¤× ×™×” ×œ×”×¢×¨×›×” ××§×¦×•×¢×™×ª
"""
        old_report = Artifact(
            artifact_id="baseline_parent_report_v1",
            artifact_type="report",
            status="ready",
            content=old_report_content,
            content_format="markdown",
            created_at=datetime.now() - timedelta(days=7),
            ready_at=datetime.now() - timedelta(days=7)
        )
        session.add_artifact(old_report)

        # Even older report (version 0 - initial assessment)
        initial_report_content = """# ×”×¢×¨×›×” ×¨××©×•× ×™×ª - ×“× ×™

## ×¤×¨×˜×™× ×‘×¡×™×¡×™×™×

×©×: ×“× ×™
×’×™×œ: 3
×“××’×•×ª ×¢×™×§×¨×™×•×ª: ×ª×§×©×•×¨×ª

## ×”×¢×¨×•×ª

×××ª×™×Ÿ ×œ××™×“×¢ × ×•×¡×£ ××”×”×•×¨×™×.
"""
        initial_report = Artifact(
            artifact_id="baseline_parent_report_v0",
            artifact_type="report",
            status="ready",
            content=initial_report_content,
            content_format="markdown",
            created_at=datetime.now() - timedelta(days=14),
            ready_at=datetime.now() - timedelta(days=14)
        )
        session.add_artifact(initial_report)

        logger.info(f"âœ… Seeded {len(session.artifacts)} artifacts (including history) for Living Dashboard demo")

    # Build context for card evaluation
    session_data = {
        "family_id": family_id,
        "extracted_data": session.extracted_data.model_dump(),
        "message_count": len(session.conversation_history),
        "artifacts": session.artifacts,
        "completeness": session.completeness,
    }
    context = prereq_service.get_context_for_cards(session_data)
    context["conversation_history"] = session.conversation_history

    # For guidelines_ready scenario, we need to pre-generate interview_summary
    # Otherwise the guidelines generation will fail due to missing dependency
    if scenario == "guidelines_ready" and not generate_artifacts:
        logger.info(f"ğŸ“ Pre-generating interview_summary for guidelines_ready scenario...")
        from app.services.artifact_generation_service import ArtifactGenerationService
        from app.services.llm.factory import create_llm_provider

        # Create artifact service
        llm_provider = create_llm_provider("gemini", "gemini-2.5-pro")
        artifact_service = ArtifactGenerationService(llm_provider)

        # Generate interview_summary artifact directly
        try:
            interview_summary_artifact = await artifact_service.generate_interview_summary(
                artifact_id="baseline_interview_summary",
                session_data={
                    "family_id": family_id,
                    "extracted_data": session.extracted_data.model_dump(),
                    "conversation_history": session.conversation_history,
                    "artifacts": {}
                }
            )
            session.add_artifact(interview_summary_artifact)
            logger.info(f"âœ… Pre-generated interview_summary: {interview_summary_artifact.status}")
        except Exception as e:
            logger.error(f"âŒ Failed to pre-generate interview_summary: {e}")
            import traceback
            traceback.print_exc()

    # Optionally trigger artifact generation (SLOW - 2+ min for guidelines)
    result = None
    if generate_artifacts:
        logger.info(f"â³ Triggering artifact generation (this may take 2+ minutes)...")
        result = await lifecycle_manager.process_lifecycle_events(
            family_id=family_id,
            context=context,
            session=session
        )
        logger.info(f"âœ… Seeded scenario '{scenario}': {result['artifacts_generated']}")
    else:
        logger.info(f"âœ… Seeded scenario '{scenario}' (data only, artifacts pre-generated if needed)")

    return {
        "success": True,
        "scenario": scenario,
        "description": scenario_config["description"],
        "family_id": family_id,
        "generate_artifacts": generate_artifacts,
        "session_state": {
            "completeness": session.completeness,
            "message_count": len(session.conversation_history),
            "artifacts": [
                {
                    "artifact_id": a.artifact_id,
                    "status": a.status,
                    "is_ready": a.is_ready,
                }
                for a in session.artifacts.values()
            ],
        },
        "lifecycle_result": result,
    }


@router.get("/scenarios")
async def list_scenarios():
    """
    ğŸ”§ DEV ONLY: List all available test scenarios
    """
    return {
        "scenarios": {
            name: {
                "name": name,
                "description": config["description"],
                "completeness": config["completeness"],
                "message_count": config["message_count"],
            }
            for name, config in TEST_SCENARIOS.items()
        }
    }


@router.delete("/reset/{family_id}")
async def reset_session(family_id: str):
    """
    ğŸ”§ DEV ONLY: Reset a session completely
    """
    session_service = get_session_service()

    # For in-memory mode, just recreate the session
    session_service.sessions.pop(family_id, None)

    logger.info(f"ğŸ—‘ï¸ Reset session for family '{family_id}'")

    return {
        "success": True,
        "family_id": family_id,
        "message": "Session reset"
    }
