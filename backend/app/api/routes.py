"""
API Routes for Chitta
"""

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import List, Optional
from datetime import datetime

from app.core.app_state import app_state
from app.services.llm.base import Message
from app.services.conversation_service import get_conversation_service
from app.services.interview_service import get_interview_service
# Wu Wei Architecture: Import config-driven UI components
from app.config.card_generator import get_card_generator
from app.config.view_manager import get_view_manager
# Demo Mode: Import demo orchestrator
from app.services.demo_orchestrator_service import get_demo_orchestrator
# State-based architecture
from app.services.mock_graphiti import get_mock_graphiti
from app.services.state_derivation import (
    derive_active_cards,
    derive_contextual_greeting,
    derive_suggestions
)
# Parent Simulator (Test Mode)
from app.services.parent_simulator import get_parent_simulator

router = APIRouter()

# === Request/Response Models ===

class SendMessageRequest(BaseModel):
    family_id: str
    message: str
    parent_name: Optional[str] = "×”×•×¨×”"

class SendMessageResponse(BaseModel):
    response: str
    stage: str
    ui_data: dict

class CompleteInterviewResponse(BaseModel):
    success: bool
    video_guidelines: dict
    next_stage: str

class UploadVideoRequest(BaseModel):
    family_id: str
    video_id: str
    scenario: str
    duration_seconds: int

class JournalEntryRequest(BaseModel):
    family_id: str
    content: str
    category: str  # "×”×ª×§×“××•×ª", "×ª×¦×¤×™×ª", "××ª×’×¨"

class JournalEntryResponse(BaseModel):
    entry_id: str
    timestamp: str
    success: bool

class AvailableViewsResponse(BaseModel):
    """Response model for available views"""
    family_id: str
    phase: str
    available_views: List[str]

class ViewContentResponse(BaseModel):
    """Response model for view content"""
    view_id: str
    view_name: str
    view_name_en: str
    available: bool
    content: Optional[dict] = None
    reason_unavailable: Optional[str] = None

# === Wu Wei: Artifact Response Models ===

class ArtifactResponse(BaseModel):
    """Response model for artifact"""
    artifact_id: str
    artifact_type: str
    status: str  # pending, generating, ready, error
    content: Optional[str] = None
    content_format: str = "markdown"
    created_at: str
    ready_at: Optional[str] = None
    error_message: Optional[str] = None

class SessionArtifactsResponse(BaseModel):
    """Response model for session artifacts list"""
    family_id: str
    artifacts: List[dict]

class ArtifactActionRequest(BaseModel):
    """Request model for artifact user actions"""
    family_id: str
    action: str  # "view", "download", "decline"

# === Demo Mode Response Models ===

class DemoStartRequest(BaseModel):
    """Request to start demo mode"""
    scenario_id: Optional[str] = "language_concerns"

class DemoStartResponse(BaseModel):
    """Response when starting demo"""
    demo_family_id: str
    scenario: dict
    first_message: dict
    demo_card: dict

class DemoNextResponse(BaseModel):
    """Response for next demo step"""
    step: int
    total_steps: int
    message: dict
    artifact_generated: Optional[dict] = None
    card_hint: Optional[str] = None
    demo_card: dict
    is_complete: bool

class DemoStopResponse(BaseModel):
    """Response when stopping demo"""
    success: bool
    message: str

# === Endpoints ===

@router.get("/")
async def root():
    """API root"""
    return {"message": "Chitta API", "version": "1.0.0"}

@router.post("/chat/send", response_model=SendMessageResponse)
async def send_message(request: SendMessageRequest):
    """
    ×©×œ×™×—×ª ×”×•×“×¢×” ×œ×¦'×™×˜×” - Real AI Conversation with Function Calling
    """
    if not app_state.initialized:
        raise HTTPException(status_code=500, detail="App not initialized")

    # Get services
    conversation_service = get_conversation_service()
    graphiti = get_mock_graphiti()
    knowledge_service = conversation_service.knowledge_service

    # ğŸ¯ LLM-based Intent Detection: Check for system actions (test/demo mode)
    # Use the intelligent intent detector instead of primitive string matching
    from app.prompts.intent_types import IntentCategory
    detected_intent = await knowledge_service.detect_unified_intent(request.message)

    # Handle system/developer actions
    if detected_intent.category == IntentCategory.ACTION_REQUEST:
        action = detected_intent.specific_action

        # ğŸ¬ Demo Mode
        if action == "start_demo":
            demo_orchestrator = get_demo_orchestrator()
            # Use demo orchestrator's logic to pick scenario
            scenario_id = "language_delay"  # Default scenario
            demo_result = await demo_orchestrator.start_demo(scenario_id)

            return SendMessageResponse(
                response=demo_result["first_message"]["content"],
                stage="demo",
                ui_data={
                    "demo_mode": True,
                    "demo_family_id": demo_result["demo_family_id"],
                    "demo_scenario": demo_result["scenario"],
                    "cards": [demo_result["demo_card"]],
                    "suggestions": ["×”××©×š ×“××•", "×¢×¦×•×¨ ×“××•", "×“×œ×’ ×œ×©×œ×‘ ×”×‘×"],
                    "progress": 0
                }
            )

        # ğŸ§ª Test Mode
        elif action == "start_test_mode":
            simulator = get_parent_simulator()
            personas = simulator.list_personas()

            # Build persona list
            persona_list = "\n".join([
                f"- {p['parent']}: {p['child']} - {p['concern']}"
                for p in personas[:5]  # Show first 5
            ])

            return SendMessageResponse(
                response=f"ğŸ§ª ××¦×‘ ×‘×“×™×§×”\n\n×”×‘× ×ª×™ ×©××ª ×¨×•×¦×” ×œ×‘×“×•×§ ××ª ×”××¢×¨×›×ª! ×™×© ×œ×™ {len(personas)} ×¤×¨×¡×•× ×•×ª ×”×•×¨×™× ××•×›× ×•×ª:\n\n{persona_list}\n\n×›×“×™ ×œ×”×ª×—×™×œ, ×”×©×ª××©×™ ×‘-API ×©×œ ××¦×‘ ×”×‘×“×™×§×” (/test/start) ××• ×‘×××©×§ ×”××™×•×—×“ ×œ××¤×ª×—×™×.",
                stage="interview",
                ui_data={
                    "test_mode_available": True,
                    "personas": personas,
                    "suggestions": ["×”××©×š ×©×™×—×” ×¨×’×™×œ×”"],
                    "cards": [],
                    "progress": 0
                }
            )

    # Save user message to state
    await graphiti.add_message(
        family_id=request.family_id,
        role="user",
        content=request.message
    )

    try:
        # Process message with real LLM and function calling
        result = await conversation_service.process_message(
            family_id=request.family_id,
            user_message=request.message,
            temperature=0.7
        )

        # Save assistant response to state
        await graphiti.add_message(
            family_id=request.family_id,
            role="assistant",
            content=result["response"]
        )

        # Get or create session for backward compatibility
        session = app_state.get_or_create_session(request.family_id)

        # Update session stage based on completeness
        if result["completeness"] >= 80:
            session["current_stage"] = "video_upload"
        else:
            session["current_stage"] = "interview"

        # ğŸŒŸ Wu Wei: Get artifacts for frontend
        interview_service = get_interview_service()
        interview_session = interview_service.get_or_create_session(request.family_id)

        # Sync artifacts to graphiti state (CRITICAL FIX!)
        # The state derivation checks state.artifacts, so we must sync them
        for artifact_id, artifact in interview_session.artifacts.items():
            if artifact.is_ready:  # Only sync ready artifacts
                await graphiti.add_artifact(
                    family_id=request.family_id,
                    artifact_type=artifact_id,
                    content={"status": "ready", "content": artifact.content}
                )

        # Convert artifacts to simplified format for UI
        artifacts_for_ui = {}
        for artifact_id, artifact in interview_session.artifacts.items():
            artifacts_for_ui[artifact_id] = {
                "exists": artifact.exists,
                "status": artifact.status,
                "artifact_type": artifact.artifact_type,
                "ready_at": artifact.ready_at.isoformat() if artifact.ready_at else None
            }

        # Get current state and derive UI elements
        state = graphiti.get_or_create_state(request.family_id)
        derived_cards = derive_active_cards(state)
        derived_suggestions = derive_suggestions(state)

        # Build UI data with real data from conversation service + derived UI
        ui_data = {
            "suggestions": derived_suggestions,  # Derived from state
            "cards": derived_cards,  # Derived from state
            "progress": result["completeness"] / 100,  # Convert to 0-1 scale
            "extracted_data": result.get("extracted_data", {}),
            "stats": result.get("stats", {}),
            "artifacts": artifacts_for_ui  # ğŸŒŸ Wu Wei: Include artifacts
        }

        return SendMessageResponse(
            response=result["response"],
            stage=session["current_stage"],
            ui_data=ui_data
        )

    except Exception as e:
        # Log error and return graceful fallback
        import logging
        logging.error(f"Error in send_message: {e}", exc_info=True)

        return SendMessageResponse(
            response="××¦×˜×¢×¨×ª, × ×ª×§×œ×ª×™ ×‘×‘×¢×™×” ×˜×›× ×™×ª. ×‘×•××™ × × ×¡×” ×©×•×‘.",
            stage="interview",
            ui_data={
                "suggestions": ["× ×¡×” ×©×•×‘", "×“×‘×¨ ×¢× ×ª××™×›×”"],
                "cards": [],
                "progress": 0,
                "error": str(e)
            }
        )

@router.post("/interview/complete", response_model=CompleteInterviewResponse)
async def complete_interview(family_id: str):
    """
    ×¡×™×•× ×¨××™×•×Ÿ ×•×™×¦×™×¨×ª ×”× ×—×™×•×ª ×•×™×“××•
    """
    session = app_state.get_or_create_session(family_id)

    # ×§×¨×™××” ×œ-LLM ×œ×¡×™×›×•×
    summary_result = await app_state.llm.chat_with_structured_output(
        messages=[Message(
            role="system",
            content="×¡×›× ××ª ×”×¨××™×•×Ÿ"
        )],
        response_schema={"interview_summary": {}, "video_guidelines": {}}
    )

    # ×©××™×¨×” ×‘-Graphiti
    child_uuid = session["child_uuid"]

    await app_state.graphiti.add_episode(
        name=f"interview_summary_{family_id}",
        episode_body=summary_result["interview_summary"],
        group_id=family_id
    )

    await app_state.graphiti.add_episode(
        name=f"video_guidelines_{family_id}",
        episode_body=summary_result["video_guidelines"],
        group_id=family_id
    )

    # ×¢×“×›×Ÿ session
    session["current_stage"] = "video_upload"
    session["video_guidelines"] = summary_result["video_guidelines"]

    return CompleteInterviewResponse(
        success=True,
        video_guidelines=summary_result["video_guidelines"],
        next_stage="video_upload"
    )

@router.post("/video/upload")
async def upload_video(request: UploadVideoRequest):
    """
    ×”×¢×œ××ª ×•×™×“××• (simulated)
    """
    session = app_state.get_or_create_session(request.family_id)

    # ×”×•×¡×£ ×•×™×“××• ×œsession
    video_data = {
        "video_id": request.video_id,
        "scenario": request.scenario,
        "duration_seconds": request.duration_seconds,
        "uploaded_at": datetime.now().isoformat()
    }

    session["videos"].append(video_data)

    # ×©××™×¨×” ×‘-Graphiti
    await app_state.graphiti.add_episode(
        name=f"video_upload_{request.video_id}",
        episode_body=video_data,
        group_id=request.family_id
    )

    total_videos = len(session["videos"])

    # ×‘×“×™×§×” ×× ×”×•×©×œ××• ×›×œ ×”×¡×¨×˜×•× ×™× ×”× ×“×¨×©×™×
    num_required = len(session.get("video_guidelines", {}).get("scenarios", []))
    if num_required == 0:
        num_required = 3  # ×‘×¨×™×¨×ª ××—×“×œ

    analysis_started = False
    if total_videos >= num_required:
        # ××¢×‘×¨ ××•×˜×•××˜×™ ×œ×©×œ×‘ × ×™×ª×•×—
        session["current_stage"] = "video_analysis"
        analysis_started = True

    return {
        "success": True,
        "video_id": request.video_id,
        "total_videos": total_videos,
        "required_videos": num_required,
        "analysis_started": analysis_started,
        "next_stage": session["current_stage"]
    }

@router.post("/video/analyze")
async def analyze_videos(family_id: str):
    """
    × ×™×ª×•×— ×›×œ ×”×•×™×“××•××™×
    """
    session = app_state.get_or_create_session(family_id)

    if not session["videos"]:
        raise HTTPException(status_code=400, detail="No videos to analyze")

    # ×§×¨×™××” ×œ-LLM ×œ× ×™×ª×•×—
    analysis_result = await app_state.llm.chat_with_structured_output(
        messages=[Message(
            role="system",
            content=f"× ×ª×— {len(session['videos'])} ×•×™×“××•××™×"
        )],
        response_schema={"behavioral_observations": [], "key_findings_summary": ""}
    )

    # ×©××™×¨×” ×‘-Graphiti
    await app_state.graphiti.add_episode(
        name=f"video_analysis_{family_id}",
        episode_body=analysis_result,
        group_id=family_id,
        reference_time=datetime.now()
    )

    # ×©××™×¨×ª ×ª×•×¦××•×ª × ×™×ª×•×— ×‘-session
    session["video_analysis"] = analysis_result

    # ××¢×‘×¨ ××•×˜×•××˜×™ ×œ×™×¦×™×¨×ª ×“×•×—×•×ª
    session["current_stage"] = "report_generation"

    # ×™×¦×™×¨×” ××•×˜×•××˜×™×ª ×©×œ ×“×•×—×•×ª
    await _generate_reports_internal(family_id, session)

    return {
        "success": True,
        "analysis": analysis_result,
        "next_stage": session["current_stage"]
    }

@router.post("/reports/generate")
async def generate_reports(family_id: str):
    """
    ×™×¦×™×¨×ª ×“×•×—×•×ª (××§×¦×•×¢×™ + ×œ×”×•×¨×”)
    """
    session = app_state.get_or_create_session(family_id)

    # ×™×¦×™×¨×ª ×“×•×—×•×ª ×‘×××¦×¢×•×ª ×”×¤×•× ×§×¦×™×” ×”×¤× ×™××™×ª
    await _generate_reports_internal(family_id, session)

    return {
        "success": True,
        "professional_report": session.get("professional_report"),
        "parent_report": session.get("parent_report"),
        "next_stage": session["current_stage"]
    }

@router.get("/timeline/{family_id}")
async def get_timeline(family_id: str):
    """
    ×§×‘×œ×ª timeline ×©×œ ×›×œ ×”××¡×¢ + UI state ×¢×“×›× ×™
    """
    # ×§×‘×œ×ª session
    session = app_state.get_or_create_session(family_id)

    # ×§×‘×œ×ª ×›×œ ×”-episodes
    episodes = app_state.graphiti.get_all_episodes(group_id=family_id)

    # ×”××¨×” ×œ×¤×•×¨××˜ timeline
    timeline = []
    for episode in episodes:
        timeline.append({
            "date": episode.reference_time.isoformat() if episode.reference_time else None,
            "type": _classify_episode_type(episode.name),
            "title": _generate_event_title(episode),
            "data": episode.body
        })

    # ××™×•×Ÿ ×œ×¤×™ ×ª××¨×™×š
    timeline.sort(key=lambda x: x["date"] if x["date"] else "", reverse=True)

    # ×™×¦×™×¨×ª contextual cards ×œ×¤×™ stage ×”× ×•×›×—×™
    current_stage = session.get("current_stage", "welcome")
    cards = _generate_cards(session)

    return {
        "timeline": timeline,
        "ui_data": {
            "cards": cards,
            "stage": current_stage
        }
    }

@router.post("/journal/entry", response_model=JournalEntryResponse)
async def add_journal_entry(request: JournalEntryRequest):
    """
    ×”×•×¡×¤×ª ×¨×©×•××” ×œ×™×•××Ÿ ×”×™×œ×“
    """
    session = app_state.get_or_create_session(request.family_id)

    # ×¦×•×¨ entry ID ×™×™×—×•×“×™
    import uuid
    entry_id = str(uuid.uuid4())
    timestamp = datetime.now().isoformat()

    # ×™×¦×™×¨×ª entry
    entry = {
        "entry_id": entry_id,
        "content": request.content,
        "category": request.category,
        "timestamp": timestamp
    }

    # ×”×•×¡×¤×” ×œ-session
    if "journal_entries" not in session:
        session["journal_entries"] = []
    session["journal_entries"].append(entry)

    # ×©××™×¨×” ×‘-Graphiti
    await app_state.graphiti.add_episode(
        name=f"journal_entry_{entry_id}",
        episode_body={
            "type": "journal",
            "category": request.category,
            "content": request.content,
            "family_id": request.family_id
        },
        group_id=request.family_id,
        reference_time=datetime.now()
    )

    return JournalEntryResponse(
        entry_id=entry_id,
        timestamp=timestamp,
        success=True
    )

@router.get("/journal/entries/{family_id}")
async def get_journal_entries(family_id: str, limit: int = 10):
    """
    ×§×‘×œ×ª ×¨×©×•××•×ª ×™×•××Ÿ ××—×¨×•× ×•×ª
    """
    session = app_state.get_or_create_session(family_id)

    # ×§×‘×œ entries ××”-session
    entries = session.get("journal_entries", [])

    # ××™×•×Ÿ ×œ×¤×™ ×ª××¨×™×š (×—×“×© ×œ×™×©×Ÿ)
    entries_sorted = sorted(entries, key=lambda x: x["timestamp"], reverse=True)

    # ×”×—×–×¨ ××ª ×”××¡×¤×¨ ×”××‘×•×§×©
    return {
        "entries": entries_sorted[:limit],
        "total": len(entries_sorted)
    }

# === Helper Functions ===

async def _generate_reports_internal(family_id: str, session: dict):
    """×¤×•× ×§×¦×™×” ×¤× ×™××™×ª ×œ×™×¦×™×¨×ª ×“×•×—×•×ª"""
    # ×“×•×— ××§×¦×•×¢×™
    prof_report = await app_state.llm.chat_with_structured_output(
        messages=[Message(
            role="system",
            content="×¦×•×¨ ×“×•×— ××§×¦×•×¢×™"
        )],
        response_schema={"report_markdown": "", "professional_recommendations_data": []}
    )

    # ×“×•×— ×œ×”×•×¨×”
    parent_report = await app_state.llm.chat_with_structured_output(
        messages=[Message(
            role="system",
            content="×¦×•×¨ ××›×ª×‘ ×œ×”×•×¨×”"
        )],
        response_schema={"parent_letter": "", "actionable_next_steps": []}
    )

    # ×©××™×¨×” ×‘-Graphiti
    await app_state.graphiti.add_episode(
        name=f"professional_report_{family_id}",
        episode_body=prof_report,
        group_id=family_id,
        reference_time=datetime.now()
    )

    await app_state.graphiti.add_episode(
        name=f"parent_report_{family_id}",
        episode_body=parent_report,
        group_id=family_id,
        reference_time=datetime.now()
    )

    # ×©××™×¨×” ×‘-session
    session["professional_report"] = prof_report
    session["parent_report"] = parent_report

    # ×œ× ×¢×•×‘×¨×™× ××•×˜×•××˜×™×ª ×œ-consultation - × ×©××¨ ×‘-report_generation
    # ×›×“×™ ×©×”××©×ª××© ×™×•×›×œ ×œ×¨××•×ª ××ª ×”×›×¨×˜×™×¡×™× ×•×œ×’×©×ª ×œ×“×•×—×•×ª

def _generate_suggestions(session: dict) -> List[str]:
    """×™×¦×™×¨×ª ×”×¦×¢×•×ª ×œ×¤×™ ×©×œ×‘"""
    stage = session["current_stage"]

    if stage == "welcome":
        return [
            "×©××• ×™×•× ×™ ×•×”×•× ×‘×Ÿ 3.5",
            "×”×™×œ×“×” ×©×œ×™ ×‘×ª 5",
            "×× ×™ ×¨×•×¦×” ×œ×“×‘×¨ ×¢×œ ×”×‘×Ÿ ×©×œ×™"
        ]
    elif len(session["interview_messages"]) < 5:
        return [
            "×”×•× ×××•×“ ××•×”×‘ ×¤××–×œ×™×",
            "×™×© ×œ×™ ×“××’×•×ª ×œ×’×‘×™ ×”×ª×§×©×•×¨×ª",
            "×¡×¤×¨×™ ×œ×™ ××” ×¢×•×“ ×—×©×•×‘"
        ]

    return []

def _generate_suggestions_from_state(result: dict) -> List[str]:
    """
    Generate suggestions based on conversation service result

    Args:
        result: Result dict from conversation_service.process_message()
    """
    completeness = result.get("completeness", 0)
    stats = result.get("stats", {})

    # Early conversation (<20% complete)
    if completeness < 20:
        return [
            "×©××• ×™×•× ×™ ×•×”×•× ×‘×Ÿ 3.5",
            "×™×© ×œ×™ ×“××’×•×ª ×œ×’×‘×™ ×”×“×™×‘×•×¨ ×©×œ×•",
            "×¡×¤×¨×™ ×œ×™ ××” ×¢×•×“ ×—×©×•×‘"
        ]

    # Mid conversation (20-60% complete)
    elif completeness < 60:
        return [
            "×”×•× ×××•×“ ××•×”×‘ ×¤××–×œ×™× ×•××©×—×§×™ ×‘× ×™×™×”",
            "××™×š ×”×•× ××ª× ×”×’ ×‘×’×Ÿ?",
            "×™×© ×¢×•×“ ××©×”×• ×©×—×©×•×‘ ×œ×“×¢×ª?"
        ]

    # Late conversation (60-80% complete)
    elif completeness < 80:
        return [
            "××” ×”××˜×¨×” ×©×œ×™ ×¢×‘×•×¨×•?",
            "××™×š ×”××©×¤×—×” ××ª××•×“×“×ª?",
            "×× ×™ ×—×•×©×‘×ª ×©×–×” ×”×›×œ"
        ]

    # Ready for next stage (>80% complete)
    else:
        return [
            "××™×š ××¢×œ×™× ×¡×¨×˜×•×Ÿ?",
            "×ª×¨××™ ×œ×™ ××ª ×”×”× ×—×™×•×ª",
            "××” ×”×¦×¢×“×™× ×”×‘××™×?"
        ]

def _generate_cards(session: dict) -> List[dict]:
    """×™×¦×™×¨×ª ×›×¨×˜×™×¡×™× ×“×™× ××™×™×"""
    cards = []

    # ×”×’×“×¨×ª ×©×œ×‘×™ ×”××¡×¢
    journey_stages = {
        "welcome": {"step": 1, "name": "×¨××™×•×Ÿ ×”×ª×¤×ª×—×•×ª×™", "emoji": "ğŸ—£ï¸"},
        "video_upload": {"step": 2, "name": "×¦×™×œ×•× ×¡×¨×˜×•× ×™×", "emoji": "ğŸ¬"},
        "video_analysis": {"step": 3, "name": "× ×™×ª×•×— ×¡×¨×˜×•× ×™×", "emoji": "ğŸ”"},
        "report_generation": {"step": 4, "name": "×™×¦×™×¨×ª ×“×•×—×•×ª", "emoji": "ğŸ“Š"},
        "consultation": {"step": 5, "name": "×™×™×¢×•×¥ ××§×¦×•×¢×™", "emoji": "ğŸ’¬"}
    }
    total_stages = 5
    current_stage = session["current_stage"]
    stage_info = journey_stages.get(current_stage, {"step": 1, "name": "×”×ª×—×œ×”", "emoji": "âœ¨"})

    # ×›×¨×˜×™×¡×™× ×œ×©×œ×‘ ×”×¨××™×•×Ÿ
    if session["current_stage"] == "welcome":
        num_messages = len(session.get("interview_messages", []))

        # ×›×¨×˜×™×¡ 0: ×”× ×—×™×” ×¨××©×•× ×™×ª - ××” ×”×•×œ×š ×œ×§×¨×•×ª? (×¦×™××Ÿ - instruction)
        if num_messages == 0:
            cards.append({
                "type": "welcome_guide",
                "title": "ğŸ‘‹ ×‘×¨×•×›×” ×”×‘××”! ×‘×•××™ × ×›×™×¨ ××ª ×”×™×œ×“/×” ×©×œ×š",
                "subtitle": "×× ×™ ×”×•×œ×›×ª ×œ×©××•×œ ××•×ª×š ×›××” ×©××œ×•×ª ×¢×œ ×”×™×œ×“/×” - ×—×•×–×§×•×ª, ××ª×’×¨×™×, ×“×‘×¨×™× ×©××¢× ×™×™× ×™× ××•×ª×•/×”. ×–×” ×™×™×§×— ×‘×¢×¨×š 10-15 ×“×§×•×ª. ×‘×¡×•×£ ××›×™×Ÿ ×œ×š ×”××œ×¦×•×ª ××•×ª×××•×ª ××™×©×™×ª",
                "icon": "Info",
                "status": "instruction",
                "action": None
            })

        # ×›×¨×˜×™×¡ 1: ××ª× ×”×œ ×¨××™×•×Ÿ (×¦×”×•×‘ - processing)
        if num_messages > 0:
            progress_stage = "××™×“×¢ ×‘×¡×™×¡×™" if num_messages <= 3 else "×ª×•×‘× ×•×ª ×¢××•×§×•×ª" if num_messages <= 6 else "×¡×™×›×•×"
            cards.append({
                "type": "interview_status",
                "title": "××ª× ×”×œ ×¨××™×•×Ÿ",
                "subtitle": f"×”×ª×§×“××•×ª: {progress_stage}",
                "icon": "MessageCircle",
                "status": "processing",
                "action": None
            })

        # ×›×¨×˜×™×¡ 2: × ×•×©××™× ×©× ×“×•× ×• (×¦×™××Ÿ - progress)
        if num_messages >= 2:
            topics = []
            # × ×™×ª×•×— ×¤×©×•×˜ ×©×œ ×”× ×•×©××™× ××”×”×•×“×¢×•×ª
            messages_text = " ".join([m.get("content", "") for m in session.get("interview_messages", []) if m.get("role") == "user"])
            if "×’×™×œ" in messages_text or "×©× " in messages_text:
                topics.append("×’×™×œ")
            if "×“×™×‘×•×¨" in messages_text or "××“×‘×¨" in messages_text or "×ª×§×©×•×¨×ª" in messages_text:
                topics.append("×ª×§×©×•×¨×ª")
            if "×—×•×–×§" in messages_text or "××•×”×‘" in messages_text:
                topics.append("×—×•×–×§×•×ª")
            if "×“××’×”" in messages_text or "×§×•×©×™" in messages_text:
                topics.append("×“××’×•×ª")

            topics_text = ", ".join(topics) if topics else "×‘× ×™×™×ª ×¤×¨×•×¤×™×œ"
            cards.append({
                "type": "interview_topics",
                "title": "× ×•×©××™× ×©× ×“×•× ×•",
                "subtitle": topics_text,
                "icon": "CheckCircle",
                "status": "progress",
                "action": None
            })

        # ×›×¨×˜×™×¡ 3: ×–××Ÿ ××©×•×¢×¨ (×›×ª×•× - pending)
        if num_messages >= 3 and num_messages < 7:
            estimated_time = max(5, 15 - (num_messages * 2))
            cards.append({
                "type": "interview_time",
                "title": "×–××Ÿ ××©×•×¢×¨",
                "subtitle": f"×¢×•×“ {estimated_time}-{estimated_time + 5} ×“×§×•×ª",
                "icon": "Clock",
                "status": "pending",
                "action": None
            })

    # ×›×¨×˜×™×¡×™× ×œ×©×œ×‘ ×¦×™×œ×•× ×”×•×•×™×“××•
    elif session["current_stage"] == "video_upload" and "video_guidelines" in session:
        num_scenarios = len(session["video_guidelines"].get("scenarios", []))
        num_videos = len(session.get("videos", []))

        # ×›×¨×˜×™×¡ 0: ×”× ×—×™×” ×•××•×˜×™×‘×¦×™×” - ×œ××” ×œ×¦×œ×? (×¦×™××Ÿ ×‘×•×œ×˜ - instruction)
        if num_videos == 0:
            # ×˜×§×¡×˜ ××œ× ×•××•×˜×™×‘×¦×™×•× ×™ ×‘×¤×¢× ×”×¨××©×•× ×”
            cards.append({
                "type": "video_upload_guide",
                "title": "ğŸ¬ ×©×œ×‘ ×”×¦×™×œ×•× - ×œ××” ×–×” ×—×©×•×‘?",
                "subtitle": "×”×¡×¨×˜×•× ×™× ×™×¢×–×¨×• ×œ×™ ×œ×”×‘×™×Ÿ ××ª ×”×”×ª×¤×ª×—×•×ª ×©×œ ×”×™×œ×“/×” ×©×œ×š ×‘×¦×•×¨×” ××¢××™×§×” ×•××“×•×™×§×ª. ×–×” ×›××• ×©××œ×š ××™×ª×š ×”×‘×™×ª×” ×•××¨××” ××ª ×”×™×œ×“/×” ×‘×¤×¢×•×œ×” - ×¨×§ ×©××ª ×§×•×‘×¢×ª ××ª×™ ×•××™×š",
                "icon": "Info",
                "status": "instruction",
                "action": None
            })

        # ×›×¨×˜×™×¡ 1: ×”×”×ª×§×“××•×ª ×©×œ×š (×¦×™××Ÿ - progress) + breadcrumbs
        cards.append({
            "type": "overall_progress",
            "title": "×”×”×ª×§×“××•×ª ×©×œ×š",
            "subtitle": f"×¨××™×•×Ÿ âœ“ | ×¡×¨×˜×•× ×™× ({num_videos}/{num_scenarios})",
            "icon": "CheckCircle",
            "status": "progress",
            "action": None,
            "journey_step": stage_info["step"],
            "journey_total": total_stages
        })

        # ×›×¨×˜×™×¡ 2: ×”×•×¨××•×ª ×œ×¦×™×œ×•× (×›×—×•×œ - action)
        # ×”×”×•×¨××•×ª ×™×•×¤×™×¢×• ×‘×ª×•×š ×˜×•×¤×¡ ×”×”×¢×œ××” ×¢×¦××•
        cards.append({
            "type": "upload_video",
            "title": "×”×•×¨××•×ª ×œ×¦×™×œ×•×",
            "subtitle": f"×¦×™×œ×•×: {num_scenarios} ×ª×¨×—×™×©×™× | ×”×•×¢×œ×•: {num_videos}",
            "icon": "Video",
            "status": "action",
            "action": "upload"
        })

        # ×›×¨×˜×™×¡ 3: ××” ×§×•×¨×” ××—×¨×™? (××™×“×¢ - instruction) - ××•×¤×™×¢ ×¨×§ ××—×¨×™ ×¡×¨×˜×•×Ÿ ×¨××©×•×Ÿ
        if num_videos >= 1:
            if num_videos >= num_scenarios:
                next_step_text = "×›×œ ×”×¡×¨×˜×•× ×™× ×”×•×¢×œ×•! ×× ×™ ××ª×—×™×œ ×‘× ×™×ª×•×— ×‘×§×¨×•×‘"
            else:
                remaining = num_scenarios - num_videos
                next_step_text = f"× ×”×“×¨! ×¢×•×“ {remaining} ×¡×¨×˜×•× ×™× ×•×× ×™ ××•×›×œ ×œ×”×ª×—×™×œ ×‘× ×™×ª×•×—"

            cards.append({
                "type": "next_steps_info",
                "title": "××” ×”×œ××”?",
                "subtitle": next_step_text,
                "icon": "MessageCircle",
                "status": "instruction",
                "action": None
            })

    # ×›×¨×˜×™×¡×™× ×œ×©×œ×‘ × ×™×ª×•×— (analysis)
    elif session["current_stage"] == "video_analysis":
        # ×›×¨×˜×™×¡ 0: ×”× ×—×™×” - ××” ×§×•×¨×” ×¢×›×©×™×•? (×¦×™××Ÿ - instruction)
        cards.append({
            "type": "analysis_guide",
            "title": "ğŸ” ×× ×ª×— ××ª ×”×¡×¨×˜×•× ×™×",
            "subtitle": "×× ×™ ×¢×•×‘×¨ ×¢×œ ×”×¡×¨×˜×•× ×™× ×•×”×¨××™×•×Ÿ ×©×œ× ×•, ××—×¤×© ×“×¤×•×¡×™× ×•×”×ª× ×”×’×•×™×•×ª. ×–×” ×œ×•×§×— ×‘×“×¨×š ×›×œ×œ ×›-24 ×©×¢×•×ª. ××¢×“×›×Ÿ ××•×ª×š ×›×©××¡×™×™× - ××™×Ÿ ×¦×•×¨×š ×œ×—×›×•×ª ×›××Ÿ",
            "icon": "Info",
            "status": "instruction",
            "action": None
        })

        # ×›×¨×˜×™×¡ 1: × ×™×ª×•×— ×‘×ª×”×œ×™×š (×¦×”×•×‘ - processing)
        cards.append({
            "type": "analysis_status",
            "title": "× ×™×ª×•×— ×‘×ª×”×œ×™×š",
            "subtitle": "××©×•×¢×¨: 24 ×©×¢×•×ª",
            "icon": "Clock",
            "status": "processing",
            "action": None
        })

        # ×›×¨×˜×™×¡ DEBUG: ×“×œ×’ ×œ×©×œ×‘ ×”×‘× (×›×—×•×œ - action)
        cards.append({
            "type": "debug_skip",
            "title": "ğŸ”§ ×¡×™××•×œ×¦×™×”: ×“×œ×’ ×œ×“×•×—×•×ª",
            "subtitle": "×¨×§ ×œ×¤×™×ª×•×— - ××¨×™×¥ × ×™×ª×•×— ×•××™×™×¦×¨ ×“×•×—×•×ª",
            "icon": "FastForward",
            "status": "action",
            "action": "skipAnalysis"
        })

        # ×›×¨×˜×™×¡ 2: ×¦×¤×™×™×” ×‘×¡×¨×˜×•× ×™× (×›×—×•×œ - action)
        num_videos = len(session.get("videos", []))
        cards.append({
            "type": "video_gallery",
            "title": "×¦×¤×™×™×” ×‘×¡×¨×˜×•× ×™×",
            "subtitle": f"{num_videos} ×¡×¨×˜×•× ×™×",
            "icon": "Video",
            "status": "action",
            "action": "videoGallery"
        })

        # ×›×¨×˜×™×¡ 3: ×™×•××Ÿ (×¦×™××Ÿ - action)
        cards.append({
            "type": "journal",
            "title": "×™×•××Ÿ ×™×•× ×™",
            "subtitle": "×”×•×¡×™×¤×™ ×”×¢×¨×•×ª ××”×™××™× ×”××—×¨×•× ×™×",
            "icon": "MessageCircle",
            "status": "action",
            "action": "journal"
        })

    # ×›×¨×˜×™×¡×™× ×œ×©×œ×‘ ×™×¦×™×¨×ª ×“×•×—×•×ª (report_generation)
    elif session["current_stage"] == "report_generation":
        # ×›×¨×˜×™×¡ 0: ×”× ×—×™×” - ××” ×¢×›×©×™×•? (×™×¨×•×§ ×‘×•×œ×˜ - new)
        cards.append({
            "type": "reports_ready_guide",
            "title": "ğŸ‰ ×”× ×™×ª×•×— ×”×•×©×œ× - ×”×“×•×—×•×ª ××•×›× ×™×!",
            "subtitle": "× ×™×ª×—×ª×™ ××ª ×”×¨××™×•×Ÿ ×•×”×¡×¨×˜×•× ×™×. ×¢×›×©×™×• ×™×© ×œ×š 2 ×“×•×—×•×ª ×œ×§×¨×™××” + ×”××œ×¦×•×ª ×œ××•××—×™×. ×”×›×œ ××•×›×Ÿ - ×¤×©×•×˜ ×œ×—×¦×™ ×¢×œ ×”×›×¨×˜×™×¡×™× ×œ××˜×”",
            "icon": "Sparkles",
            "status": "new",
            "action": None
        })

        # ×›×¨×˜×™×¡ 1: ××“×¨×™×š ×œ×”×•×¨×™× (×™×¨×•×§ - new)
        cards.append({
            "type": "parent_report",
            "title": "ğŸ“„ ××“×¨×™×š ×œ×”×•×¨×™×",
            "subtitle": "×œ×—×¦×™ ×œ×§×¨×™××” - ×”×¡×‘×¨×™× ×‘×¨×•×¨×™× ×‘×©×¤×” ×¤×©×•×˜×”",
            "icon": "FileText",
            "status": "new",
            "action": "parentReport"
        })

        # ×›×¨×˜×™×¡ 2: ×“×•×— ××§×¦×•×¢×™ (×›×—×•×œ - new)
        cards.append({
            "type": "professional_report",
            "title": "ğŸ“‹ ×“×•×— ××§×¦×•×¢×™",
            "subtitle": "×œ×—×¦×™ ×œ×¦×¤×™×™×” - ×“×•×— ×˜×›× ×™ ×œ×©×™×ª×•×£ ×¢× ××•××—×™×",
            "icon": "FileText",
            "status": "action",
            "action": "proReport"
        })

        # ×›×¨×˜×™×¡ 3: ××¦×™××ª ××•××—×™× (×¦×™××Ÿ - action)
        cards.append({
            "type": "find_experts",
            "title": "ğŸ” ××¦×™××ª ××•××—×™×",
            "subtitle": "×”××œ×¦×•×ª ××•×ª×××•×ª ××™×©×™×ª ×¢×œ ×¡××š ×”×××¦××™×",
            "icon": "Search",
            "status": "action",
            "action": "experts"
        })

    # ×›×¨×˜×™×¡×™× ×œ×©×œ×‘ ×™×™×¢×•×¥ (consultation)
    elif session["current_stage"] == "consultation":
        # ×›×¨×˜×™×¡ 0: ×”× ×—×™×” - ××” ×”×©×œ×‘ ×”×–×”? (×¦×™××Ÿ - instruction)
        cards.append({
            "type": "consultation_guide",
            "title": "ğŸ’¬ ×©×œ×‘ ×”×™×™×¢×•×¥ - ×× ×™ ×›××Ÿ ×‘×©×‘×™×œ×š",
            "subtitle": "×§×¨××ª ××ª ×”×“×•×—×•×ª? ×™×© ×œ×š ×©××œ×•×ª? ×¨×•×¦×” ×œ×“×•×Ÿ ×‘×××¦××™× ××• ×œ×§×‘×œ ×”××œ×¦×•×ª × ×•×¡×¤×•×ª? ×¤×©×•×˜ ×©××œ×™ ××•×ª×™ ×‘×¦'××˜. ××¤×©×¨ ×’× ×œ×”×¢×œ×•×ª ××¡××›×™× × ×•×¡×¤×™× ×× ×™×©",
            "icon": "Info",
            "status": "instruction",
            "action": None
        })

        # ×›×¨×˜×™×¡ 1: ××¦×‘ ×”×ª×™×™×¢×¦×•×ª (×¡×’×•×œ - processing)
        cards.append({
            "type": "consultation",
            "title": "××¦×‘ ×”×ª×™×™×¢×¦×•×ª",
            "subtitle": "×©××œ×™ ×›×œ ×©××œ×”",
            "icon": "Brain",
            "status": "processing",
            "action": "consultDoc"
        })

        # ×›×¨×˜×™×¡ 2: ×”×¢×œ××ª ××¡××›×™× (×›×ª×•× - action)
        cards.append({
            "type": "upload_document",
            "title": "×”×¢×œ××ª ××¡××›×™×",
            "subtitle": "××‘×—×•× ×™×, ×¡×™×›×•××™×, ×“×•×—×•×ª",
            "icon": "FileText",
            "status": "action",
            "action": "uploadDoc"
        })

        # ×›×¨×˜×™×¡ 3: ×™×•××Ÿ (×¦×™××Ÿ - action)
        cards.append({
            "type": "journal",
            "title": "×™×•××Ÿ ×™×•× ×™",
            "subtitle": "×”×¢×¨×•×ª ×•×”×ª×‘×•× × ×•×™×•×ª",
            "icon": "Book",
            "status": "action",
            "action": "journal"
        })

    return cards

def _classify_episode_type(name: str) -> str:
    """×–×™×”×•×™ ×¡×•×’ episode"""
    if "interview" in name:
        return "interview"
    elif "video_guidelines" in name:
        return "guidelines"
    elif "video_upload" in name:
        return "video_upload"
    elif "video_analysis" in name:
        return "analysis"
    elif "report" in name:
        return "report"
    elif "journal_entry" in name:
        return "journal"
    else:
        return "other"

def _generate_event_title(episode) -> str:
    """×™×¦×™×¨×ª ×›×•×ª×¨×ª ×œevent"""
    episode_type = _classify_episode_type(episode.name)

    titles = {
        "interview": "×¨××™×•×Ÿ ×”×ª×¤×ª×—×•×ª×™",
        "guidelines": "×”× ×—×™×•×ª ×¦×™×œ×•× × ×•×¦×¨×•",
        "video_upload": "×”×¢×œ××ª ×•×™×“××•",
        "analysis": "× ×™×ª×•×— ×•×™×“××• ×”×•×©×œ×",
        "report": "×“×•×— ××•×›×Ÿ",
        "journal": "×¨×©×•××ª ×™×•××Ÿ"
    }

    return titles.get(episode_type, "××™×¨×•×¢")

# === Wu Wei Architecture: Deep Views Endpoints ===

@router.get("/views/available", response_model=AvailableViewsResponse)
async def get_available_views(family_id: str):
    """
    ğŸŒŸ Wu Wei Architecture: Get available deep views for current session

    Returns list of view IDs that are available based on current session state.
    """
    if not app_state.initialized:
        raise HTTPException(status_code=500, detail="App not initialized")

    # Get services
    interview_service = get_interview_service()
    view_manager = get_view_manager()

    # Get session state
    session = interview_service.get_or_create_session(family_id)
    data = session.extracted_data

    # ğŸŒŸ Wu Wei: Build artifacts for view availability checks
    artifacts = {}
    for artifact_id, artifact in session.artifacts.items():
        artifacts[artifact_id] = {
            "exists": artifact.exists,
            "status": artifact.status
        }

    # Build context for view availability checks
    context = {
        "phase": session.phase,
        "completeness": session.completeness,
        "child_name": data.child_name,
        "artifacts": artifacts,  # ğŸŒŸ Wu Wei: Include artifacts
        "reports_ready": session.has_artifact("baseline_parent_report"),  # DEPRECATED: for backwards compatibility
        "video_count": 0,  # TODO: Get from video storage
    }

    # Get available views from view_manager
    available_views = view_manager.get_available_views(context)

    return AvailableViewsResponse(
        family_id=family_id,
        phase=session.phase,
        available_views=available_views
    )


@router.get("/views/{view_id}", response_model=ViewContentResponse)
async def get_view_content(view_id: str, family_id: str):
    """
    ğŸŒŸ Wu Wei Architecture: Get specific view content

    Returns view definition and content if available, or reason if unavailable.
    """
    if not app_state.initialized:
        raise HTTPException(status_code=500, detail="App not initialized")

    # Get services
    interview_service = get_interview_service()
    view_manager = get_view_manager()

    # Get view definition
    view = view_manager.get_view(view_id)
    if not view:
        raise HTTPException(status_code=404, detail=f"View '{view_id}' not found")

    # Get session state
    session = interview_service.get_or_create_session(family_id)
    data = session.extracted_data

    # ğŸŒŸ Wu Wei: Build artifacts for view availability check
    artifacts = {}
    for artifact_id, artifact in session.artifacts.items():
        artifacts[artifact_id] = {
            "exists": artifact.exists,
            "status": artifact.status,
            "content": artifact.content if artifact.is_ready else None
        }

    # Build context for availability check
    context = {
        "phase": session.phase,
        "completeness": session.completeness,
        "child_name": data.child_name,
        "artifacts": artifacts,  # ğŸŒŸ Wu Wei: Include artifacts
        "reports_ready": session.has_artifact("baseline_parent_report"),  # DEPRECATED
        "video_count": 0,  # TODO: Get from video storage
    }

    # Check if view is available
    is_available = view_manager.check_view_availability(view_id, context)

    if is_available:
        # ğŸŒŸ Wu Wei: Enrich view content with artifact data
        view_content = view.copy()

        # Map view data sources to artifacts
        data_sources = view.get("data_sources", {})
        primary_source = data_sources.get("primary")

        if primary_source:
            # Map artifact names to actual artifact IDs
            artifact_map = {
                "video_guidelines": "baseline_video_guidelines",
                "parent_report": "baseline_parent_report",
                "professional_report": "baseline_professional_report",
                "updated_parent_report": "updated_parent_report"
            }

            artifact_id = artifact_map.get(primary_source, primary_source)
            artifact = session.get_artifact(artifact_id)

            if artifact and artifact.is_ready:
                # Include artifact content in view
                view_content["artifact_content"] = artifact.content
                view_content["artifact_metadata"] = {
                    "created_at": artifact.created_at.isoformat(),
                    "ready_at": artifact.ready_at.isoformat() if artifact.ready_at else None
                }

        # Enrich with context variables
        view_content["context"] = {
            "child_name": data.child_name,
            "phase": session.phase,
            "artifacts_available": list(artifacts.keys())
        }

        return ViewContentResponse(
            view_id=view_id,
            view_name=view.get("name", ""),
            view_name_en=view.get("name_en", ""),
            available=True,
            content=view_content
        )
    else:
        return ViewContentResponse(
            view_id=view_id,
            view_name=view.get("name", ""),
            view_name_en=view.get("name_en", ""),
            available=False,
            reason_unavailable="View not available in current phase or missing required data"
        )


# === Wu Wei Architecture: Artifact Endpoints ===

@router.get("/session/{family_id}/artifacts", response_model=SessionArtifactsResponse)
async def get_session_artifacts(family_id: str):
    """
    ğŸŒŸ Wu Wei: Get all artifacts for a session

    Returns list of all artifacts (guidelines, reports, etc.) that have been
    generated for this family session.
    """
    if not app_state.initialized:
        raise HTTPException(status_code=500, detail="App not initialized")

    interview_service = get_interview_service()
    session = interview_service.get_or_create_session(family_id)

    # Convert artifacts to dict format for response
    artifacts_list = []
    for artifact_id, artifact in session.artifacts.items():
        artifacts_list.append({
            "artifact_id": artifact.artifact_id,
            "artifact_type": artifact.artifact_type,
            "status": artifact.status,
            "content_format": artifact.content_format,
            "created_at": artifact.created_at.isoformat(),
            "ready_at": artifact.ready_at.isoformat() if artifact.ready_at else None,
            "exists": artifact.exists,
            "is_ready": artifact.is_ready,
            "has_error": artifact.has_error,
            "error_message": artifact.error_message
        })

    return SessionArtifactsResponse(
        family_id=family_id,
        artifacts=artifacts_list
    )


@router.get("/artifacts/{artifact_id}", response_model=ArtifactResponse)
async def get_artifact(artifact_id: str, family_id: str):
    """
    ğŸŒŸ Wu Wei: Get specific artifact content

    Returns the full artifact including content if it's ready.
    Artifact IDs: baseline_video_guidelines, baseline_parent_report, etc.
    """
    if not app_state.initialized:
        raise HTTPException(status_code=500, detail="App not initialized")

    interview_service = get_interview_service()
    session = interview_service.get_or_create_session(family_id)

    # Get artifact
    artifact = session.get_artifact(artifact_id)
    if not artifact:
        raise HTTPException(
            status_code=404,
            detail=f"Artifact '{artifact_id}' not found for family {family_id}"
        )

    return ArtifactResponse(
        artifact_id=artifact.artifact_id,
        artifact_type=artifact.artifact_type,
        status=artifact.status,
        content=artifact.content if artifact.is_ready else None,
        content_format=artifact.content_format,
        created_at=artifact.created_at.isoformat(),
        ready_at=artifact.ready_at.isoformat() if artifact.ready_at else None,
        error_message=artifact.error_message
    )


@router.post("/artifacts/{artifact_id}/action")
async def artifact_action(artifact_id: str, request: ArtifactActionRequest):
    """
    ğŸŒŸ Wu Wei: Track user actions on artifacts

    Actions: "view", "download", "decline"
    This tracks user engagement with generated artifacts.
    """
    if not app_state.initialized:
        raise HTTPException(status_code=500, detail="App not initialized")

    interview_service = get_interview_service()
    session = interview_service.get_or_create_session(request.family_id)

    # Verify artifact exists
    artifact = session.get_artifact(artifact_id)
    if not artifact:
        raise HTTPException(
            status_code=404,
            detail=f"Artifact '{artifact_id}' not found"
        )

    # Track action in metadata
    if "user_actions" not in artifact.metadata:
        artifact.metadata["user_actions"] = []

    artifact.metadata["user_actions"].append({
        "action": request.action,
        "timestamp": datetime.now().isoformat()
    })

    # Update artifact
    session.add_artifact(artifact)

    import logging
    logger = logging.getLogger(__name__)
    logger.info(
        f"ğŸ“Š Artifact action tracked: {request.action} on {artifact_id} "
        f"for family {request.family_id}"
    )

    return {
        "success": True,
        "artifact_id": artifact_id,
        "action": request.action,
        "tracked_at": datetime.now().isoformat()
    }


# === Demo Mode Endpoints (DEPRECATED - Use Test Mode Instead) ===
# Demo mode has been replaced with Test Mode which uses real backend processing
# Old demo endpoints are disabled to prevent confusion

# @router.post("/demo/start", response_model=DemoStartResponse)
# async def start_demo(request: DemoStartRequest):
#     """ğŸ¬ DEPRECATED: Use /test/start instead"""
#     raise HTTPException(status_code=410, detail="Demo mode deprecated. Use test mode instead.")

# @router.get("/demo/{demo_family_id}/next", response_model=DemoNextResponse)
# async def get_next_demo_step(demo_family_id: str):
#     """ğŸ¬ DEPRECATED: Use test mode instead"""
#     raise HTTPException(status_code=410, detail="Demo mode deprecated. Use test mode instead.")

# @router.post("/demo/{demo_family_id}/stop", response_model=DemoStopResponse)
# async def stop_demo(demo_family_id: str):
#     """ğŸ¬ DEPRECATED: Use test mode instead"""
#     raise HTTPException(status_code=410, detail="Demo mode deprecated. Use test mode instead.")


# === State-Based Endpoints (Wu Wei Architecture) ===

@router.get("/state/{family_id}")
async def get_family_state(family_id: str):
    """
    Get complete family state - the DNA of the system.
    Everything (cards, greeting, suggestions) derives from this.
    """
    graphiti = get_mock_graphiti()
    state = graphiti.get_or_create_state(family_id)

    # Derive UI elements from state
    greeting = derive_contextual_greeting(state)
    cards = derive_active_cards(state)
    suggestions = derive_suggestions(state)

    return {
        "state": state.dict(),
        "ui": {
            "greeting": greeting,
            "cards": cards,
            "suggestions": suggestions
        }
    }


# === Test Mode Endpoints (Parent Simulator) ===

@router.get("/test/personas")
async def list_test_personas():
    """
    List available parent personas for testing.
    Each persona represents a realistic test case.
    """
    simulator = get_parent_simulator()
    return {
        "personas": simulator.list_personas()
    }


class StartTestRequest(BaseModel):
    """Request to start test mode"""
    persona_id: str
    family_id: Optional[str] = None  # If not provided, generate one


@router.post("/test/start")
async def start_test_mode(request: StartTestRequest):
    """
    Start test mode with a parent persona.
    System will simulate this parent interacting with real backend.
    """
    simulator = get_parent_simulator()

    # Generate family ID if not provided
    family_id = request.family_id or f"test_{request.persona_id}_{int(datetime.now().timestamp())}"

    try:
        result = simulator.start_simulation(request.persona_id, family_id)

        return {
            "success": True,
            "family_id": family_id,
            "persona": result["persona"],
            "message": f"Test mode started with persona: {result['persona']['parent_name']}"
        }
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))


class GenerateResponseRequest(BaseModel):
    """Request to generate parent response"""
    family_id: str
    chitta_question: str


@router.post("/test/generate-response")
async def generate_parent_response(request: GenerateResponseRequest):
    """
    Generate realistic parent response using LLM.
    The LLM acts as the parent persona.
    """
    if not app_state.initialized:
        raise HTTPException(status_code=500, detail="App not initialized")

    simulator = get_parent_simulator()
    graphiti = get_mock_graphiti()

    try:
        response = await simulator.generate_response(
            family_id=request.family_id,
            chitta_question=request.chitta_question,
            llm_provider=app_state.llm,
            graphiti=graphiti
        )

        # If response is None, interview has completed - parent stops responding
        if response is None:
            return {
                "parent_response": "",  # Empty string, not None (None triggers frontend error)
                "interview_complete": True,
                "conversation_ended": True  # Clear flag for frontend
            }

        return {
            "parent_response": response,
            "interview_complete": False
        }
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        import logging
        logging.error(f"Error generating parent response: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Failed to generate response")
