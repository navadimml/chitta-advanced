"""
API Routes for Chitta
"""

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import List, Optional
from datetime import datetime

from app.core.app_state import app_state

router = APIRouter()

# === Request/Response Models ===

class SendMessageRequest(BaseModel):
    family_id: str
    message: str
    parent_name: Optional[str] = "×”×•×¨×”"

class SendMessageResponse(BaseModel):
    response: str
    stage: str
    ui_data: dict

class CompleteInterviewResponse(BaseModel):
    success: bool
    video_guidelines: dict
    next_stage: str

class UploadVideoRequest(BaseModel):
    family_id: str
    video_id: str
    scenario: str
    duration_seconds: int

# === Endpoints ===

@router.get("/")
async def root():
    """API root"""
    return {"message": "Chitta API", "version": "1.0.0"}

@router.post("/chat/send", response_model=SendMessageResponse)
async def send_message(request: SendMessageRequest):
    """
    ×©×œ×™×—×ª ×”×•×“×¢×” ×œ×¦'×™×˜×”
    """
    if not app_state.initialized:
        raise HTTPException(status_code=500, detail="App not initialized")

    # ×§×‘×œ/×¦×•×¨ session
    session = app_state.get_or_create_session(request.family_id)

    # ×”×•×¡×£ ×”×•×“×¢×ª ××©×ª××©
    session["interview_messages"].append({
        "role": "user",
        "content": request.message,
        "timestamp": datetime.now().isoformat()
    })

    # ×§×‘×œ ×ª×’×•×‘×” ××”-LLM
    messages = [
        {"role": msg["role"], "content": msg["content"]}
        for msg in session["interview_messages"]
    ]

    # ×× ×–×• ×”×”×•×“×¢×” ×”×¨××©×•× ×”, ×”×•×¡×£ system prompt
    if len(session["interview_messages"]) == 1:
        messages.insert(0, {
            "role": "system",
            "content": "××ª×” Chitta - ×¢×•×–×¨×ª AI ×—××” ×©×× ×”×œ×ª ×¨××™×•×Ÿ ×”×ª×¤×ª×—×•×ª×™ ×¢× ×”×•×¨×”."
        })

    response = await app_state.llm.chat(messages)

    # ×‘×“×™×§×” ×× ×”×¨××™×•×Ÿ ×”×¡×ª×™×™×
    if response == "INTERVIEW_COMPLETE":
        # ×”×©×œ××ª ×¨××™×•×Ÿ ××•×˜×•××˜×™×ª
        summary_result = await app_state.llm.chat_with_structured_output(
            messages=[{"role": "system", "content": "×¡×›× ××ª ×”×¨××™×•×Ÿ"}],
            response_schema={"interview_summary": {}, "video_guidelines": {}}
        )

        # ×©××™×¨×” ×‘-session
        session["interview_summary"] = summary_result["interview_summary"]
        session["video_guidelines"] = summary_result["video_guidelines"]
        session["current_stage"] = "video_upload"

        # ×©××™×¨×” ×‘-Graphiti
        await app_state.graphiti.add_episode(
            name=f"interview_summary_{request.family_id}",
            episode_body=summary_result["interview_summary"],
            group_id=request.family_id
        )

        await app_state.graphiti.add_episode(
            name=f"video_guidelines_{request.family_id}",
            episode_body=summary_result["video_guidelines"],
            group_id=request.family_id
        )

        response = "××¢×•×œ×”! ×™×¦×¨×ª×™ ×¢×‘×•×¨×š ×”× ×—×™×•×ª ×¦×™×œ×•× ××•×ª×××•×ª ××™×©×™×ª. ×ª×¨××™ ××•×ª×Ÿ ×œ××˜×”. ×›×©×ª×”×™×™ ××•×›× ×”, ×ª×•×›×œ×™ ×œ×”×¢×œ×•×ª ××ª ×”×¡×¨×˜×•× ×™×."

        # ×”×•×¡×£ ×ª×’×•×‘×” ×œ×”×™×¡×˜×•×¨×™×”
        session["interview_messages"].append({
            "role": "assistant",
            "content": response,
            "timestamp": datetime.now().isoformat()
        })

        # UI data ×¢× ×›×¨×˜×™×¡×™ ×•×™×“××•
        ui_data = {
            "suggestions": ["××¢×œ×” ×¡×¨×˜×•×Ÿ ×¢×›×©×™×•", "××§×¨× ××ª ×”×”× ×—×™×•×ª"],
            "cards": _generate_cards(session),
            "progress": 0.4,
            "video_guidelines": summary_result["video_guidelines"]
        }

        return SendMessageResponse(
            response=response,
            stage=session["current_stage"],
            ui_data=ui_data
        )

    # ×”×•×¡×£ ×ª×’×•×‘×” ×œ×”×™×¡×˜×•×¨×™×”
    session["interview_messages"].append({
        "role": "assistant",
        "content": response,
        "timestamp": datetime.now().isoformat()
    })

    # ×‘× ×” UI data
    ui_data = {
        "suggestions": _generate_suggestions(session),
        "cards": _generate_cards(session),
        "progress": len(session["interview_messages"]) / 10  # Rough estimate
    }

    return SendMessageResponse(
        response=response,
        stage=session["current_stage"],
        ui_data=ui_data
    )

@router.post("/interview/complete", response_model=CompleteInterviewResponse)
async def complete_interview(family_id: str):
    """
    ×¡×™×•× ×¨××™×•×Ÿ ×•×™×¦×™×¨×ª ×”× ×—×™×•×ª ×•×™×“××•
    """
    session = app_state.get_or_create_session(family_id)

    # ×§×¨×™××” ×œ-LLM ×œ×¡×™×›×•×
    summary_result = await app_state.llm.chat_with_structured_output(
        messages=[{
            "role": "system",
            "content": "×¡×›× ××ª ×”×¨××™×•×Ÿ"
        }],
        response_schema={"interview_summary": {}, "video_guidelines": {}}
    )

    # ×©××™×¨×” ×‘-Graphiti
    child_uuid = session["child_uuid"]

    await app_state.graphiti.add_episode(
        name=f"interview_summary_{family_id}",
        episode_body=summary_result["interview_summary"],
        group_id=family_id
    )

    await app_state.graphiti.add_episode(
        name=f"video_guidelines_{family_id}",
        episode_body=summary_result["video_guidelines"],
        group_id=family_id
    )

    # ×¢×“×›×Ÿ session
    session["current_stage"] = "video_upload"
    session["video_guidelines"] = summary_result["video_guidelines"]

    return CompleteInterviewResponse(
        success=True,
        video_guidelines=summary_result["video_guidelines"],
        next_stage="video_upload"
    )

@router.post("/video/upload")
async def upload_video(request: UploadVideoRequest):
    """
    ×”×¢×œ××ª ×•×™×“××• (simulated)
    """
    session = app_state.get_or_create_session(request.family_id)

    # ×”×•×¡×£ ×•×™×“××• ×œsession
    video_data = {
        "video_id": request.video_id,
        "scenario": request.scenario,
        "duration_seconds": request.duration_seconds,
        "uploaded_at": datetime.now().isoformat()
    }

    session["videos"].append(video_data)

    # ×©××™×¨×” ×‘-Graphiti
    await app_state.graphiti.add_episode(
        name=f"video_upload_{request.video_id}",
        episode_body=video_data,
        group_id=request.family_id
    )

    return {
        "success": True,
        "video_id": request.video_id,
        "total_videos": len(session["videos"])
    }

@router.post("/video/analyze")
async def analyze_videos(family_id: str):
    """
    × ×™×ª×•×— ×›×œ ×”×•×™×“××•××™×
    """
    session = app_state.get_or_create_session(family_id)

    if not session["videos"]:
        raise HTTPException(status_code=400, detail="No videos to analyze")

    # ×§×¨×™××” ×œ-LLM ×œ× ×™×ª×•×—
    analysis_result = await app_state.llm.chat_with_structured_output(
        messages=[{
            "role": "system",
            "content": f"× ×ª×— {len(session['videos'])} ×•×™×“××•××™×"
        }],
        response_schema={"behavioral_observations": [], "key_findings_summary": ""}
    )

    # ×©××™×¨×” ×‘-Graphiti
    await app_state.graphiti.add_episode(
        name=f"video_analysis_{family_id}",
        episode_body=analysis_result,
        group_id=family_id
    )

    session["current_stage"] = "report_generation"

    return {
        "success": True,
        "analysis": analysis_result
    }

@router.post("/reports/generate")
async def generate_reports(family_id: str):
    """
    ×™×¦×™×¨×ª ×“×•×—×•×ª (××§×¦×•×¢×™ + ×œ×”×•×¨×”)
    """
    session = app_state.get_or_create_session(family_id)

    # ×“×•×— ××§×¦×•×¢×™
    prof_report = await app_state.llm.chat_with_structured_output(
        messages=[{
            "role": "system",
            "content": "×¦×•×¨ ×“×•×— ××§×¦×•×¢×™"
        }],
        response_schema={"report_markdown": "", "professional_recommendations_data": []}
    )

    # ×“×•×— ×œ×”×•×¨×”
    parent_report = await app_state.llm.chat_with_structured_output(
        messages=[{
            "role": "system",
            "content": "×¦×•×¨ ××›×ª×‘ ×œ×”×•×¨×”"
        }],
        response_schema={"parent_letter": "", "actionable_next_steps": []}
    )

    # ×©××™×¨×” ×‘-Graphiti
    await app_state.graphiti.add_episode(
        name=f"professional_report_{family_id}",
        episode_body=prof_report,
        group_id=family_id
    )

    await app_state.graphiti.add_episode(
        name=f"parent_report_{family_id}",
        episode_body=parent_report,
        group_id=family_id
    )

    session["current_stage"] = "consultation"

    return {
        "success": True,
        "professional_report": prof_report,
        "parent_report": parent_report
    }

@router.get("/timeline/{family_id}")
async def get_timeline(family_id: str):
    """
    ×§×‘×œ×ª timeline ×©×œ ×›×œ ×”××¡×¢
    """
    # ×—×™×¤×•×© ×‘×’×¨×£
    episodes = await app_state.graphiti.search(
        query="all events",
        group_id=family_id,
        num_results=100
    )

    # ×”××¨×” ×œ×¤×•×¨××˜ timeline
    timeline = []
    for episode in episodes:
        timeline.append({
            "date": episode.reference_time.isoformat() if episode.reference_time else None,
            "type": _classify_episode_type(episode.name),
            "title": _generate_event_title(episode),
            "data": episode.body
        })

    # ××™×•×Ÿ ×œ×¤×™ ×ª××¨×™×š
    timeline.sort(key=lambda x: x["date"] if x["date"] else "", reverse=True)

    return {"timeline": timeline}

# === Helper Functions ===

def _generate_suggestions(session: dict) -> List[str]:
    """×™×¦×™×¨×ª ×”×¦×¢×•×ª ×œ×¤×™ ×©×œ×‘"""
    stage = session["current_stage"]

    if stage == "welcome":
        return [
            "×©××• ×™×•× ×™ ×•×”×•× ×‘×Ÿ 3.5",
            "×”×™×œ×“×” ×©×œ×™ ×‘×ª 5",
            "×× ×™ ×¨×•×¦×” ×œ×“×‘×¨ ×¢×œ ×”×‘×Ÿ ×©×œ×™"
        ]
    elif len(session["interview_messages"]) < 5:
        return [
            "×”×•× ×××•×“ ××•×”×‘ ×¤××–×œ×™×",
            "×™×© ×œ×™ ×“××’×•×ª ×œ×’×‘×™ ×”×ª×§×©×•×¨×ª",
            "×¡×¤×¨×™ ×œ×™ ××” ×¢×•×“ ×—×©×•×‘"
        ]

    return []

def _generate_cards(session: dict) -> List[dict]:
    """×™×¦×™×¨×ª ×›×¨×˜×™×¡×™× ×“×™× ××™×™×"""
    cards = []

    # ×”×’×“×¨×ª ×©×œ×‘×™ ×”××¡×¢
    journey_stages = {
        "welcome": {"step": 1, "name": "×¨××™×•×Ÿ ×”×ª×¤×ª×—×•×ª×™", "emoji": "ğŸ—£ï¸"},
        "video_upload": {"step": 2, "name": "×¦×™×œ×•× ×¡×¨×˜×•× ×™×", "emoji": "ğŸ¬"},
        "video_analysis": {"step": 3, "name": "× ×™×ª×•×— ×¡×¨×˜×•× ×™×", "emoji": "ğŸ”"},
        "report_generation": {"step": 4, "name": "×™×¦×™×¨×ª ×“×•×—×•×ª", "emoji": "ğŸ“Š"},
        "consultation": {"step": 5, "name": "×™×™×¢×•×¥ ××§×¦×•×¢×™", "emoji": "ğŸ’¬"}
    }
    total_stages = 5
    current_stage = session["current_stage"]
    stage_info = journey_stages.get(current_stage, {"step": 1, "name": "×”×ª×—×œ×”", "emoji": "âœ¨"})

    if session["current_stage"] == "video_upload" and "video_guidelines" in session:
        # ×›×¨×˜×™×¡ ×¡×˜×˜×•×¡ ×¨××©×•×Ÿ - ××¡×‘×™×¨ ××” ×œ×¢×©×•×ª ×¢×›×©×™×• + ×”×ª×§×“××•×ª ×‘××¡×¢
        num_scenarios = len(session["video_guidelines"].get("scenarios", []))
        cards.append({
            "type": "status",
            "title": f"{stage_info['emoji']} {stage_info['name']}",
            "subtitle": f"×¦×œ××™ {num_scenarios} ×¡×¨×˜×•× ×™× ×§×¦×¨×™× ×œ×¤×™ ×”×”× ×—×™×•×ª ×œ××˜×”. ×œ×—×¦×™ ×¢×œ ×›×œ ×”× ×—×™×” ×œ×¤×¨×˜×™× ××œ××™×.",
            "icon": "Info",
            "status": "active",
            "action": None,  # ×œ× × ×™×ª×Ÿ ×œ×œ×—×•×¥
            "journey_step": stage_info["step"],
            "journey_total": total_stages,
            "journey_label": f"×©×œ×‘ {stage_info['step']} ××ª×•×š {total_stages}"
        })

        # ×›×¨×˜×™×¡×™ ×”× ×—×™×•×ª ×¦×™×œ×•×
        for idx, scenario in enumerate(session["video_guidelines"].get("scenarios", [])):
            cards.append({
                "type": "video_guideline",
                "title": scenario["title"],
                "subtitle": scenario["description"],
                "icon": "Video",
                "status": "instruction",
                "action": f"view_guideline_{idx}",
                "priority": scenario.get("priority", "recommended"),
                "rationale": scenario.get("rationale", ""),
                "target_areas": scenario.get("target_areas", [])
            })

    return cards

def _classify_episode_type(name: str) -> str:
    """×–×™×”×•×™ ×¡×•×’ episode"""
    if "interview" in name:
        return "interview"
    elif "video_guidelines" in name:
        return "guidelines"
    elif "video_upload" in name:
        return "video_upload"
    elif "video_analysis" in name:
        return "analysis"
    elif "report" in name:
        return "report"
    else:
        return "other"

def _generate_event_title(episode) -> str:
    """×™×¦×™×¨×ª ×›×•×ª×¨×ª ×œevent"""
    episode_type = _classify_episode_type(episode.name)

    titles = {
        "interview": "×¨××™×•×Ÿ ×”×ª×¤×ª×—×•×ª×™",
        "guidelines": "×”× ×—×™×•×ª ×¦×™×œ×•× × ×•×¦×¨×•",
        "video_upload": "×”×¢×œ××ª ×•×™×“××•",
        "analysis": "× ×™×ª×•×— ×•×™×“××• ×”×•×©×œ×",
        "report": "×“×•×— ××•×›×Ÿ"
    }

    return titles.get(episode_type, "××™×¨×•×¢")
