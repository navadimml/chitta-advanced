"""
API Routes for Chitta
"""

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import List, Optional
from datetime import datetime

from app.core.app_state import app_state

router = APIRouter()

# === Request/Response Models ===

class SendMessageRequest(BaseModel):
    family_id: str
    message: str
    parent_name: Optional[str] = "×”×•×¨×”"

class SendMessageResponse(BaseModel):
    response: str
    stage: str
    ui_data: dict

class CompleteInterviewResponse(BaseModel):
    success: bool
    video_guidelines: dict
    next_stage: str

class UploadVideoRequest(BaseModel):
    family_id: str
    video_id: str
    scenario: str
    duration_seconds: int

# === Endpoints ===

@router.get("/")
async def root():
    """API root"""
    return {"message": "Chitta API", "version": "1.0.0"}

@router.post("/chat/send", response_model=SendMessageResponse)
async def send_message(request: SendMessageRequest):
    """
    ×©×œ×™×—×ª ×”×•×“×¢×” ×œ×¦'×™×˜×”
    """
    if not app_state.initialized:
        raise HTTPException(status_code=500, detail="App not initialized")

    # ×§×‘×œ/×¦×•×¨ session
    session = app_state.get_or_create_session(request.family_id)

    # ×”×•×¡×£ ×”×•×“×¢×ª ××©×ª××©
    session["interview_messages"].append({
        "role": "user",
        "content": request.message,
        "timestamp": datetime.now().isoformat()
    })

    # ×§×‘×œ ×ª×’×•×‘×” ××”-LLM
    messages = [
        {"role": msg["role"], "content": msg["content"]}
        for msg in session["interview_messages"]
    ]

    # ×× ×–×• ×”×”×•×“×¢×” ×”×¨××©×•× ×”, ×”×•×¡×£ system prompt
    if len(session["interview_messages"]) == 1:
        messages.insert(0, {
            "role": "system",
            "content": "××ª×” Chitta - ×¢×•×–×¨×ª AI ×—××” ×©×× ×”×œ×ª ×¨××™×•×Ÿ ×”×ª×¤×ª×—×•×ª×™ ×¢× ×”×•×¨×”."
        })

    response = await app_state.llm.chat(messages)

    # ×‘×“×™×§×” ×× ×”×¨××™×•×Ÿ ×”×¡×ª×™×™×
    if response == "INTERVIEW_COMPLETE":
        # ×”×©×œ××ª ×¨××™×•×Ÿ ××•×˜×•××˜×™×ª
        summary_result = await app_state.llm.chat_with_structured_output(
            messages=[{"role": "system", "content": "×¡×›× ××ª ×”×¨××™×•×Ÿ"}],
            response_schema={"interview_summary": {}, "video_guidelines": {}}
        )

        # ×©××™×¨×” ×‘-session
        session["interview_summary"] = summary_result["interview_summary"]
        session["video_guidelines"] = summary_result["video_guidelines"]
        session["current_stage"] = "video_upload"

        # ×©××™×¨×” ×‘-Graphiti
        await app_state.graphiti.add_episode(
            name=f"interview_summary_{request.family_id}",
            episode_body=summary_result["interview_summary"],
            group_id=request.family_id
        )

        await app_state.graphiti.add_episode(
            name=f"video_guidelines_{request.family_id}",
            episode_body=summary_result["video_guidelines"],
            group_id=request.family_id
        )

        response = "××¢×•×œ×”! ×™×¦×¨×ª×™ ×¢×‘×•×¨×š ×”× ×—×™×•×ª ×¦×™×œ×•× ××•×ª×××•×ª ××™×©×™×ª. ×ª×¨××™ ××•×ª×Ÿ ×œ××˜×”. ×›×©×ª×”×™×™ ××•×›× ×”, ×ª×•×›×œ×™ ×œ×”×¢×œ×•×ª ××ª ×”×¡×¨×˜×•× ×™×."

        # ×”×•×¡×£ ×ª×’×•×‘×” ×œ×”×™×¡×˜×•×¨×™×”
        session["interview_messages"].append({
            "role": "assistant",
            "content": response,
            "timestamp": datetime.now().isoformat()
        })

        # UI data ×¢× ×›×¨×˜×™×¡×™ ×•×™×“××•
        ui_data = {
            "suggestions": ["××¢×œ×” ×¡×¨×˜×•×Ÿ ×¢×›×©×™×•", "××§×¨× ××ª ×”×”× ×—×™×•×ª"],
            "cards": _generate_cards(session),
            "progress": 0.4,
            "video_guidelines": summary_result["video_guidelines"]
        }

        return SendMessageResponse(
            response=response,
            stage=session["current_stage"],
            ui_data=ui_data
        )

    # ×”×•×¡×£ ×ª×’×•×‘×” ×œ×”×™×¡×˜×•×¨×™×”
    session["interview_messages"].append({
        "role": "assistant",
        "content": response,
        "timestamp": datetime.now().isoformat()
    })

    # ×‘× ×” UI data
    ui_data = {
        "suggestions": _generate_suggestions(session),
        "cards": _generate_cards(session),
        "progress": len(session["interview_messages"]) / 10  # Rough estimate
    }

    return SendMessageResponse(
        response=response,
        stage=session["current_stage"],
        ui_data=ui_data
    )

@router.post("/interview/complete", response_model=CompleteInterviewResponse)
async def complete_interview(family_id: str):
    """
    ×¡×™×•× ×¨××™×•×Ÿ ×•×™×¦×™×¨×ª ×”× ×—×™×•×ª ×•×™×“××•
    """
    session = app_state.get_or_create_session(family_id)

    # ×§×¨×™××” ×œ-LLM ×œ×¡×™×›×•×
    summary_result = await app_state.llm.chat_with_structured_output(
        messages=[{
            "role": "system",
            "content": "×¡×›× ××ª ×”×¨××™×•×Ÿ"
        }],
        response_schema={"interview_summary": {}, "video_guidelines": {}}
    )

    # ×©××™×¨×” ×‘-Graphiti
    child_uuid = session["child_uuid"]

    await app_state.graphiti.add_episode(
        name=f"interview_summary_{family_id}",
        episode_body=summary_result["interview_summary"],
        group_id=family_id
    )

    await app_state.graphiti.add_episode(
        name=f"video_guidelines_{family_id}",
        episode_body=summary_result["video_guidelines"],
        group_id=family_id
    )

    # ×¢×“×›×Ÿ session
    session["current_stage"] = "video_upload"
    session["video_guidelines"] = summary_result["video_guidelines"]

    return CompleteInterviewResponse(
        success=True,
        video_guidelines=summary_result["video_guidelines"],
        next_stage="video_upload"
    )

@router.post("/video/upload")
async def upload_video(request: UploadVideoRequest):
    """
    ×”×¢×œ××ª ×•×™×“××• (simulated)
    """
    session = app_state.get_or_create_session(request.family_id)

    # ×”×•×¡×£ ×•×™×“××• ×œsession
    video_data = {
        "video_id": request.video_id,
        "scenario": request.scenario,
        "duration_seconds": request.duration_seconds,
        "uploaded_at": datetime.now().isoformat()
    }

    session["videos"].append(video_data)

    # ×©××™×¨×” ×‘-Graphiti
    await app_state.graphiti.add_episode(
        name=f"video_upload_{request.video_id}",
        episode_body=video_data,
        group_id=request.family_id
    )

    return {
        "success": True,
        "video_id": request.video_id,
        "total_videos": len(session["videos"])
    }

@router.post("/video/analyze")
async def analyze_videos(family_id: str):
    """
    × ×™×ª×•×— ×›×œ ×”×•×™×“××•××™×
    """
    session = app_state.get_or_create_session(family_id)

    if not session["videos"]:
        raise HTTPException(status_code=400, detail="No videos to analyze")

    # ×§×¨×™××” ×œ-LLM ×œ× ×™×ª×•×—
    analysis_result = await app_state.llm.chat_with_structured_output(
        messages=[{
            "role": "system",
            "content": f"× ×ª×— {len(session['videos'])} ×•×™×“××•××™×"
        }],
        response_schema={"behavioral_observations": [], "key_findings_summary": ""}
    )

    # ×©××™×¨×” ×‘-Graphiti
    await app_state.graphiti.add_episode(
        name=f"video_analysis_{family_id}",
        episode_body=analysis_result,
        group_id=family_id
    )

    session["current_stage"] = "report_generation"

    return {
        "success": True,
        "analysis": analysis_result
    }

@router.post("/reports/generate")
async def generate_reports(family_id: str):
    """
    ×™×¦×™×¨×ª ×“×•×—×•×ª (××§×¦×•×¢×™ + ×œ×”×•×¨×”)
    """
    session = app_state.get_or_create_session(family_id)

    # ×“×•×— ××§×¦×•×¢×™
    prof_report = await app_state.llm.chat_with_structured_output(
        messages=[{
            "role": "system",
            "content": "×¦×•×¨ ×“×•×— ××§×¦×•×¢×™"
        }],
        response_schema={"report_markdown": "", "professional_recommendations_data": []}
    )

    # ×“×•×— ×œ×”×•×¨×”
    parent_report = await app_state.llm.chat_with_structured_output(
        messages=[{
            "role": "system",
            "content": "×¦×•×¨ ××›×ª×‘ ×œ×”×•×¨×”"
        }],
        response_schema={"parent_letter": "", "actionable_next_steps": []}
    )

    # ×©××™×¨×” ×‘-Graphiti
    await app_state.graphiti.add_episode(
        name=f"professional_report_{family_id}",
        episode_body=prof_report,
        group_id=family_id
    )

    await app_state.graphiti.add_episode(
        name=f"parent_report_{family_id}",
        episode_body=parent_report,
        group_id=family_id
    )

    session["current_stage"] = "consultation"

    return {
        "success": True,
        "professional_report": prof_report,
        "parent_report": parent_report
    }

@router.get("/timeline/{family_id}")
async def get_timeline(family_id: str):
    """
    ×§×‘×œ×ª timeline ×©×œ ×›×œ ×”××¡×¢
    """
    # ×—×™×¤×•×© ×‘×’×¨×£
    episodes = await app_state.graphiti.search(
        query="all events",
        group_id=family_id,
        num_results=100
    )

    # ×”××¨×” ×œ×¤×•×¨××˜ timeline
    timeline = []
    for episode in episodes:
        timeline.append({
            "date": episode.reference_time.isoformat() if episode.reference_time else None,
            "type": _classify_episode_type(episode.name),
            "title": _generate_event_title(episode),
            "data": episode.body
        })

    # ××™×•×Ÿ ×œ×¤×™ ×ª××¨×™×š
    timeline.sort(key=lambda x: x["date"] if x["date"] else "", reverse=True)

    return {"timeline": timeline}

# === Helper Functions ===

def _generate_suggestions(session: dict) -> List[str]:
    """×™×¦×™×¨×ª ×”×¦×¢×•×ª ×œ×¤×™ ×©×œ×‘"""
    stage = session["current_stage"]

    if stage == "welcome":
        return [
            "×©××• ×™×•× ×™ ×•×”×•× ×‘×Ÿ 3.5",
            "×”×™×œ×“×” ×©×œ×™ ×‘×ª 5",
            "×× ×™ ×¨×•×¦×” ×œ×“×‘×¨ ×¢×œ ×”×‘×Ÿ ×©×œ×™"
        ]
    elif len(session["interview_messages"]) < 5:
        return [
            "×”×•× ×××•×“ ××•×”×‘ ×¤××–×œ×™×",
            "×™×© ×œ×™ ×“××’×•×ª ×œ×’×‘×™ ×”×ª×§×©×•×¨×ª",
            "×¡×¤×¨×™ ×œ×™ ××” ×¢×•×“ ×—×©×•×‘"
        ]

    return []

def _generate_cards(session: dict) -> List[dict]:
    """×™×¦×™×¨×ª ×›×¨×˜×™×¡×™× ×“×™× ××™×™×"""
    cards = []

    # ×”×’×“×¨×ª ×©×œ×‘×™ ×”××¡×¢
    journey_stages = {
        "welcome": {"step": 1, "name": "×¨××™×•×Ÿ ×”×ª×¤×ª×—×•×ª×™", "emoji": "ğŸ—£ï¸"},
        "video_upload": {"step": 2, "name": "×¦×™×œ×•× ×¡×¨×˜×•× ×™×", "emoji": "ğŸ¬"},
        "video_analysis": {"step": 3, "name": "× ×™×ª×•×— ×¡×¨×˜×•× ×™×", "emoji": "ğŸ”"},
        "report_generation": {"step": 4, "name": "×™×¦×™×¨×ª ×“×•×—×•×ª", "emoji": "ğŸ“Š"},
        "consultation": {"step": 5, "name": "×™×™×¢×•×¥ ××§×¦×•×¢×™", "emoji": "ğŸ’¬"}
    }
    total_stages = 5
    current_stage = session["current_stage"]
    stage_info = journey_stages.get(current_stage, {"step": 1, "name": "×”×ª×—×œ×”", "emoji": "âœ¨"})

    # ×›×¨×˜×™×¡×™× ×œ×©×œ×‘ ×”×¨××™×•×Ÿ
    if session["current_stage"] == "welcome":
        num_messages = len(session.get("interview_messages", []))

        # ×›×¨×˜×™×¡ 1: ××ª× ×”×œ ×¨××™×•×Ÿ (×¦×”×•×‘ - processing)
        if num_messages > 0:
            progress_stage = "××™×“×¢ ×‘×¡×™×¡×™" if num_messages <= 3 else "×ª×•×‘× ×•×ª ×¢××•×§×•×ª" if num_messages <= 6 else "×¡×™×›×•×"
            cards.append({
                "type": "interview_status",
                "title": "××ª× ×”×œ ×¨××™×•×Ÿ",
                "subtitle": f"×”×ª×§×“××•×ª: {progress_stage}",
                "icon": "MessageCircle",
                "status": "processing",
                "action": None
            })

        # ×›×¨×˜×™×¡ 2: × ×•×©××™× ×©× ×“×•× ×• (×¦×™××Ÿ - progress)
        if num_messages >= 2:
            topics = []
            # × ×™×ª×•×— ×¤×©×•×˜ ×©×œ ×”× ×•×©××™× ××”×”×•×“×¢×•×ª
            messages_text = " ".join([m.get("content", "") for m in session.get("interview_messages", []) if m.get("role") == "user"])
            if "×’×™×œ" in messages_text or "×©× " in messages_text:
                topics.append("×’×™×œ")
            if "×“×™×‘×•×¨" in messages_text or "××“×‘×¨" in messages_text or "×ª×§×©×•×¨×ª" in messages_text:
                topics.append("×ª×§×©×•×¨×ª")
            if "×—×•×–×§" in messages_text or "××•×”×‘" in messages_text:
                topics.append("×—×•×–×§×•×ª")
            if "×“××’×”" in messages_text or "×§×•×©×™" in messages_text:
                topics.append("×“××’×•×ª")

            topics_text = ", ".join(topics) if topics else "×‘× ×™×™×ª ×¤×¨×•×¤×™×œ"
            cards.append({
                "type": "interview_topics",
                "title": "× ×•×©××™× ×©× ×“×•× ×•",
                "subtitle": topics_text,
                "icon": "CheckCircle2",
                "status": "progress",
                "action": None
            })

        # ×›×¨×˜×™×¡ 3: ×–××Ÿ ××©×•×¢×¨ (×›×ª×•× - pending)
        if num_messages >= 3 and num_messages < 7:
            estimated_time = max(5, 15 - (num_messages * 2))
            cards.append({
                "type": "interview_time",
                "title": "×–××Ÿ ××©×•×¢×¨",
                "subtitle": f"×¢×•×“ {estimated_time}-{estimated_time + 5} ×“×§×•×ª",
                "icon": "Clock",
                "status": "pending",
                "action": None
            })

    # ×›×¨×˜×™×¡×™× ×œ×©×œ×‘ ×¦×™×œ×•× ×”×•×•×™×“××•
    elif session["current_stage"] == "video_upload" and "video_guidelines" in session:
        num_scenarios = len(session["video_guidelines"].get("scenarios", []))
        num_videos = len(session.get("uploaded_videos", []))

        # ×›×¨×˜×™×¡ 1: ×”×•×¨××•×ª ×¦×™×œ×•× (×›×ª×•× - pending) - ×¨×™×›×•×– ×›×œ ×”×”× ×—×™×•×ª
        cards.append({
            "type": "guidelines_summary",
            "title": "×”×•×¨××•×ª ×¦×™×œ×•×",
            "subtitle": f"{num_scenarios} ×ª×¨×—×™×©×™×",
            "icon": "Video",
            "status": "pending",
            "action": "view_all_guidelines"
        })

        # ×›×¨×˜×™×¡ 2: ×”×”×ª×§×“××•×ª ×©×œ×š (×¦×™××Ÿ - progress) + breadcrumbs
        cards.append({
            "type": "overall_progress",
            "title": "×”×”×ª×§×“××•×ª ×©×œ×š",
            "subtitle": f"×¨××™×•×Ÿ âœ“ | ×¡×¨×˜×•× ×™× ({num_videos}/{num_scenarios})",
            "icon": "CheckCircle2",
            "status": "progress",
            "action": None,
            "journey_step": stage_info["step"],
            "journey_total": total_stages
        })

        # ×›×¨×˜×™×¡ 3: ×”×¢×œ××ª ×¡×¨×˜×•×Ÿ (×›×—×•×œ - action)
        cards.append({
            "type": "upload_video",
            "title": "×”×¢×œ××ª ×¡×¨×˜×•×Ÿ",
            "subtitle": "×œ×—×¦×™ ×›×“×™ ×œ×”×¢×œ×•×ª",
            "icon": "Upload",
            "status": "action",
            "action": "upload"
        })

        # ×›×¨×˜×™×¡×™ ×”× ×—×™×•×ª ×¦×™×œ×•× ××¤×•×¨×˜×•×ª (××™× ×“×™×’×• - instruction)
        for idx, scenario in enumerate(session["video_guidelines"].get("scenarios", [])):
            cards.append({
                "type": "video_guideline",
                "title": scenario["title"],
                "subtitle": scenario["description"],
                "icon": "Video",
                "status": "instruction",
                "action": f"view_guideline_{idx}",
                "priority": scenario.get("priority", "recommended"),
                "rationale": scenario.get("rationale", ""),
                "target_areas": scenario.get("target_areas", [])
            })

    return cards

def _classify_episode_type(name: str) -> str:
    """×–×™×”×•×™ ×¡×•×’ episode"""
    if "interview" in name:
        return "interview"
    elif "video_guidelines" in name:
        return "guidelines"
    elif "video_upload" in name:
        return "video_upload"
    elif "video_analysis" in name:
        return "analysis"
    elif "report" in name:
        return "report"
    else:
        return "other"

def _generate_event_title(episode) -> str:
    """×™×¦×™×¨×ª ×›×•×ª×¨×ª ×œevent"""
    episode_type = _classify_episode_type(episode.name)

    titles = {
        "interview": "×¨××™×•×Ÿ ×”×ª×¤×ª×—×•×ª×™",
        "guidelines": "×”× ×—×™×•×ª ×¦×™×œ×•× × ×•×¦×¨×•",
        "video_upload": "×”×¢×œ××ª ×•×™×“××•",
        "analysis": "× ×™×ª×•×— ×•×™×“××• ×”×•×©×œ×",
        "report": "×“×•×— ××•×›×Ÿ"
    }

    return titles.get(episode_type, "××™×¨×•×¢")
