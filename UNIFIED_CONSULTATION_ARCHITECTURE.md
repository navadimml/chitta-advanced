# Unified Consultation Architecture: Graphiti-Powered

**Status:** Design Document
**Date:** 2025-11-11
**Philosophy:** Wu Wei - Leverage existing power, don't reinvent

---

## Core Insight

Instead of creating special handlers for different types of knowledge (artifacts, documents, conversations), **use Graphiti's search as the universal retrieval mechanism**.

### The Simplification

**Before (Complex):**
```
Question about artifact? â†’ artifact_handler() â†’ retrieve artifact
Question about diagnosis? â†’ diagnosis_handler() â†’ retrieve document
Question about child? â†’ context_handler() â†’ retrieve structured data
General question? â†’ consultation_handler() â†’ retrieve conversation
```

**After (Simple - Wu Wei):**
```
ANY question â†’ graphiti.search(question, child_node, family_id) â†’ relevant context
```

Graphiti automatically retrieves relevant information from ALL sources:
- Generated artifacts (reports, guidelines, analysis)
- Uploaded documents (diagnosis reports, evaluations)
- Conversation history (all discussions)
- Journal entries (observations over time)
- Structured data (milestones, concerns, professionals)

---

## How Uploaded Documents Work

### Document as Episode

When a parent uploads a diagnosis report (××™×‘×—×•×Ÿ):

```python
# backend/app/services/document_service.py
from graphiti_core import Graphiti
from graphiti_core.nodes import EpisodeType
from datetime import datetime
import PyPDF2  # or other document parser

async def upload_diagnosis_document(
    family_id: str,
    child_id: str,
    file_path: str,
    document_metadata: dict
):
    """
    Upload an external diagnosis report (××™×‘×—×•×Ÿ) to Graphiti.

    The document becomes searchable alongside all other knowledge.
    """

    # Extract text from PDF/DOC
    document_text = extract_text_from_document(file_path)

    # Create episode with structured metadata
    episode_body = f"""
    External Diagnosis Report

    Document Type: {document_metadata.get('type', 'Diagnosis Report')}
    Professional: {document_metadata.get('professional_name')}
    Specialty: {document_metadata.get('specialty')}
    Date: {document_metadata.get('report_date')}

    Full Content:
    {document_text}

    Key Findings:
    {document_metadata.get('key_findings', 'See full content above')}
    """

    # Add to Graphiti as episode
    await graphiti.add_episode(
        name=f"diagnosis_report_{child_id}_{document_metadata.get('report_date')}",
        episode_body=episode_body,
        source=EpisodeType.text,
        reference_time=datetime.fromisoformat(document_metadata['report_date']),
        group_id=f"family_{family_id}",
        entity_types=entity_types,
        edge_types=edge_types,
        edge_type_map=edge_type_map
    )

    # Graphiti automatically:
    # 1. Extracts entities (diagnoses, observations, recommendations)
    # 2. Creates relationships (Child -> HasDiagnosis -> Diagnosis entity)
    # 3. Makes it searchable with all other knowledge

    return {
        "status": "uploaded",
        "searchable": True,
        "message": "Document indexed and ready for consultation"
    }
```

### Document Entity Type

Add new entity type for external documents:

```python
# In entity schema (from GRAPHITI_INTEGRATION_GUIDE.md)

class ExternalDocument(BaseModel):
    """An uploaded external document (diagnosis report, evaluation, etc.)"""
    document_type: str = Field(..., description="Diagnosis, Evaluation, Assessment, etc.")
    professional_name: Optional[str] = None
    specialty: Optional[str] = None
    report_date: datetime
    key_findings: Optional[list[str]] = None

class Diagnosis(BaseModel):
    """A clinical diagnosis from external document or assessment"""
    diagnosis_name: str = Field(..., description="e.g., Autism Spectrum Disorder, Speech Delay")
    icd_code: Optional[str] = None
    severity: Optional[str] = Field(None, description="mild, moderate, severe")
    notes: Optional[str] = None
```

### Edge Types for Documents

```python
class ReceivedDiagnosis(BaseModel):
    """Child received a diagnosis from a professional"""
    diagnosis_date: datetime
    diagnosing_professional: Optional[str] = None
    confidence_level: Optional[str] = Field(None, description="confirmed, suspected, ruled out")

class DocumentedIn(BaseModel):
    """Finding or diagnosis is documented in an external document"""
    page_number: Optional[int] = None
    section: Optional[str] = None

# Update edge type map
edge_type_map = {
    # ... existing mappings
    ("Child", "Diagnosis"): ["ReceivedDiagnosis"],
    ("Child", "ExternalDocument"): ["HasDocument"],
    ("Diagnosis", "ExternalDocument"): ["DocumentedIn"],
    ("Observation", "ExternalDocument"): ["DocumentedIn"],
}
```

---

## Universal Consultation Service

### The Single Handler

```python
# backend/app/services/consultation_service.py
from graphiti_core import Graphiti
from services.llm.factory import LLMFactory
from services.llm.base import Message
from datetime import datetime
import json

class ConsultationService:
    """
    Universal consultation service powered by Graphiti.

    Works for ANY question:
    - "What did the psychologist write about attention?" â†’ searches diagnosis docs
    - "What did you mean by 'sensory seeking' in the report?" â†’ searches our artifacts
    - "How has speech improved over time?" â†’ searches all observations
    - "What strategies worked for meltdowns?" â†’ searches journal + conversations
    """

    def __init__(self, graphiti: Graphiti, llm_provider: str = "gemini"):
        self.graphiti = graphiti
        self.llm = LLMFactory.create(
            provider=llm_provider,
            api_key=settings.LLM_API_KEY,
            model=settings.LM_MODEL
        )

    async def handle_consultation(
        self,
        family_id: str,
        child_id: str,
        question: str,
        conversation_history: list[dict] = None
    ) -> dict:
        """
        Universal consultation handler.

        1. Use Graphiti to retrieve relevant context
        2. Generate response with full context
        3. Save consultation as episode for future reference
        """

        # Get child's node for centered search
        child_node = await self._get_child_node(child_id, family_id)

        # Retrieve relevant context using Graphiti's semantic search
        context_results = await self.graphiti.search(
            query=question,
            center_node_uuid=child_node.uuid if child_node else None,
            group_id=f"family_{family_id}",
            num_results=20  # Get rich context
        )

        # Format context for LLM
        formatted_context = self._format_context_for_llm(context_results)

        # Build system prompt with context
        system_prompt = f"""
        ××ª×” Chitta, ××“×¨×™×›×” ×œ×”×ª×¤×ª×—×•×ª ×™×œ×“×™× ×‘×™×©×¨××œ.

        ×”×”×•×¨×” ×©×•××œ ×©××œ×”. ×™×© ×œ×š ×’×™×©×” ×œ×”×™×¡×˜×•×¨×™×” ××œ××” ×©×œ ×”×™×œ×“/×”:
        - ×©×™×—×•×ª ×©×§×™×™××ª×
        - ×“×•×—×•×ª ×©×™×¦×¨×ª (×”× ×—×™×•×ª, × ×™×ª×•×—×™×, ×¡×™×›×•××™×)
        - ××¡××›×™× ×©×”×”×•×¨×” ×”×¢×œ×” (××™×‘×—×•× ×™×, ×”×¢×¨×›×•×ª ××§×¦×•×¢×™×•×ª)
        - ×¨×™×©×•××™ ×™×•××Ÿ (×ª×¦×¤×™×•×ª ×œ××•×¨×š ×–××Ÿ)
        - ××‘× ×™ ×“×¨×š ×•×”×ª×§×“××•×ª

        ×”×§×©×¨ ×¨×œ×•×•× ×˜×™ ××”-Knowledge Graph:
        {formatted_context}

        ×”× ×—×™×•×ª ×œ××¢× ×”:
        1. ×”×©×ª××©×™ ×‘×§×©×¨ ×”××œ× - ×”×ª×™×™×—×¡×™ ×œ×ª×¦×¤×™×•×ª ×¡×¤×¦×™×¤×™×•×ª, ×ª××¨×™×›×™×, ×“×¤×•×¡×™×
        2. ×× ×”×©××œ×” ×¢×œ ××¡××š ×—×™×¦×•× ×™ (××™×‘×—×•×Ÿ), ×¦×™×˜×˜×™ ××× ×• ×™×©×™×¨×•×ª
        3. ×× ×”×©××œ×” ×¢×œ ×“×•×— ×©×›×ª×‘×ª, ×”×¡×‘×™×¨×™ ××” ×”×ª×›×•×•× ×ª ×•×œ××”
        4. ×× ×”×©××œ×” ×¢×œ ×“×¤×•×¡×™× ×œ××•×¨×š ×–××Ÿ, ×”×¨××™ ××ª ×”××’××”
        5. ×ª× ×™ ×¢×¦×•×ª ××¢×©×™×•×ª ××‘×•×¡×¡×•×ª ×¢×œ ××” ×©×¢×‘×“ ×‘×¢×‘×¨
        6. ×× ××™×Ÿ ×œ×š ××™×“×¢ ××¡×¤×™×§, ×ª×’×™×“×™ ×–××ª ×‘×›× ×•×ª

        ×“×‘×¨×™ ×‘×¢×‘×¨×™×ª ×˜×‘×¢×™×ª, ×—××” ×•×ª×•××›×ª.
        """

        # Generate consultation response
        messages = [
            Message(role="system", content=system_prompt),
            *[Message(role=h["role"], content=h["content"])
              for h in (conversation_history or [])],
            Message(role="user", content=question)
        ]

        llm_response = await self.llm.generate(
            messages=messages,
            temperature=0.7,
            max_tokens=2048
        )

        response_text = llm_response.content

        # Save this consultation as an episode for future context
        await self.graphiti.add_episode(
            name=f"consultation_{child_id}_{datetime.now().isoformat()}",
            episode_body=f"Parent Question: {question}\n\nChitta Response: {response_text}",
            source=EpisodeType.message,
            reference_time=datetime.now(),
            group_id=f"family_{family_id}",
            entity_types=entity_types,
            edge_types=edge_types,
            edge_type_map=edge_type_map
        )

        return {
            "response": response_text,
            "context_sources": self._summarize_sources(context_results),
            "timestamp": datetime.now().isoformat()
        }

    def _format_context_for_llm(self, context_results: list) -> str:
        """Format Graphiti search results for LLM consumption"""

        if not context_results:
            return "××™×Ÿ ××™×“×¢ ×–××™×Ÿ ×¢×“×™×™×Ÿ."

        formatted = []

        for i, result in enumerate(context_results, 1):
            # Each result has: fact, reference_time, episode_name, etc.
            timestamp = result.reference_time.strftime("%Y-%m-%d") if result.reference_time else "Unknown date"
            source_type = self._identify_source_type(result.episode_name)

            formatted.append(f"""
            [{i}] [{source_type}] ({timestamp})
            {result.fact}
            """)

        return "\n".join(formatted)

    def _identify_source_type(self, episode_name: str) -> str:
        """Identify the source type from episode name"""
        if "diagnosis_report" in episode_name:
            return "ğŸ“„ ××™×‘×—×•×Ÿ ×—×™×¦×•× ×™"
        elif "baseline_parent_report" in episode_name:
            return "ğŸ“‹ ×“×•×— ×©×™×¦×¨×” Chitta"
        elif "journal" in episode_name:
            return "ğŸ“” ×™×•××Ÿ"
        elif "interview" in episode_name:
            return "ğŸ’¬ ×©×™×—×”"
        elif "video_analysis" in episode_name:
            return "ğŸ¥ × ×™×ª×•×— ×•×™×“××•"
        else:
            return "ğŸ“ ××™×“×¢"

    def _summarize_sources(self, context_results: list) -> dict:
        """Summarize which sources were used in consultation"""
        sources = {
            "external_documents": 0,
            "generated_reports": 0,
            "conversations": 0,
            "journal_entries": 0,
            "video_analyses": 0
        }

        for result in context_results:
            if "diagnosis_report" in result.episode_name:
                sources["external_documents"] += 1
            elif "report" in result.episode_name:
                sources["generated_reports"] += 1
            elif "journal" in result.episode_name:
                sources["journal_entries"] += 1
            elif "interview" in result.episode_name or "consultation" in result.episode_name:
                sources["conversations"] += 1
            elif "video" in result.episode_name:
                sources["video_analyses"] += 1

        return sources

    async def _get_child_node(self, child_id: str, family_id: str):
        """Get the child's node UUID for centered search"""
        # Search for the child entity
        results = await self.graphiti.search(
            query=f"child with id {child_id}",
            group_id=f"family_{family_id}",
            num_results=1
        )

        if results and len(results) > 0:
            return results[0]
        return None
```

---

## Example Usage Scenarios

### Scenario 1: Question About External Diagnosis

```python
# Parent uploaded a diagnosis report from a psychologist
# Report mentioned "executive function difficulties"

# Parent asks:
question = "××” ×”××©××¢×•×ª ×©×œ '×§×©×™×™ ×ª×¤×§×•×“×™× × ×™×”×•×œ×™×™×' ×©×”×¤×¡×™×›×•×œ×•×’×™×ª ×›×ª×‘×”?"

response = await consultation_service.handle_consultation(
    family_id="family_123",
    child_id="child_456",
    question=question
)

# Graphiti automatically finds:
# 1. The external diagnosis document episode
# 2. Relevant observations from conversations about attention/planning
# 3. Strategies tried from journal entries
# 4. Related information from generated reports

# Chitta responds:
"""
×”×¤×¡×™×›×•×œ×•×’×™×ª ×”×ª×™×™×—×¡×” ×œ'×ª×¤×§×•×“×™× × ×™×”×•×œ×™×™×' (Executive Functions) - ××œ×• ×”×›×™×©×•×¨×™×
×©×¢×•×–×¨×™× ×œ×™×œ×“ ×œ×ª×›× ×Ÿ, ×œ×”×ª××¨×’×Ÿ, ×•×œ×¢×¦×•×¨ ×•×œ×—×©×•×‘ ×œ×¤× ×™ ×¤×¢×•×œ×”.

××”××™×‘×—×•×Ÿ ×©×”×¢×œ×™×ª (15.10.2024), ×”×™× ×›×ª×‘×”:
"× ×¦×¤×• ×§×©×™×™× ×‘×ª×¤×§×•×“×™× × ×™×”×•×œ×™×™×, ×‘××™×•×—×“ ×‘×ª×›× ×•×Ÿ ×¨×¦×£ ×¤×¢×•×œ×•×ª ×•×‘×¢×™×›×•×‘ ×ª×’×•×‘×”"

×–×” ××ª×—×‘×¨ ×œ××” ×©×¡×™×¤×¨×ª ×œ×™ ×‘×©×™×—×” ×©×œ× ×• ×‘-20.10:
"×§×©×” ×œ×• ×œ×¢×¦×•×¨ ×œ×¤× ×™ ×©×”×•× ×¢×•×©×” ××©×”×•, ×”×•× ×¤×©×•×˜ ×§×•×¤×¥"

×“×¤×•×¡ ×–×” ×—×–×¨ ×’× ×‘×™×•××Ÿ ×©×œ×š - 3 ××ª×•×š 4 ×¨×™×©×•××™× ×‘××•×§×˜×•×‘×¨ ×“×™×•×•×—×• ×¢×œ ×”×ª× ×”×’×•×ª
××™××¤×•×œ×¡×™×‘×™×ª (×œ××©×œ: ×§×•×¤×¥ ××”××™×˜×” ×œ×¤× ×™ ×©×”×¤×¢×•×˜×•×Ÿ ××•×›×Ÿ).

××” ×©××¤×©×¨ ×œ×¢×©×•×ª:
1. ×¤×™×¨×•×§ ××©×™××•×ª ×œ×©×œ×‘×™× ×§×˜× ×™× ("×§×•×“× × ×œ×‘×™×© ×’×¨×‘×™×™×, ××—×¨ ×›×š × ×¢×œ×™×™×")
2. ×ª××•× ×•×ª ×¨×¦×£ ×¤×¢×•×œ×•×ª ×¢×œ ×”×§×™×¨
3. ××©×—×§×™ '×¢×¦×•×¨-×”××©×š' (×›××• '××•×¨ ×™×¨×•×§-××•×¨ ××“×•×')

×”×˜×™×¤×•×œ×™×ª ×”×ª×¢×¡×•×§×ª×™×ª ×©×œ×›× ×’× ×”××œ×™×¦×” ×¢×œ ××©×”×• ×“×•××” ×‘×¤×’×™×©×” ×”×¨××©×•× ×”.
"""
```

### Scenario 2: Question About Generated Report

```python
question = "×œ××” ×›×ª×‘×ª ×‘×“×•×— ×©×™×© ×œ×• '×—×™×¤×•×© ×—×•×©×™'? ××” ×–×” ××•××¨?"

# Graphiti finds:
# 1. The baseline_parent_report artifact episode
# 2. Original interview where parent described behaviors
# 3. Video analysis that identified sensory-seeking patterns
# 4. Professional diagnosis that mentioned sensory processing

# Chitta responds:
"""
×›×ª×‘×ª×™ '×—×™×¤×•×© ×—×•×©×™' (Sensory Seeking) ×‘×“×•×— ×›×™ ×©××ª×™ ×œ×‘ ×œ×“×¤×•×¡ ×©×œ ×”×ª× ×”×’×•×™×•×ª
×©×›×•×œ×Ÿ ×§×©×•×¨×•×ª ×œ×—×™×¤×•×© ×’×™×¨×•×™ ×—×•×©×™ ×—×–×§.

×‘××” ×“×™×‘×¨× ×• ×¢×œ ×–×”:
- ×‘×©×™×—×” ×©×œ× ×• (8.9.2024) ×¡×™×¤×¨×ª: "×”×•× ××•×”×‘ ×œ×§×¤×•×¥ ×¢×œ ×”×¡×¤×” ×‘×œ×™ ×”×¤×¡×§×”"
- ×‘×¡×¨×˜×•×Ÿ ×”×¨××©×•×Ÿ (12.9) ×¨××™×ª×™ ××•×ª×• ××¡×ª×•×‘×‘ ×‘××¢×’×œ×™× 7 ×¤×¢××™×
- ×‘×™×•××Ÿ (15.9) ×¨×©××ª: "×”×™×•× ×”×•× ×‘×™×§×© ×©×× ×™ ××œ×—×¥ ××•×ª×• ×—×–×§ ×‘×©××™×›×”"

×›×œ ××œ×• ×”×Ÿ ×“×¨×›×™× ×©×”×’×•×£ ×©×œ×• ××—×¤×© ×ª×—×•×©×•×ª ×ª× ×•×¢×” ×•×œ×—×¥.

×–×” ×œ× ×“×‘×¨ ×¨×¢! ×–×” ×¡×•×’ ×©×œ ×•×™×¡×•×ª ×—×•×©×™. ×”×™×œ×“×™× ×”××œ×• ×¤×©×•×˜ ×¦×¨×™×›×™× ×™×•×ª×¨
×§×œ×˜ ×—×•×©×™ ×›×“×™ ×œ×”×¨×’×™×© ×××•×¨×’× ×™×.

×’× ×”×˜×™×¤×•×œ×™×ª ×”×ª×¢×¡×•×§×ª×™×ª ×©×œ×›× ×›×ª×‘×” ××©×”×• ×“×•××” ×‘××™×‘×—×•×Ÿ ×©×œ×” (20.9):
"××¨××” ×“×¤×•×¡×™ Sensory Seeking ×‘××¢×¨×›×ª ×”×•×•×¡×˜×™×‘×•×œ×¨×™×ª ×•×”×¤×¨×•×¤×¨×™×•×¦×¤×˜×™×‘×™×ª"

×”×“×‘×¨ ×”×—×©×•×‘: ×œ×ª×ª ×œ×• ×”×–×“×× ×•×™×•×ª ×‘×˜×•×—×•×ª ×œ×—×™×¤×•×© ×”×—×•×©×™ ×”×–×” - ×˜×¨××¤×•×œ×™× ×”,
××©×—×§×™ ×“×—×™×¤×”/××©×™×›×”, ×©××™×›×•×ª ×›×‘×“×•×ª.
"""
```

### Scenario 3: Pattern Over Time

```python
question = "×”×× ×”×“×™×‘×•×¨ ×©×œ×• ×”×©×ª×¤×¨ ×‘×—×•×“×©×™×™× ×”××—×¨×•× ×™×?"

# Graphiti searches across time:
# - Conversations from September, October, November
# - Journal entries documenting speech milestones
# - Video analysis comparing early vs recent videos
# - Professional notes from speech therapist

# Chitta responds:
"""
×›×Ÿ! ×× ×™ ×¨×•××” ×©×™×¤×•×¨ ×‘×¨×•×¨ ×‘×“×™×‘×•×¨ ×©×œ ×™×•× ×™ ×‘×—×•×“×©×™×™× ×”××—×¨×•× ×™×. ×‘×•××™ ××¨××” ×œ×š:

×¡×¤×˜××‘×¨ (× ×§×•×“×ª ×”×ª×—×œ×”):
- "×™×© ×œ×• ×›××” ××™×œ×™× ×‘×•×“×“×•×ª ××‘×œ ×œ× ××©×¤×˜×™×" (×©×™×—×”, 8.9)
- ×‘×¡×¨×˜×•×Ÿ ×”×¨××©×•×Ÿ: ×–×™×”×™×ª×™ 4 ××™×œ×™× ×‘×¨×•×¨×•×ª

××•×§×˜×•×‘×¨ (×©×™×¤×•×¨ × ×™×›×¨):
- "×”×™×•× ×”×•× ×××¨ '××‘× ×‘×•×' - ×©×ª×™ ××™×œ×™× ×‘×™×—×“!" (×™×•××Ÿ, 15.10)
- ×’× ×”×§×œ×™× ××™×ª ×”×ª×§×©×•×¨×ª ×¦×™×™× ×” ×‘×¤×’×™×©×” (22.10): "××ª×—×™×œ ×œ×©×œ×‘ ×©×ª×™ ××™×œ×™×"

× ×•×‘××‘×¨ (×”××©×š ×”×ª×§×“××•×ª):
- "×××¨ ×œ×™ ×”×™×•× '×¨×•×¦×” ××™×' - ×× ×™ ×‘×”×œ×!" (×™×•××Ÿ, 3.11)
- ×‘×©×™×—×” ×©×œ× ×• (7.11) ×¡×™×¤×¨×ª ×©×”×•× ×××¨ 4 ××©×¤×˜×™× ×©×•× ×™× ×‘××•×ª×• ×™×•×

×–×” ×©×™×¤×•×¨ ××©××¢×•×ª×™! ×-4 ××™×œ×™× ×‘×•×“×“×•×ª ×œ×¢×©×¨×•×ª ××™×œ×™× ×•××©×¤×˜×™× ×‘× ×™ 2-3 ××™×œ×™×.

×§×¦×‘ ×”×“×™×‘×•×¨ ×©×œ×• ×¢×œ×” ×¤×™ 3 ×‘×—×•×“×©×™×™× - ×–×” ××¢×•×œ×”! ×××©×™×›×™× ×‘×“×™×•×§ ××ª ××” ×©××ª ×¢×•×©×”. ğŸ’™
"""
```

---

## Integration with Conversation Service

```python
# backend/app/services/conversation_service.py

async def process_message(family_id: str, child_id: str, user_message: str):
    """
    Process incoming message - detect if it's a consultation question
    """

    # Detect intent (existing logic)
    intent = await detect_intent(user_message, conversation_history)

    if intent == "SEEKING_CONSULTATION":
        # Use universal consultation service
        result = await consultation_service.handle_consultation(
            family_id=family_id,
            child_id=child_id,
            question=user_message,
            conversation_history=get_recent_history(family_id)
        )

        return {
            "response": result["response"],
            "sources_used": result["context_sources"],
            "type": "consultation"
        }

    elif intent == "SHARING_INFORMATION":
        # Extract data and continue conversation
        # ... existing logic
        pass

    elif intent == "ACTION_REQUEST":
        # Handle action (view report, generate summary, etc.)
        # ... existing logic
        pass

    # ... other intents
```

---

## Benefits of Unified Approach

### 1. **Simplicity (×¤×©×•×˜)**
- ONE service for all consultation types
- NO special handlers for different knowledge types
- Graphiti handles complexity internally

### 2. **Generality (×›×œ×œ×™)**
- Works for existing knowledge: conversations, reports, journal
- Works for NEW knowledge types: uploaded documents, video analysis, professional notes
- Future-proof: any new knowledge type just becomes an episode

### 3. **Accuracy (××“×•×™×§)**
- Semantic search finds relevant context automatically
- Temporal awareness (recent vs old information)
- Relationship awareness (connected facts surface together)

### 4. **Context-Rich (×¢×©×™×¨ ×‘×”×§×©×¨)**
- LLM gets full context from all sources
- Can reference specific observations, dates, patterns
- Creates natural, informed responses

### 5. **Privacy (×¤×¨×˜×™×•×ª)**
- `group_id=family_X` ensures complete isolation
- Each family's knowledge is separate
- No cross-family leakage

---

## Implementation Steps

### Step 1: Extend Entity Schema (Week 1)

```python
# Add to backend/app/services/graphiti_service.py

# New entity types
class ExternalDocument(BaseModel):
    document_type: str
    professional_name: Optional[str] = None
    specialty: Optional[str] = None
    report_date: datetime
    key_findings: Optional[list[str]] = None

class Diagnosis(BaseModel):
    diagnosis_name: str
    icd_code: Optional[str] = None
    severity: Optional[str] = None
    notes: Optional[str] = None

# New edge types
class ReceivedDiagnosis(BaseModel):
    diagnosis_date: datetime
    diagnosing_professional: Optional[str] = None

class DocumentedIn(BaseModel):
    page_number: Optional[int] = None
    section: Optional[str] = None

# Update edge_type_map
edge_type_map.update({
    ("Child", "Diagnosis"): ["ReceivedDiagnosis"],
    ("Child", "ExternalDocument"): ["HasDocument"],
    ("Diagnosis", "ExternalDocument"): ["DocumentedIn"],
})
```

### Step 2: Implement Document Upload Service (Week 1-2)

```python
# backend/app/services/document_service.py
# (See code example above)
```

### Step 3: Implement Universal Consultation Service (Week 2)

```python
# backend/app/services/consultation_service.py
# (See code example above)
```

### Step 4: Integrate with Conversation Flow (Week 2-3)

- Update conversation_service.py to route consultation questions
- Add UI for document upload
- Display source attribution in responses

### Step 5: Test with Real Data (Week 3)

- Upload sample diagnosis reports
- Test consultation across all knowledge types
- Verify context relevance and quality

---

## Example API Endpoints

### Upload Document

```python
@router.post("/families/{family_id}/documents/upload")
async def upload_document(
    family_id: str,
    child_id: str,
    file: UploadFile,
    metadata: DocumentMetadata
):
    """Upload external document (diagnosis, evaluation, etc.)"""

    # Save file
    file_path = await save_uploaded_file(file, family_id)

    # Ingest into Graphiti
    result = await document_service.upload_diagnosis_document(
        family_id=family_id,
        child_id=child_id,
        file_path=file_path,
        document_metadata=metadata.dict()
    )

    return result
```

### Ask Consultation Question

```python
@router.post("/families/{family_id}/consultation")
async def ask_consultation_question(
    family_id: str,
    child_id: str,
    question: ConsultationRequest
):
    """Ask any consultation question - universal handler"""

    result = await consultation_service.handle_consultation(
        family_id=family_id,
        child_id=child_id,
        question=question.text,
        conversation_history=question.context
    )

    return {
        "answer": result["response"],
        "sources": result["context_sources"],
        "timestamp": result["timestamp"]
    }
```

---

## Wu Wei Achievement

**Before:**
- Multiple special handlers
- Complex routing logic
- Duplicate code for different knowledge types
- Fragile (breaks when new types added)

**After:**
- Single consultation service
- Graphiti handles routing via semantic search
- Universal mechanism for all knowledge
- Extensible (new types just become episodes)

**Wu Wei:** ×¤×©×•×˜ - × ×˜×•×œ ×—×œ×§×™× ×¢×•×“×¤×™× (Simple - without excess parts)

The power was already there in Graphiti. We just needed to use it fully instead of building redundant handlers on top.

---

## Next Steps

1. âœ… **Design complete** (this document)
2. ğŸ”§ **Extend entity schema** with ExternalDocument and Diagnosis
3. ğŸ”§ **Implement document upload service**
4. ğŸ”§ **Implement universal consultation service**
5. ğŸ”§ **Add UI for document upload**
6. ğŸ”§ **Test with real diagnosis reports**
7. ğŸ”§ **Validate consultation quality**

---

**Status:** Ready for implementation
**Complexity:** Simple (Wu Wei)
**Extensibility:** Infinite (any new knowledge type works automatically)
